{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d3e456-2b0d-4cb2-8f77-e2745ae0d259",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# NLP & Classification Project\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159356e2-cbf3-43f2-b743-0a89be820262",
   "metadata": {},
   "source": [
    "## import and Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "205a33bc-2270-4f0c-8ad4-ce5ddcc54904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# NLP tools\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "600820d0-759f-4833-bde7-e2b410e5b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = pd.read_csv('subreddit_pepsi_vs_cocacola.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bbf785e1-f489-46f4-b810-56be5073ff4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1958, 8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "456090cf-14c1-4ba6-bd75-7e69a5dfc820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>is_pepsi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall clock.</td>\n",
       "      <td>17</td>\n",
       "      <td>1godhom</td>\n",
       "      <td>https://www.reddit.com/gallery/1godhom</td>\n",
       "      <td>1</td>\n",
       "      <td>11/11/2024 5:58</td>\n",
       "      <td>I'm trying to locate a value for this clock. I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy Veterans Day!, Coca Cola poster sealed d...</td>\n",
       "      <td>4</td>\n",
       "      <td>1gojyxe</td>\n",
       "      <td>https://i.redd.it/a3xsqwwaa70e1.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>11/11/2024 11:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do yall like better</td>\n",
       "      <td>30</td>\n",
       "      <td>1go7cpq</td>\n",
       "      <td>https://www.reddit.com/gallery/1go7cpq</td>\n",
       "      <td>85</td>\n",
       "      <td>11/11/2024 1:33</td>\n",
       "      <td>Diet coke or coke and why</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Every drink company cola has owned and owns an...</td>\n",
       "      <td>0</td>\n",
       "      <td>1goc0ni</td>\n",
       "      <td>https://miro.com/app/board/uXjVM_YVujs=/</td>\n",
       "      <td>1</td>\n",
       "      <td>11/11/2024 4:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wall thermometer</td>\n",
       "      <td>22</td>\n",
       "      <td>1gnaebp</td>\n",
       "      <td>https://i.redd.it/13cyo811rvzd1.jpeg</td>\n",
       "      <td>4</td>\n",
       "      <td>11/9/2024 20:44</td>\n",
       "      <td>Vintage wall thermometer my Dad had.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score       id  \\\n",
       "0                                        Wall clock.     17  1godhom   \n",
       "1  Happy Veterans Day!, Coca Cola poster sealed d...      4  1gojyxe   \n",
       "2                           What do yall like better     30  1go7cpq   \n",
       "3  Every drink company cola has owned and owns an...      0  1goc0ni   \n",
       "4                                   Wall thermometer     22  1gnaebp   \n",
       "\n",
       "                                        url  comms_num           created  \\\n",
       "0    https://www.reddit.com/gallery/1godhom          1   11/11/2024 5:58   \n",
       "1      https://i.redd.it/a3xsqwwaa70e1.jpeg          0  11/11/2024 11:31   \n",
       "2    https://www.reddit.com/gallery/1go7cpq         85   11/11/2024 1:33   \n",
       "3  https://miro.com/app/board/uXjVM_YVujs=/          1   11/11/2024 4:53   \n",
       "4      https://i.redd.it/13cyo811rvzd1.jpeg          4   11/9/2024 20:44   \n",
       "\n",
       "                                                body  is_pepsi  \n",
       "0  I'm trying to locate a value for this clock. I...         0  \n",
       "1                                                NaN         0  \n",
       "2                          Diet coke or coke and why         0  \n",
       "3                                                NaN         0  \n",
       "4               Vintage wall thermometer my Dad had.         0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "83cf867f-4fc8-4a73-9810-231cf975d9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "score          0\n",
       "id             0\n",
       "url            0\n",
       "comms_num      0\n",
       "created        0\n",
       "body         713\n",
       "is_pepsi       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93a4e60e-4723-4877-865d-94342f75d5ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1958, 8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee6a3382-32b3-46f2-9c82-25584d36fa87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I'm trying to locate a value for this clock. I...\n",
       "1                                                  NaN\n",
       "2                            Diet coke or coke and why\n",
       "3                                                  NaN\n",
       "4                 Vintage wall thermometer my Dad had.\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem['body'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cac39b8e-bfa2-4a20-be1c-85416b7e707d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1958, 8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stem = stem.dropna()\n",
    "stem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5f63726d-98f2-4a79-bff7-a5bb2b062ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem['body'] = np.where(stem['body'].isnull(), stem['title'], stem['title'] + ' ' + stem['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a34dbfe-620a-4aee-8326-34ea97a2fa98",
   "metadata": {},
   "source": [
    "## Define Stopwords and remove from X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d29d3d7b-abce-4d03-bdba-9793064188b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = set(stopwords.words('english') + ['pepsi','pepsico', 'coke', 'coca', 'cola'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e90c5c97-545f-4f6b-9db6-a713cb50d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stem['body']\n",
    "y = stem['is_pepsi'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e64befa5-7452-47b7-b28c-3c1cfac9b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    tokens = text.split()  # Tokenize the text\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in custom_stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Apply the function to the dataset X\n",
    "X = X.apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ef8373bf-0b8b-437e-826e-be507c139008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.20,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0e761b34-edd2-4cfd-99e4-98b2b58247f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_pepsi\n",
       "1    0.508301\n",
       "0    0.491699\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "910cde5b-7510-488a-9da3-79c884520ab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_pepsi\n",
       "1    0.507653\n",
       "0    0.492347\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de59ea-7257-4c16-9c39-9667af3d6879",
   "metadata": {},
   "source": [
    "### Define Stem and Lematize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a9cb6f73-fcd9-4153-bfe4-6e8bef85d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer() \n",
    "lemmatizer = WordNetLemmatizer()  \n",
    "\n",
    "def stemmer_tokenizer(tokens):\n",
    "    tokens = tokens.split()\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "def lemmatizer_tokenizer(tokens):\n",
    "    tokens = tokens.split()\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "781175b6-2b26-4e86-a7e0-e80c80dad114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defualt vector params \n",
    "defualt_params = {\n",
    "    'vectorizer__max_features': [None],  \n",
    "    'vectorizer__ngram_range': [(1, 1)], \n",
    "    'vectorizer__lowercase': [True],     \n",
    "    'vectorizer__min_df': [1],           \n",
    "    'vectorizer__max_df': [1.0],         \n",
    "    'vectorizer__token_pattern': [r'(?u)\\b\\w+\\b']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "57802ef8-8a69-4512-a029-03a1a826c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of vectors Params for GridSearchCV\n",
    "params = {\n",
    "    'vectorizer__max_features': [3000, 5000],\n",
    "    'vectorizer__min_df': [2, 3],\n",
    "    'vectorizer__max_df': [0.8, 0.9],\n",
    "    'vectorizer__ngram_range': [(1, 2), (1, 1)],\n",
    "    'vectorizer__lowercase': [True, False],\n",
    "    'vectorizer__tokenizer': [None, stemmer_tokenizer, lemmatizer_tokenizer],  # Custom tokenizers\n",
    "    'vectorizer__token_pattern': [r'(?u)\\b[a-zA-Z]+\\b', r'(?u)\\b[a-zA-Z0-9]+\\b']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8e2ee188-f954-4f45-ae28-3f7ab8014c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of model params (defualt_params be added)\n",
    "defualt_param_grids = {\n",
    "    'LogisticRegression': [{**params, 'classifier': [LogisticRegression()]}],\n",
    "    'KNN': [{**params, 'classifier': [KNeighborsClassifier()]}],\n",
    "    'DecisionTree': [{**params, 'classifier': [DecisionTreeClassifier()]}],\n",
    "    'BaggedDecisionTree': [{**params, 'classifier': [BaggingClassifier(DecisionTreeClassifier())]}],\n",
    "    'RandomForest': [{**params, 'classifier': [RandomForestClassifier()]}],\n",
    "    'AdaBoost': [{**params,'classifier': [AdaBoostClassifier(algorithm='SAMME')]}],    \n",
    "    'GradientBoosting': [{**params,  'classifier': [GradientBoostingClassifier()]}],    \n",
    "    'XGBoost': [{**params,  'classifier': [XGBClassifier()]}],    \n",
    "    'SVM': [{**params,  'classifier': [SVC()]}],    \n",
    "    'Naive Bayes': [{**params,  'classifier': [MultinomialNB()]}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "577c96a8-024b-4160-ab17-2d84c027187c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to evaluate model and return dataframe to compare train/test score by model,params \n",
    "def evaluate_models(X_train, y_train, param_grids):\n",
    "\n",
    "    start_time = time.time()\n",
    "    vectorizers = {'CountVectorizer': CountVectorizer(), 'TfidfVectorizer': TfidfVectorizer()}\n",
    "    results = []\n",
    "\n",
    "    # Iterate through vectorizer options\n",
    "    for vector_name, vector in vectorizers.items():\n",
    "        for clf_name, param_grid in param_grids.items():\n",
    "            for params in param_grid:\n",
    "                pipeline = Pipeline([\n",
    "                    ('vectorizer', vector),\n",
    "                    ('classifier', None)  # Will be set by GridSearchCV\n",
    "                ])\n",
    "                \n",
    "                print(f\"Running GridSearch for {clf_name}...\")\n",
    "\n",
    "                # GridSearchCV with the classifier-specific parameters\n",
    "                grid_search = GridSearchCV(pipeline, params, cv=5, n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "                grid_search.fit(X_train, y_train)\n",
    "\n",
    "                # Collecting all combinations of parameters and scores\n",
    "                for param_combination, train_score, test_score in zip(grid_search.cv_results_['params'], \n",
    "                                                                      grid_search.cv_results_['mean_train_score'],\n",
    "                                                                      grid_search.cv_results_['mean_test_score']): \n",
    "\n",
    "                    tokenizer = param_combination.get('vectorizer__tokenizer', None)\n",
    "                    tokenizer_name = tokenizer.__name__ if callable(tokenizer) else 'NONE'\n",
    "                    \n",
    "                    if param_combination.get('vectorizer__token_pattern') == r'(?u)\\b[a-zA-Z]+\\b':\n",
    "                        pattern = 'Keep only alphabet'\n",
    "                    elif param_combination.get('vectorizer__token_pattern') == r'(?u)\\b[a-zA-Z0-9]+\\b':\n",
    "                        pattern = 'Keep numeric and alphabet'\n",
    "                    else:\n",
    "                        pattern = 'Keep all characters'\n",
    "                    \n",
    "                    results.append({\n",
    "                        'Classifier': clf_name,\n",
    "                        'Vectorizer': vector_name,\n",
    "                        'Tokenizer': tokenizer_name,\n",
    "                        'Max Features': param_combination.get('vectorizer__max_features', 'None'),\n",
    "                        'Ngram Range': param_combination.get('vectorizer__ngram_range', 'None'),\n",
    "                        'Lowercase': param_combination.get('vectorizer__lowercase', 'None'),\n",
    "                        'Min DF': param_combination.get('vectorizer__min_df', 'None'),\n",
    "                        'Max DF': param_combination.get('vectorizer__max_df', 'None'),\n",
    "                        'Token Pattern': pattern,\n",
    "                        'Train Score': train_score,\n",
    "                        'Test Score': test_score\n",
    "                    })\n",
    "    \n",
    "    # Convert the list of results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Time to take the model runs: {(end_time - start_time) / 60:.0f} minutes\")\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bb23c19a-d4c9-44ee-b0c7-ec3a10807893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearch for LogisticRegression...\n",
      "Running GridSearch for KNN...\n",
      "Running GridSearch for DecisionTree...\n",
      "Running GridSearch for BaggedDecisionTree...\n",
      "Running GridSearch for RandomForest...\n",
      "Running GridSearch for AdaBoost...\n",
      "Running GridSearch for GradientBoosting...\n",
      "Running GridSearch for XGBoost...\n",
      "Running GridSearch for SVM...\n",
      "Running GridSearch for Naive Bayes...\n",
      "Running GridSearch for LogisticRegression...\n",
      "Running GridSearch for KNN...\n",
      "Running GridSearch for DecisionTree...\n",
      "Running GridSearch for BaggedDecisionTree...\n",
      "Running GridSearch for RandomForest...\n",
      "Running GridSearch for AdaBoost...\n",
      "Running GridSearch for GradientBoosting...\n",
      "Running GridSearch for XGBoost...\n",
      "Running GridSearch for SVM...\n",
      "Running GridSearch for Naive Bayes...\n",
      "Time to take the model runs: 161 minutes\n"
     ]
    }
   ],
   "source": [
    "results_df = evaluate_models(X_train, y_train, defualt_param_grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "65a412ce-4742-4ee4-80b3-b1500da5b278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Tokenizer</th>\n",
       "      <th>Max Features</th>\n",
       "      <th>Ngram Range</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>Min DF</th>\n",
       "      <th>Max DF</th>\n",
       "      <th>Token Pattern</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>lemmatizer_tokenizer</td>\n",
       "      <td>3000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.651023</td>\n",
       "      <td>0.644973</td>\n",
       "      <td>0.006050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>lemmatizer_tokenizer</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.651023</td>\n",
       "      <td>0.644973</td>\n",
       "      <td>0.006050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>lemmatizer_tokenizer</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep only alphabet</td>\n",
       "      <td>0.651023</td>\n",
       "      <td>0.644973</td>\n",
       "      <td>0.006050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>lemmatizer_tokenizer</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.651023</td>\n",
       "      <td>0.644973</td>\n",
       "      <td>0.006050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>lemmatizer_tokenizer</td>\n",
       "      <td>3000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Keep only alphabet</td>\n",
       "      <td>0.651023</td>\n",
       "      <td>0.644973</td>\n",
       "      <td>0.006050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>lemmatizer_tokenizer</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.990900</td>\n",
       "      <td>0.617513</td>\n",
       "      <td>0.373387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>lemmatizer_tokenizer</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.988186</td>\n",
       "      <td>0.613038</td>\n",
       "      <td>0.375148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>lemmatizer_tokenizer</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Keep only alphabet</td>\n",
       "      <td>0.988186</td>\n",
       "      <td>0.612385</td>\n",
       "      <td>0.375801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>lemmatizer_tokenizer</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.988186</td>\n",
       "      <td>0.608577</td>\n",
       "      <td>0.379609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>stemmer_tokenizer</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.990581</td>\n",
       "      <td>0.610474</td>\n",
       "      <td>0.380107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3840 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Classifier       Vectorizer             Tokenizer  Max Features  \\\n",
       "965       AdaBoost  CountVectorizer  lemmatizer_tokenizer          3000   \n",
       "1001      AdaBoost  CountVectorizer  lemmatizer_tokenizer          5000   \n",
       "1004      AdaBoost  CountVectorizer  lemmatizer_tokenizer          5000   \n",
       "1049      AdaBoost  CountVectorizer  lemmatizer_tokenizer          5000   \n",
       "1010      AdaBoost  CountVectorizer  lemmatizer_tokenizer          3000   \n",
       "...            ...              ...                   ...           ...   \n",
       "467   DecisionTree  CountVectorizer  lemmatizer_tokenizer          5000   \n",
       "2435  DecisionTree  TfidfVectorizer  lemmatizer_tokenizer          5000   \n",
       "2474  DecisionTree  TfidfVectorizer  lemmatizer_tokenizer          5000   \n",
       "2483  DecisionTree  TfidfVectorizer  lemmatizer_tokenizer          5000   \n",
       "2380  DecisionTree  TfidfVectorizer     stemmer_tokenizer          5000   \n",
       "\n",
       "     Ngram Range  Lowercase  Min DF  Max DF              Token Pattern  \\\n",
       "965       (1, 2)       True       2     0.8  Keep numeric and alphabet   \n",
       "1001      (1, 2)       True       3     0.8  Keep numeric and alphabet   \n",
       "1004      (1, 1)       True       3     0.8         Keep only alphabet   \n",
       "1049      (1, 2)       True       3     0.9  Keep numeric and alphabet   \n",
       "1010      (1, 2)       True       2     0.9         Keep only alphabet   \n",
       "...          ...        ...     ...     ...                        ...   \n",
       "467       (1, 1)       True       2     0.9  Keep numeric and alphabet   \n",
       "2435      (1, 1)      False       2     0.8  Keep numeric and alphabet   \n",
       "2474      (1, 2)      False       2     0.9         Keep only alphabet   \n",
       "2483      (1, 1)      False       2     0.9  Keep numeric and alphabet   \n",
       "2380      (1, 2)       True       2     0.9  Keep numeric and alphabet   \n",
       "\n",
       "      Train Score  Test Score       gap  \n",
       "965      0.651023    0.644973  0.006050  \n",
       "1001     0.651023    0.644973  0.006050  \n",
       "1004     0.651023    0.644973  0.006050  \n",
       "1049     0.651023    0.644973  0.006050  \n",
       "1010     0.651023    0.644973  0.006050  \n",
       "...           ...         ...       ...  \n",
       "467      0.990900    0.617513  0.373387  \n",
       "2435     0.988186    0.613038  0.375148  \n",
       "2474     0.988186    0.612385  0.375801  \n",
       "2483     0.988186    0.608577  0.379609  \n",
       "2380     0.990581    0.610474  0.380107  \n",
       "\n",
       "[3840 rows x 12 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['gap'] = results_df['Train Score'] - results_df['Test Score']\n",
    "results_df.sort_values(by='gap', ascending = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6f62bdc4-2be3-496f-903a-5c1853348548",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('model_compare_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b29bc013-63da-46de-a93e-0f9bdbaa0cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Tokenizer</th>\n",
       "      <th>Max Features</th>\n",
       "      <th>Ngram Range</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>Min DF</th>\n",
       "      <th>Max DF</th>\n",
       "      <th>Token Pattern</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.993455</td>\n",
       "      <td>0.735016</td>\n",
       "      <td>0.258439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep only alphabet</td>\n",
       "      <td>0.828065</td>\n",
       "      <td>0.733748</td>\n",
       "      <td>0.094318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.862867</td>\n",
       "      <td>0.733740</td>\n",
       "      <td>0.129127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Keep only alphabet</td>\n",
       "      <td>0.863507</td>\n",
       "      <td>0.733732</td>\n",
       "      <td>0.129775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>3000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.824873</td>\n",
       "      <td>0.733105</td>\n",
       "      <td>0.091768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep only alphabet</td>\n",
       "      <td>0.826150</td>\n",
       "      <td>0.733105</td>\n",
       "      <td>0.093045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>3000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.993455</td>\n",
       "      <td>0.733093</td>\n",
       "      <td>0.260362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>3000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Keep only alphabet</td>\n",
       "      <td>0.826789</td>\n",
       "      <td>0.732466</td>\n",
       "      <td>0.094323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>3000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep only alphabet</td>\n",
       "      <td>0.866859</td>\n",
       "      <td>0.732464</td>\n",
       "      <td>0.134396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep only alphabet</td>\n",
       "      <td>0.827267</td>\n",
       "      <td>0.731829</td>\n",
       "      <td>0.095438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>3000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.827747</td>\n",
       "      <td>0.731192</td>\n",
       "      <td>0.096555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Keep only alphabet</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.731192</td>\n",
       "      <td>0.096394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.826151</td>\n",
       "      <td>0.731190</td>\n",
       "      <td>0.094962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>3000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Keep only alphabet</td>\n",
       "      <td>0.865263</td>\n",
       "      <td>0.731180</td>\n",
       "      <td>0.134083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.988186</td>\n",
       "      <td>0.731174</td>\n",
       "      <td>0.257013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep only alphabet</td>\n",
       "      <td>0.827428</td>\n",
       "      <td>0.730555</td>\n",
       "      <td>0.096873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>3000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.829025</td>\n",
       "      <td>0.730553</td>\n",
       "      <td>0.098472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>3000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.824553</td>\n",
       "      <td>0.730553</td>\n",
       "      <td>0.094001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>3000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Keep numeric and alphabet</td>\n",
       "      <td>0.829503</td>\n",
       "      <td>0.730551</td>\n",
       "      <td>0.098953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>NONE</td>\n",
       "      <td>3000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Keep only alphabet</td>\n",
       "      <td>0.864943</td>\n",
       "      <td>0.730547</td>\n",
       "      <td>0.134397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier       Vectorizer Tokenizer  Max Features Ngram Range  \\\n",
       "795       RandomForest  CountVectorizer      NONE          5000      (1, 2)   \n",
       "1182  GradientBoosting  CountVectorizer      NONE          5000      (1, 1)   \n",
       "3105  GradientBoosting  TfidfVectorizer      NONE          5000      (1, 1)   \n",
       "3156  GradientBoosting  TfidfVectorizer      NONE          5000      (1, 2)   \n",
       "1173  GradientBoosting  CountVectorizer      NONE          3000      (1, 1)   \n",
       "1194  GradientBoosting  CountVectorizer      NONE          5000      (1, 1)   \n",
       "777       RandomForest  CountVectorizer      NONE          3000      (1, 1)   \n",
       "1218  GradientBoosting  CountVectorizer      NONE          3000      (1, 1)   \n",
       "3084  GradientBoosting  TfidfVectorizer      NONE          3000      (1, 2)   \n",
       "1176  GradientBoosting  CountVectorizer      NONE          5000      (1, 2)   \n",
       "1161  GradientBoosting  CountVectorizer      NONE          3000      (1, 1)   \n",
       "1224  GradientBoosting  CountVectorizer      NONE          5000      (1, 2)   \n",
       "1239  GradientBoosting  CountVectorizer      NONE          5000      (1, 2)   \n",
       "3132  GradientBoosting  TfidfVectorizer      NONE          3000      (1, 2)   \n",
       "813       RandomForest  CountVectorizer      NONE          5000      (1, 1)   \n",
       "1188  GradientBoosting  CountVectorizer      NONE          5000      (1, 2)   \n",
       "1215  GradientBoosting  CountVectorizer      NONE          3000      (1, 2)   \n",
       "1209  GradientBoosting  CountVectorizer      NONE          3000      (1, 1)   \n",
       "1167  GradientBoosting  CountVectorizer      NONE          3000      (1, 2)   \n",
       "3120  GradientBoosting  TfidfVectorizer      NONE          3000      (1, 2)   \n",
       "\n",
       "      Lowercase  Min DF  Max DF              Token Pattern  Train Score  \\\n",
       "795        True       2     0.8  Keep numeric and alphabet     0.993455   \n",
       "1182       True       2     0.8         Keep only alphabet     0.828065   \n",
       "3105       True       2     0.8  Keep numeric and alphabet     0.862867   \n",
       "3156       True       3     0.9         Keep only alphabet     0.863507   \n",
       "1173       True       3     0.8  Keep numeric and alphabet     0.824873   \n",
       "1194       True       3     0.8         Keep only alphabet     0.826150   \n",
       "777        True       2     0.8  Keep numeric and alphabet     0.993455   \n",
       "1218       True       3     0.9         Keep only alphabet     0.826789   \n",
       "3084       True       3     0.8         Keep only alphabet     0.866859   \n",
       "1176       True       2     0.8         Keep only alphabet     0.827267   \n",
       "1161       True       2     0.8  Keep numeric and alphabet     0.827747   \n",
       "1224       True       2     0.9         Keep only alphabet     0.827586   \n",
       "1239       True       3     0.9  Keep numeric and alphabet     0.826151   \n",
       "3132       True       3     0.9         Keep only alphabet     0.865263   \n",
       "813        True       3     0.8  Keep numeric and alphabet     0.988186   \n",
       "1188       True       3     0.8         Keep only alphabet     0.827428   \n",
       "1215       True       3     0.9  Keep numeric and alphabet     0.829025   \n",
       "1209       True       2     0.9  Keep numeric and alphabet     0.824553   \n",
       "1167       True       3     0.8  Keep numeric and alphabet     0.829503   \n",
       "3120       True       2     0.9         Keep only alphabet     0.864943   \n",
       "\n",
       "      Test Score       gap  \n",
       "795     0.735016  0.258439  \n",
       "1182    0.733748  0.094318  \n",
       "3105    0.733740  0.129127  \n",
       "3156    0.733732  0.129775  \n",
       "1173    0.733105  0.091768  \n",
       "1194    0.733105  0.093045  \n",
       "777     0.733093  0.260362  \n",
       "1218    0.732466  0.094323  \n",
       "3084    0.732464  0.134396  \n",
       "1176    0.731829  0.095438  \n",
       "1161    0.731192  0.096555  \n",
       "1224    0.731192  0.096394  \n",
       "1239    0.731190  0.094962  \n",
       "3132    0.731180  0.134083  \n",
       "813     0.731174  0.257013  \n",
       "1188    0.730555  0.096873  \n",
       "1215    0.730553  0.098472  \n",
       "1209    0.730553  0.094001  \n",
       "1167    0.730551  0.098953  \n",
       "3120    0.730547  0.134397  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by = 'Test Score',ascending = False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
