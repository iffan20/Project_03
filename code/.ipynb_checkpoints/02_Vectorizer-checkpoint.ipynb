{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d3e456-2b0d-4cb2-8f77-e2745ae0d259",
   "metadata": {},
   "source": [
    "## ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Project 3: NLP Classification: Subreddit Pepsi vs Coca-Cola | Part 2: Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8fbe8-2a19-4381-a90d-89b96a000aa1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[README](../README.md) | [Part 1: EDA](01_EDA.ipynb) | **Part 2: Vectorizer** | [Part 3: xxx](03_Interpretation.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de04adb-b620-44a5-b8bf-ad5cd93340c9",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "From [Part 1: EDA](01_EDA.ipynb), we obtained `subreddit_pepsi_vs_cocacola.csv_clean`, which has been cleaned. In this part, we focus on tuning the hyperparameters of two vectorizers: **CountVectorizer** and **TfidfVectorizer**, while using default settings for the model. Our goal is to analyze how the hyperparameters of the vectorizers affect model performance.\n",
    "\n",
    "The **CountVectorizer** represents each document by the frequency of words (tokens) in the text. While **TfidfVectorizer** measures the relative importance of a word in a document by balancing its frequency in that document (Term Frequency) with how rare it is across all documents (Inverse Document Frequency). The latter vectorizer often provides better results, especially when distinguishing key terms in large corpora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa54522-c06f-4862-9cb7-7deb56fdab01",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ab99150-5149-48d3-ba8e-ba897db1f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP tools\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Model selection and evaluation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Time utility\n",
    "import time\n",
    "from joblib import parallel_backend\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27203691-7357-484e-ad9f-cc402b0a7c16",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8dcc06d-fd2a-41bb-95fa-9b42073babb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>is_pepsi</th>\n",
       "      <th>title_body</th>\n",
       "      <th>title_body_length</th>\n",
       "      <th>title_body_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall clock.</td>\n",
       "      <td>17</td>\n",
       "      <td>1godhom</td>\n",
       "      <td>https://www.reddit.com/gallery/1godhom</td>\n",
       "      <td>1</td>\n",
       "      <td>11/11/2024 5:58</td>\n",
       "      <td>I'm trying to locate a value for this clock. I...</td>\n",
       "      <td>0</td>\n",
       "      <td>Wall clock. I'm trying to locate a value for t...</td>\n",
       "      <td>220</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title  score       id                                     url  \\\n",
       "0  Wall clock.     17  1godhom  https://www.reddit.com/gallery/1godhom   \n",
       "\n",
       "   comms_num          created  \\\n",
       "0          1  11/11/2024 5:58   \n",
       "\n",
       "                                                body  is_pepsi  \\\n",
       "0  I'm trying to locate a value for this clock. I...         0   \n",
       "\n",
       "                                          title_body  title_body_length  \\\n",
       "0  Wall clock. I'm trying to locate a value for t...                220   \n",
       "\n",
       "   title_body_word_count  \n",
       "0                     39  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/subreddit_pepsi_vs_cocacola_clean.csv')          # Load Data\n",
    "df.head(1)                                                                 # Check first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c805ab9-f52e-4839-83da-640598d71232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1958, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0e734a8-cc68-476e-b862-2038e258823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Features and Target\n",
    "\n",
    "X = df['title_body']\n",
    "y = df['is_pepsi']\n",
    "\n",
    "# Split the data to training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X\n",
    "                                                    , y\n",
    "                                                    , test_size = 0.2\n",
    "                                                    , stratify = y\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f753cc5-f28f-4c2d-80e5-1fcb3a4da226",
   "metadata": {},
   "source": [
    "### Vectorizer\n",
    "- We focus on two types of vectorizers: **CountVectorizer** and **TfidfVectorizer**, which share the same set of parameters.\n",
    "- First, converting the text to lowercase and removing words related to **Pepsi** and **Coca-Cola** are mandatory steps.\n",
    "- The other parameters we will adjust for comparison are:\n",
    "    - Removes English Stopwords or not\n",
    "    - Maximum features: 3000, 5000, or None\n",
    "    - N-gram length: whether to include bigrams or not\n",
    "    - Minimum document frequency (min_df): 2, or 3\n",
    "    - Maximum document frequency (max_df): 0.8 or 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "428f3cf0-26e0-4063-a33e-1843f01a4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Related words are words that can easily identify the subreddit categories, \n",
    "# such as the names of brands.\n",
    "related_words = {'pepsi', 'pepsico', 'coca', 'cola', 'coke'}\n",
    "\n",
    "# Custom stop words are common English words that are meaningless, \n",
    "# and we also include related words to create a custom stop word list.\n",
    "\n",
    "custom_stop_words = set(stopwords.words('english')).union(related_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7458215b-a0f8-4296-8938-d43bb02c3368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Stemmer and Lemmatizer\n",
    "stemmer = nltk.PorterStemmer()\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "# Create 6 custom tokenizers. \n",
    "# Note that all tokenizers are designed to remove symbols, related words, and convert text to lowercase, \n",
    "# with the following additional functions:\n",
    "# - lower_only: no other changes\n",
    "# - lower_stop: removes stopwords\n",
    "# - stem_only: applies stemming\n",
    "# - stem_stop: applies stemming and removes stopwords\n",
    "# - lem_only: applies lemmatizing\n",
    "# - lem_stop: applies lemmatizing and removes stopwords\n",
    "\n",
    "def lower_only(doc):\n",
    "    doc = doc.lower()\n",
    "    tokens = word_tokenize(doc)\n",
    "    return [token for token in tokens if token not in related_words and token.isalpha()]\n",
    "\n",
    "def lower_stop(doc):\n",
    "    doc = doc.lower()\n",
    "    tokens = word_tokenize(doc)\n",
    "    return [token for token in tokens if token not in custom_stop_words and token.isalpha()]\n",
    "\n",
    "def stem_only(doc):\n",
    "    doc = doc.lower()\n",
    "    tokens = word_tokenize(doc)\n",
    "    return [stemmer.stem(token) for token in tokens if token not in related_words and token.isalpha()]\n",
    "\n",
    "def stem_stop(doc):\n",
    "    doc = doc.lower()\n",
    "    tokens = word_tokenize(doc)\n",
    "    return [stemmer.stem(token) for token in tokens if token not in custom_stop_words and token.isalpha()]\n",
    "\n",
    "def lem_only(doc):\n",
    "    doc = doc.lower()\n",
    "    tokens = word_tokenize(doc)\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens if token not in related_words and token.isalpha()]\n",
    "\n",
    "def lem_stop(doc):\n",
    "    doc = doc.lower()\n",
    "    tokens = word_tokenize(doc)\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens if token not in custom_stop_words and token.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31fa89e2-f5d6-41c2-9357-da8f05e4b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metrics used in GridSearch results\n",
    "scorers = {\n",
    "    'accuracy': make_scorer(accuracy_score)\n",
    "    , 'recall': make_scorer(recall_score, average = 'binary')\n",
    "    , 'precision': make_scorer(precision_score, average = 'binary')\n",
    "    , 'f1': make_scorer(f1_score, average = 'binary')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dcab4fe-7978-4a89-922f-1979845f6980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch parameters\n",
    "# 'vectorizer__' is used to set parameters for CountVectorizer and TfidfVectorizer.\n",
    "# Since the tokenizer parameter is applied, we set 'token_pattern' to None.\n",
    "params = {\n",
    "    'vectorizer': [CountVectorizer(token_pattern = None)\n",
    "                   , TfidfVectorizer(token_pattern = None)\n",
    "                  ] \n",
    "    , 'vectorizer__tokenizer': [lower_only\n",
    "                                , lower_stop\n",
    "                                , stem_only\n",
    "                                , stem_stop\n",
    "                                , lem_only\n",
    "                                , lem_stop\n",
    "                               ] \n",
    "    , 'vectorizer__max_features': [3000\n",
    "                                   , 5000\n",
    "                                   , None\n",
    "                                  ]\n",
    "    , 'vectorizer__ngram_range': [(1, 1)                  # unigrams\n",
    "                                  , (1, 2)                # unigrams and bigrams\n",
    "                                 ]\n",
    "    , 'vectorizer__min_df': [2, 3]\n",
    "    , 'vectorizer__max_df': [0.8, 0.9]\n",
    "    , 'classifier': [#MultinomialNB()\n",
    "                     #, LogisticRegression()\n",
    "                     #, KNeighborsClassifier()\n",
    "                     #, DecisionTreeClassifier()\n",
    "                     #, BaggingClassifier()\n",
    "                     #, RandomForestClassifier()\n",
    "                     #, AdaBoostClassifier(algorithm = 'SAMME')\n",
    "                     #, GradientBoostingClassifier()\n",
    "                     #, SVC()\n",
    "                      XGBClassifier()\n",
    "                    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3207930a-6a3b-435a-9af0-f574147bc7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer())                    # Will replace in GridSearch  \n",
    "    , ('classifier', MultinomialNB())                    # Will replace in GridSearch \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af9a41e7-03a5-4951-927f-53ac0df2831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline\n",
    "                           , param_grid=params\n",
    "                           , cv = 5\n",
    "                           , verbose = 3\n",
    "                           , scoring = scorers\n",
    "                           , refit = 'f1'\n",
    "                           , return_train_score = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a6134b7-5675-4235-a450-c90e41c808fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.650) f1: (train=0.920, test=0.669) precision: (train=0.881, test=0.645) recall: (train=0.962, test=0.694) total time=  10.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.875, test=0.643) f1: (train=0.884, test=0.673) precision: (train=0.839, test=0.632) recall: (train=0.934, test=0.719) total time=  10.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.919, test=0.655) f1: (train=0.924, test=0.682) precision: (train=0.886, test=0.641) recall: (train=0.965, test=0.730) total time=  11.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.629) f1: (train=0.882, test=0.663) precision: (train=0.835, test=0.616) recall: (train=0.936, test=0.717) total time=  11.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.865, test=0.658) f1: (train=0.876, test=0.693) precision: (train=0.823, test=0.637) recall: (train=0.936, test=0.761) total time=  11.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.917, test=0.629) f1: (train=0.922, test=0.669) precision: (train=0.887, test=0.613) recall: (train=0.959, test=0.736) total time=  11.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.918, test=0.620) f1: (train=0.923, test=0.629) precision: (train=0.881, test=0.623) recall: (train=0.969, test=0.635) total time=  13.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.913, test=0.687) f1: (train=0.918, test=0.710) precision: (train=0.882, test=0.670) recall: (train=0.958, test=0.755) total time=  14.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.674) f1: (train=0.879, test=0.703) precision: (train=0.827, test=0.654) recall: (train=0.937, test=0.761) total time=  20.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.867, test=0.712) f1: (train=0.875, test=0.732) precision: (train=0.835, test=0.695) recall: (train=0.920, test=0.774) total time=  21.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.921, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.889, test=0.652) recall: (train=0.965, test=0.730) total time=  24.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.926, test=0.709) f1: (train=0.929, test=0.722) precision: (train=0.900, test=0.702) recall: (train=0.961, test=0.742) total time=  27.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.653) f1: (train=0.887, test=0.686) precision: (train=0.845, test=0.636) recall: (train=0.934, test=0.744) total time=  23.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.922, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.897, test=0.652) recall: (train=0.956, test=0.730) total time=  27.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.929, test=0.659) f1: (train=0.933, test=0.684) precision: (train=0.897, test=0.648) recall: (train=0.972, test=0.725) total time=  26.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.919, test=0.620) f1: (train=0.923, test=0.653) precision: (train=0.893, test=0.609) recall: (train=0.956, test=0.704) total time=  26.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=nan, test=nan) f1: (train=nan, test=nan) precision: (train=nan, test=nan) recall: (train=nan, test=nan) total time=  19.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=nan, test=nan) f1: (train=nan, test=nan) precision: (train=nan, test=nan) recall: (train=nan, test=nan) total time=  19.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=nan, test=nan) f1: (train=nan, test=nan) precision: (train=nan, test=nan) recall: (train=nan, test=nan) total time=  21.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.649) f1: (train=0.888, test=0.682) precision: (train=0.847, test=0.631) recall: (train=0.932, test=0.742) total time=  35.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.665) f1: (train=0.886, test=0.692) precision: (train=0.842, test=0.648) recall: (train=0.936, test=0.742) total time=  36.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.877, test=0.658) f1: (train=0.885, test=0.684) precision: (train=0.843, test=0.644) recall: (train=0.932, test=0.730) total time=  34.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.706) f1: (train=0.885, test=0.718) precision: (train=0.849, test=0.701) recall: (train=0.925, test=0.736) total time=  34.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.922, test=0.607) f1: (train=0.926, test=0.643) precision: (train=0.893, test=0.597) recall: (train=0.961, test=0.698) total time=  42.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.877, test=0.671) f1: (train=0.885, test=0.701) precision: (train=0.842, test=0.651) recall: (train=0.934, test=0.761) total time=  19.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.879, test=0.650) f1: (train=0.886, test=0.682) precision: (train=0.846, test=0.634) recall: (train=0.931, test=0.738) total time=  21.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.658) f1: (train=0.927, test=0.686) precision: (train=0.890, test=0.643) recall: (train=0.967, test=0.736) total time=  22.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.870, test=0.665) f1: (train=0.880, test=0.696) precision: (train=0.830, test=0.645) recall: (train=0.936, test=0.755) total time=  20.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.875, test=0.709) f1: (train=0.883, test=0.730) precision: (train=0.843, test=0.691) recall: (train=0.926, test=0.774) total time=  22.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.872, test=0.681) f1: (train=0.882, test=0.711) precision: (train=0.833, test=0.658) recall: (train=0.937, test=0.774) total time=  18.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.923, test=0.646) f1: (train=0.927, test=0.671) precision: (train=0.888, test=0.638) recall: (train=0.970, test=0.706) total time=  19.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.671) f1: (train=0.930, test=0.681) precision: (train=0.892, test=0.671) recall: (train=0.972, test=0.692) total time=  16.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.629) f1: (train=0.920, test=0.669) precision: (train=0.877, test=0.613) recall: (train=0.967, test=0.736) total time=  16.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.922, test=0.684) f1: (train=0.926, test=0.706) precision: (train=0.888, test=0.669) recall: (train=0.969, test=0.748) total time=  16.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.658) f1: (train=0.930, test=0.702) precision: (train=0.890, test=0.630) recall: (train=0.975, test=0.792) total time=  12.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.879, test=0.640) f1: (train=0.888, test=0.672) precision: (train=0.843, test=0.627) recall: (train=0.937, test=0.725) total time=  15.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.642) f1: (train=0.883, test=0.676) precision: (train=0.831, test=0.626) recall: (train=0.942, test=0.736) total time=  16.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.658) f1: (train=0.877, test=0.690) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.748) total time=  29.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.862, test=0.712) f1: (train=0.872, test=0.731) precision: (train=0.827, test=0.697) recall: (train=0.922, test=0.767) total time=  30.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.872, test=0.677) f1: (train=0.881, test=0.706) precision: (train=0.831, test=0.658) recall: (train=0.939, test=0.761) total time=  25.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.931, test=0.678) f1: (train=0.935, test=0.702) precision: (train=0.895, test=0.665) recall: (train=0.980, test=0.744) total time=  33.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.928, test=0.681) f1: (train=0.932, test=0.693) precision: (train=0.895, test=0.677) recall: (train=0.973, test=0.711) total time=  32.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.925, test=0.636) f1: (train=0.929, test=0.665) precision: (train=0.893, test=0.624) recall: (train=0.969, test=0.711) total time=  32.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.927, test=0.700) f1: (train=0.931, test=0.712) precision: (train=0.893, test=0.695) recall: (train=0.972, test=0.730) total time=  34.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.924, test=0.639) f1: (train=0.929, test=0.674) precision: (train=0.888, test=0.622) recall: (train=0.973, test=0.736) total time=  37.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.643) f1: (train=0.887, test=0.678) precision: (train=0.845, test=0.628) recall: (train=0.934, test=0.738) total time=  38.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.883, test=0.652) f1: (train=0.891, test=0.686) precision: (train=0.842, test=0.633) recall: (train=0.947, test=0.748) total time=  33.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.703) f1: (train=0.888, test=0.727) precision: (train=0.846, test=0.681) recall: (train=0.934, test=0.780) total time=  39.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.653) f1: (train=0.934, test=0.671) precision: (train=0.895, test=0.649) recall: (train=0.976, test=0.694) total time=  26.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.874, test=0.700) f1: (train=0.882, test=0.715) precision: (train=0.843, test=0.690) recall: (train=0.925, test=0.742) total time=  28.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.658) f1: (train=0.933, test=0.667) precision: (train=0.902, test=0.660) recall: (train=0.967, test=0.673) total time=  27.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.668) f1: (train=0.888, test=0.692) precision: (train=0.845, test=0.654) recall: (train=0.936, test=0.736) total time=  29.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.928, test=0.607) f1: (train=0.932, test=0.635) precision: (train=0.897, test=0.601) recall: (train=0.970, test=0.673) total time=  26.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.693) f1: (train=0.927, test=0.709) precision: (train=0.892, test=0.684) recall: (train=0.964, test=0.736) total time=  25.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.883, test=0.634) f1: (train=0.891, test=0.667) precision: (train=0.844, test=0.622) recall: (train=0.943, test=0.719) total time=  23.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.661) f1: (train=0.927, test=0.694) precision: (train=0.886, test=0.642) recall: (train=0.973, test=0.755) total time=  25.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.868, test=0.661) f1: (train=0.877, test=0.695) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.761) total time=  18.4s[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.876, test=0.661) f1: (train=0.884, test=0.695) precision: (train=0.843, test=0.640) recall: (train=0.929, test=0.761) total time=  18.1s\n",
      "\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.873, test=0.725) f1: (train=0.881, test=0.741) precision: (train=0.844, test=0.711) recall: (train=0.920, test=0.774) total time=  20.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.878, test=0.668) f1: (train=0.887, test=0.698) precision: (train=0.835, test=0.649) recall: (train=0.947, test=0.755) total time=  18.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.650) f1: (train=0.920, test=0.669) precision: (train=0.881, test=0.645) recall: (train=0.962, test=0.694) total time=  17.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.918, test=0.620) f1: (train=0.923, test=0.629) precision: (train=0.881, test=0.623) recall: (train=0.969, test=0.635) total time=  15.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.917, test=0.629) f1: (train=0.922, test=0.669) precision: (train=0.887, test=0.613) recall: (train=0.959, test=0.736) total time=  15.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.913, test=0.687) f1: (train=0.918, test=0.710) precision: (train=0.882, test=0.670) recall: (train=0.958, test=0.755) total time=  14.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.919, test=0.655) f1: (train=0.924, test=0.682) precision: (train=0.886, test=0.641) recall: (train=0.965, test=0.730) total time=  18.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.875, test=0.643) f1: (train=0.884, test=0.673) precision: (train=0.839, test=0.632) recall: (train=0.934, test=0.719) total time=  18.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.867, test=0.712) f1: (train=0.875, test=0.732) precision: (train=0.835, test=0.695) recall: (train=0.920, test=0.774) total time=  17.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.629) f1: (train=0.882, test=0.663) precision: (train=0.835, test=0.616) recall: (train=0.936, test=0.717) total time=  18.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.865, test=0.658) f1: (train=0.876, test=0.693) precision: (train=0.823, test=0.637) recall: (train=0.936, test=0.761) total time=  18.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.674) f1: (train=0.879, test=0.703) precision: (train=0.827, test=0.654) recall: (train=0.937, test=0.761) total time=  17.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.929, test=0.659) f1: (train=0.933, test=0.684) precision: (train=0.897, test=0.648) recall: (train=0.972, test=0.725) total time=  28.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.922, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.897, test=0.652) recall: (train=0.956, test=0.730) total time=  28.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.653) f1: (train=0.887, test=0.686) precision: (train=0.845, test=0.636) recall: (train=0.934, test=0.744) total time=  29.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.919, test=0.620) f1: (train=0.923, test=0.653) precision: (train=0.893, test=0.609) recall: (train=0.956, test=0.704) total time=  34.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.665) f1: (train=0.886, test=0.692) precision: (train=0.842, test=0.648) recall: (train=0.936, test=0.742) total time=  32.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.926, test=0.709) f1: (train=0.929, test=0.722) precision: (train=0.900, test=0.702) recall: (train=0.961, test=0.742) total time=  36.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.921, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.889, test=0.652) recall: (train=0.965, test=0.730) total time=  35.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.649) f1: (train=0.888, test=0.682) precision: (train=0.847, test=0.631) recall: (train=0.932, test=0.742) total time=  31.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.877, test=0.658) f1: (train=0.885, test=0.684) precision: (train=0.843, test=0.644) recall: (train=0.932, test=0.730) total time=  34.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.706) f1: (train=0.885, test=0.718) precision: (train=0.849, test=0.701) recall: (train=0.925, test=0.736) total time=  34.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.653) f1: (train=0.927, test=0.675) precision: (train=0.894, test=0.646) recall: (train=0.964, test=0.706) total time=  22.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.919, test=0.642) f1: (train=0.924, test=0.663) precision: (train=0.879, test=0.636) recall: (train=0.973, test=0.692) total time=  20.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.922, test=0.607) f1: (train=0.926, test=0.643) precision: (train=0.893, test=0.597) recall: (train=0.961, test=0.698) total time=  20.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.658) f1: (train=0.927, test=0.686) precision: (train=0.890, test=0.643) recall: (train=0.967, test=0.736) total time=  21.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.932, test=0.687) f1: (train=0.935, test=0.698) precision: (train=0.907, test=0.685) recall: (train=0.965, test=0.711) total time=  21.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.879, test=0.650) f1: (train=0.886, test=0.682) precision: (train=0.846, test=0.634) recall: (train=0.931, test=0.738) total time=  18.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.877, test=0.671) f1: (train=0.885, test=0.701) precision: (train=0.842, test=0.651) recall: (train=0.934, test=0.761) total time=  18.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.870, test=0.665) f1: (train=0.880, test=0.696) precision: (train=0.830, test=0.645) recall: (train=0.936, test=0.755) total time=  24.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.671) f1: (train=0.930, test=0.681) precision: (train=0.892, test=0.671) recall: (train=0.972, test=0.692) total time=  14.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.872, test=0.681) f1: (train=0.882, test=0.711) precision: (train=0.833, test=0.658) recall: (train=0.937, test=0.774) total time=  15.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.923, test=0.646) f1: (train=0.927, test=0.671) precision: (train=0.888, test=0.638) recall: (train=0.970, test=0.706) total time=  16.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.875, test=0.709) f1: (train=0.883, test=0.730) precision: (train=0.843, test=0.691) recall: (train=0.926, test=0.774) total time=  15.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.629) f1: (train=0.920, test=0.669) precision: (train=0.877, test=0.613) recall: (train=0.967, test=0.736) total time=  16.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.922, test=0.684) f1: (train=0.926, test=0.706) precision: (train=0.888, test=0.669) recall: (train=0.969, test=0.748) total time=  15.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.658) f1: (train=0.930, test=0.702) precision: (train=0.890, test=0.630) recall: (train=0.975, test=0.792) total time=  14.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.879, test=0.640) f1: (train=0.888, test=0.672) precision: (train=0.843, test=0.627) recall: (train=0.937, test=0.725) total time=  17.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.658) f1: (train=0.877, test=0.690) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.748) total time=  23.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.642) f1: (train=0.883, test=0.676) precision: (train=0.831, test=0.626) recall: (train=0.942, test=0.736) total time=  22.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.872, test=0.677) f1: (train=0.881, test=0.706) precision: (train=0.831, test=0.658) recall: (train=0.939, test=0.761) total time=  22.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.862, test=0.712) f1: (train=0.872, test=0.731) precision: (train=0.827, test=0.697) recall: (train=0.922, test=0.767) total time=  23.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.928, test=0.681) f1: (train=0.932, test=0.693) precision: (train=0.895, test=0.677) recall: (train=0.973, test=0.711) total time=  32.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.931, test=0.678) f1: (train=0.935, test=0.702) precision: (train=0.895, test=0.665) recall: (train=0.980, test=0.744) total time=  36.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.925, test=0.636) f1: (train=0.929, test=0.665) precision: (train=0.893, test=0.624) recall: (train=0.969, test=0.711) total time=  36.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.927, test=0.700) f1: (train=0.931, test=0.712) precision: (train=0.893, test=0.695) recall: (train=0.972, test=0.730) total time=  31.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.643) f1: (train=0.887, test=0.678) precision: (train=0.845, test=0.628) recall: (train=0.934, test=0.738) total time=  27.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.883, test=0.652) f1: (train=0.891, test=0.686) precision: (train=0.842, test=0.633) recall: (train=0.947, test=0.748) total time=  27.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.703) f1: (train=0.888, test=0.727) precision: (train=0.846, test=0.681) recall: (train=0.934, test=0.780) total time=  29.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.924, test=0.639) f1: (train=0.929, test=0.674) precision: (train=0.888, test=0.622) recall: (train=0.973, test=0.736) total time=  33.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.874, test=0.700) f1: (train=0.882, test=0.715) precision: (train=0.843, test=0.690) recall: (train=0.925, test=0.742) total time=  23.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.653) f1: (train=0.934, test=0.671) precision: (train=0.895, test=0.649) recall: (train=0.976, test=0.694) total time=  18.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.668) f1: (train=0.888, test=0.692) precision: (train=0.845, test=0.654) recall: (train=0.936, test=0.736) total time=  25.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.658) f1: (train=0.933, test=0.667) precision: (train=0.902, test=0.660) recall: (train=0.967, test=0.673) total time=  19.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.928, test=0.607) f1: (train=0.932, test=0.635) precision: (train=0.897, test=0.601) recall: (train=0.970, test=0.673) total time=  15.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.693) f1: (train=0.927, test=0.709) precision: (train=0.892, test=0.684) recall: (train=0.964, test=0.736) total time=  17.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.661) f1: (train=0.927, test=0.694) precision: (train=0.886, test=0.642) recall: (train=0.973, test=0.755) total time=  16.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.883, test=0.634) f1: (train=0.891, test=0.667) precision: (train=0.844, test=0.622) recall: (train=0.943, test=0.719) total time=  18.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.876, test=0.661) f1: (train=0.884, test=0.695) precision: (train=0.843, test=0.640) recall: (train=0.929, test=0.761) total time=  14.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.868, test=0.661) f1: (train=0.877, test=0.695) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.761) total time=  12.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.873, test=0.725) f1: (train=0.881, test=0.741) precision: (train=0.844, test=0.711) recall: (train=0.920, test=0.774) total time=  14.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.878, test=0.668) f1: (train=0.887, test=0.698) precision: (train=0.835, test=0.649) recall: (train=0.947, test=0.755) total time=  11.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.650) f1: (train=0.920, test=0.669) precision: (train=0.881, test=0.645) recall: (train=0.962, test=0.694) total time=  10.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.918, test=0.620) f1: (train=0.923, test=0.629) precision: (train=0.881, test=0.623) recall: (train=0.969, test=0.635) total time=  10.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.917, test=0.629) f1: (train=0.922, test=0.669) precision: (train=0.887, test=0.613) recall: (train=0.959, test=0.736) total time=  10.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.913, test=0.687) f1: (train=0.918, test=0.710) precision: (train=0.882, test=0.670) recall: (train=0.958, test=0.755) total time=   9.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.919, test=0.655) f1: (train=0.924, test=0.682) precision: (train=0.886, test=0.641) recall: (train=0.965, test=0.730) total time=  12.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.875, test=0.643) f1: (train=0.884, test=0.673) precision: (train=0.839, test=0.632) recall: (train=0.934, test=0.719) total time=  12.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.629) f1: (train=0.882, test=0.663) precision: (train=0.835, test=0.616) recall: (train=0.936, test=0.717) total time=  11.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.865, test=0.658) f1: (train=0.876, test=0.693) precision: (train=0.823, test=0.637) recall: (train=0.936, test=0.761) total time=  14.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.867, test=0.712) f1: (train=0.875, test=0.732) precision: (train=0.835, test=0.695) recall: (train=0.920, test=0.774) total time=  15.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.674) f1: (train=0.879, test=0.703) precision: (train=0.827, test=0.654) recall: (train=0.937, test=0.761) total time=  14.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.922, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.897, test=0.652) recall: (train=0.956, test=0.730) total time=  19.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.929, test=0.659) f1: (train=0.933, test=0.684) precision: (train=0.897, test=0.648) recall: (train=0.972, test=0.725) total time=  20.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.919, test=0.620) f1: (train=0.923, test=0.653) precision: (train=0.893, test=0.609) recall: (train=0.956, test=0.704) total time=  23.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.926, test=0.709) f1: (train=0.929, test=0.722) precision: (train=0.900, test=0.702) recall: (train=0.961, test=0.742) total time=  27.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.653) f1: (train=0.887, test=0.686) precision: (train=0.845, test=0.636) recall: (train=0.934, test=0.744) total time=  24.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.921, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.889, test=0.652) recall: (train=0.965, test=0.730) total time=  28.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.649) f1: (train=0.888, test=0.682) precision: (train=0.847, test=0.631) recall: (train=0.932, test=0.742) total time=  23.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.665) f1: (train=0.886, test=0.692) precision: (train=0.842, test=0.648) recall: (train=0.936, test=0.742) total time=  23.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.706) f1: (train=0.885, test=0.718) precision: (train=0.849, test=0.701) recall: (train=0.925, test=0.736) total time=  22.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.877, test=0.658) f1: (train=0.885, test=0.684) precision: (train=0.843, test=0.644) recall: (train=0.932, test=0.730) total time=  22.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.653) f1: (train=0.927, test=0.675) precision: (train=0.894, test=0.646) recall: (train=0.964, test=0.706) total time=  20.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.919, test=0.642) f1: (train=0.924, test=0.663) precision: (train=0.879, test=0.636) recall: (train=0.973, test=0.692) total time=  18.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.932, test=0.687) f1: (train=0.935, test=0.698) precision: (train=0.907, test=0.685) recall: (train=0.965, test=0.711) total time=  15.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.879, test=0.650) f1: (train=0.886, test=0.682) precision: (train=0.846, test=0.634) recall: (train=0.931, test=0.738) total time=  12.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.658) f1: (train=0.927, test=0.686) precision: (train=0.890, test=0.643) recall: (train=0.967, test=0.736) total time=  13.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.922, test=0.607) f1: (train=0.926, test=0.643) precision: (train=0.893, test=0.597) recall: (train=0.961, test=0.698) total time=  16.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.870, test=0.665) f1: (train=0.880, test=0.696) precision: (train=0.830, test=0.645) recall: (train=0.936, test=0.755) total time=  12.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.877, test=0.671) f1: (train=0.885, test=0.701) precision: (train=0.842, test=0.651) recall: (train=0.934, test=0.761) total time=  12.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.875, test=0.709) f1: (train=0.883, test=0.730) precision: (train=0.843, test=0.691) recall: (train=0.926, test=0.774) total time=  14.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.872, test=0.681) f1: (train=0.882, test=0.711) precision: (train=0.833, test=0.658) recall: (train=0.937, test=0.774) total time=  12.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.923, test=0.646) f1: (train=0.927, test=0.671) precision: (train=0.888, test=0.638) recall: (train=0.970, test=0.706) total time=  11.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.671) f1: (train=0.930, test=0.681) precision: (train=0.892, test=0.671) recall: (train=0.972, test=0.692) total time=  11.8s[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.629) f1: (train=0.920, test=0.669) precision: (train=0.877, test=0.613) recall: (train=0.967, test=0.736) total time=  11.2s\n",
      "\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.922, test=0.684) f1: (train=0.926, test=0.706) precision: (train=0.888, test=0.669) recall: (train=0.969, test=0.748) total time=  12.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.879, test=0.640) f1: (train=0.888, test=0.672) precision: (train=0.843, test=0.627) recall: (train=0.937, test=0.725) total time=  10.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.658) f1: (train=0.930, test=0.702) precision: (train=0.890, test=0.630) recall: (train=0.975, test=0.792) total time=  10.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.642) f1: (train=0.883, test=0.676) precision: (train=0.831, test=0.626) recall: (train=0.942, test=0.736) total time=  10.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.658) f1: (train=0.877, test=0.690) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.748) total time=  13.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.862, test=0.712) f1: (train=0.872, test=0.731) precision: (train=0.827, test=0.697) recall: (train=0.922, test=0.767) total time=  18.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.872, test=0.677) f1: (train=0.881, test=0.706) precision: (train=0.831, test=0.658) recall: (train=0.939, test=0.761) total time=  17.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.931, test=0.678) f1: (train=0.935, test=0.702) precision: (train=0.895, test=0.665) recall: (train=0.980, test=0.744) total time=  21.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.928, test=0.681) f1: (train=0.932, test=0.693) precision: (train=0.895, test=0.677) recall: (train=0.973, test=0.711) total time=  22.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.925, test=0.636) f1: (train=0.929, test=0.665) precision: (train=0.893, test=0.624) recall: (train=0.969, test=0.711) total time=  22.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.927, test=0.700) f1: (train=0.931, test=0.712) precision: (train=0.893, test=0.695) recall: (train=0.972, test=0.730) total time=  22.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.643) f1: (train=0.887, test=0.678) precision: (train=0.845, test=0.628) recall: (train=0.934, test=0.738) total time=  20.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.924, test=0.639) f1: (train=0.929, test=0.674) precision: (train=0.888, test=0.622) recall: (train=0.973, test=0.736) total time=  23.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.703) f1: (train=0.888, test=0.727) precision: (train=0.846, test=0.681) recall: (train=0.934, test=0.780) total time=  30.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.883, test=0.652) f1: (train=0.891, test=0.686) precision: (train=0.842, test=0.633) recall: (train=0.947, test=0.748) total time=  28.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.653) f1: (train=0.934, test=0.671) precision: (train=0.895, test=0.649) recall: (train=0.976, test=0.694) total time=  17.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.874, test=0.700) f1: (train=0.882, test=0.715) precision: (train=0.843, test=0.690) recall: (train=0.925, test=0.742) total time=  19.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.668) f1: (train=0.888, test=0.692) precision: (train=0.845, test=0.654) recall: (train=0.936, test=0.736) total time=  17.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.658) f1: (train=0.933, test=0.667) precision: (train=0.902, test=0.660) recall: (train=0.967, test=0.673) total time=  17.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.928, test=0.607) f1: (train=0.932, test=0.635) precision: (train=0.897, test=0.601) recall: (train=0.970, test=0.673) total time=  16.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.693) f1: (train=0.927, test=0.709) precision: (train=0.892, test=0.684) recall: (train=0.964, test=0.736) total time=  19.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.661) f1: (train=0.927, test=0.694) precision: (train=0.886, test=0.642) recall: (train=0.973, test=0.755) total time=  20.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.883, test=0.634) f1: (train=0.891, test=0.667) precision: (train=0.844, test=0.622) recall: (train=0.943, test=0.719) total time=  16.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.876, test=0.661) f1: (train=0.884, test=0.695) precision: (train=0.843, test=0.640) recall: (train=0.929, test=0.761) total time=  11.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.918, test=0.620) f1: (train=0.923, test=0.629) precision: (train=0.881, test=0.623) recall: (train=0.969, test=0.635) total time=   9.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.868, test=0.661) f1: (train=0.877, test=0.695) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.761) total time=  12.0s[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.650) f1: (train=0.920, test=0.669) precision: (train=0.881, test=0.645) recall: (train=0.962, test=0.694) total time=  10.9s\n",
      "\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.873, test=0.725) f1: (train=0.881, test=0.741) precision: (train=0.844, test=0.711) recall: (train=0.920, test=0.774) total time=  11.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.878, test=0.668) f1: (train=0.887, test=0.698) precision: (train=0.835, test=0.649) recall: (train=0.947, test=0.755) total time=  11.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.917, test=0.629) f1: (train=0.922, test=0.669) precision: (train=0.887, test=0.613) recall: (train=0.959, test=0.736) total time=  10.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.913, test=0.687) f1: (train=0.918, test=0.710) precision: (train=0.882, test=0.670) recall: (train=0.958, test=0.755) total time=  12.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.919, test=0.655) f1: (train=0.924, test=0.682) precision: (train=0.886, test=0.641) recall: (train=0.965, test=0.730) total time=  11.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.875, test=0.643) f1: (train=0.884, test=0.673) precision: (train=0.839, test=0.632) recall: (train=0.934, test=0.719) total time=  12.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.674) f1: (train=0.879, test=0.703) precision: (train=0.827, test=0.654) recall: (train=0.937, test=0.761) total time=  11.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.629) f1: (train=0.882, test=0.663) precision: (train=0.835, test=0.616) recall: (train=0.936, test=0.717) total time=  13.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.865, test=0.658) f1: (train=0.876, test=0.693) precision: (train=0.823, test=0.637) recall: (train=0.936, test=0.761) total time=  12.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.867, test=0.712) f1: (train=0.875, test=0.732) precision: (train=0.835, test=0.695) recall: (train=0.920, test=0.774) total time=  12.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.929, test=0.659) f1: (train=0.933, test=0.684) precision: (train=0.897, test=0.648) recall: (train=0.972, test=0.725) total time=  24.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.922, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.897, test=0.652) recall: (train=0.956, test=0.730) total time=  24.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.653) f1: (train=0.887, test=0.686) precision: (train=0.845, test=0.636) recall: (train=0.934, test=0.744) total time=  19.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.921, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.889, test=0.652) recall: (train=0.965, test=0.730) total time=  23.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.665) f1: (train=0.886, test=0.692) precision: (train=0.842, test=0.648) recall: (train=0.936, test=0.742) total time=  21.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.926, test=0.709) f1: (train=0.929, test=0.722) precision: (train=0.900, test=0.702) recall: (train=0.961, test=0.742) total time=  22.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.919, test=0.620) f1: (train=0.923, test=0.653) precision: (train=0.893, test=0.609) recall: (train=0.956, test=0.704) total time=  24.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.649) f1: (train=0.888, test=0.682) precision: (train=0.847, test=0.631) recall: (train=0.932, test=0.742) total time=  22.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.706) f1: (train=0.885, test=0.718) precision: (train=0.849, test=0.701) recall: (train=0.925, test=0.736) total time=  25.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.877, test=0.658) f1: (train=0.885, test=0.684) precision: (train=0.843, test=0.644) recall: (train=0.932, test=0.730) total time=  16.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.653) f1: (train=0.927, test=0.675) precision: (train=0.894, test=0.646) recall: (train=0.964, test=0.706) total time=  14.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.932, test=0.687) f1: (train=0.935, test=0.698) precision: (train=0.907, test=0.685) recall: (train=0.965, test=0.711) total time=  14.1s[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.919, test=0.642) f1: (train=0.924, test=0.663) precision: (train=0.879, test=0.636) recall: (train=0.973, test=0.692) total time=  14.5s\n",
      "\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.879, test=0.650) f1: (train=0.886, test=0.682) precision: (train=0.846, test=0.634) recall: (train=0.931, test=0.738) total time=  13.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.922, test=0.607) f1: (train=0.926, test=0.643) precision: (train=0.893, test=0.597) recall: (train=0.961, test=0.698) total time=  15.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.658) f1: (train=0.927, test=0.686) precision: (train=0.890, test=0.643) recall: (train=0.967, test=0.736) total time=  15.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.877, test=0.671) f1: (train=0.885, test=0.701) precision: (train=0.842, test=0.651) recall: (train=0.934, test=0.761) total time=  17.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.870, test=0.665) f1: (train=0.880, test=0.696) precision: (train=0.830, test=0.645) recall: (train=0.936, test=0.755) total time=  13.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.875, test=0.709) f1: (train=0.883, test=0.730) precision: (train=0.843, test=0.691) recall: (train=0.926, test=0.774) total time=  10.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.872, test=0.681) f1: (train=0.882, test=0.711) precision: (train=0.833, test=0.658) recall: (train=0.937, test=0.774) total time=  12.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.923, test=0.646) f1: (train=0.927, test=0.671) precision: (train=0.888, test=0.638) recall: (train=0.970, test=0.706) total time=  12.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.671) f1: (train=0.930, test=0.681) precision: (train=0.892, test=0.671) recall: (train=0.972, test=0.692) total time=  12.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.629) f1: (train=0.920, test=0.669) precision: (train=0.877, test=0.613) recall: (train=0.967, test=0.736) total time=  10.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.922, test=0.684) f1: (train=0.926, test=0.706) precision: (train=0.888, test=0.669) recall: (train=0.969, test=0.748) total time=  11.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.658) f1: (train=0.930, test=0.702) precision: (train=0.890, test=0.630) recall: (train=0.975, test=0.792) total time=  11.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.879, test=0.640) f1: (train=0.888, test=0.672) precision: (train=0.843, test=0.627) recall: (train=0.937, test=0.725) total time=  16.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.642) f1: (train=0.883, test=0.676) precision: (train=0.831, test=0.626) recall: (train=0.942, test=0.736) total time=  14.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.862, test=0.712) f1: (train=0.872, test=0.731) precision: (train=0.827, test=0.697) recall: (train=0.922, test=0.767) total time=  14.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.658) f1: (train=0.877, test=0.690) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.748) total time=  16.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.872, test=0.677) f1: (train=0.881, test=0.706) precision: (train=0.831, test=0.658) recall: (train=0.939, test=0.761) total time=  14.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.931, test=0.678) f1: (train=0.935, test=0.702) precision: (train=0.895, test=0.665) recall: (train=0.980, test=0.744) total time=  18.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.928, test=0.681) f1: (train=0.932, test=0.693) precision: (train=0.895, test=0.677) recall: (train=0.973, test=0.711) total time=  23.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.925, test=0.636) f1: (train=0.929, test=0.665) precision: (train=0.893, test=0.624) recall: (train=0.969, test=0.711) total time=  26.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.927, test=0.700) f1: (train=0.931, test=0.712) precision: (train=0.893, test=0.695) recall: (train=0.972, test=0.730) total time=  26.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.703) f1: (train=0.888, test=0.727) precision: (train=0.846, test=0.681) recall: (train=0.934, test=0.780) total time=  26.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.643) f1: (train=0.887, test=0.678) precision: (train=0.845, test=0.628) recall: (train=0.934, test=0.738) total time=  24.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.924, test=0.639) f1: (train=0.929, test=0.674) precision: (train=0.888, test=0.622) recall: (train=0.973, test=0.736) total time=  26.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.883, test=0.652) f1: (train=0.891, test=0.686) precision: (train=0.842, test=0.633) recall: (train=0.947, test=0.748) total time=  26.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.874, test=0.700) f1: (train=0.882, test=0.715) precision: (train=0.843, test=0.690) recall: (train=0.925, test=0.742) total time=  26.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.668) f1: (train=0.888, test=0.692) precision: (train=0.845, test=0.654) recall: (train=0.936, test=0.736) total time=  26.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.653) f1: (train=0.934, test=0.671) precision: (train=0.895, test=0.649) recall: (train=0.976, test=0.694) total time=  20.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.658) f1: (train=0.933, test=0.667) precision: (train=0.902, test=0.660) recall: (train=0.967, test=0.673) total time=  16.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.928, test=0.607) f1: (train=0.932, test=0.635) precision: (train=0.897, test=0.601) recall: (train=0.970, test=0.673) total time=  15.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.661) f1: (train=0.927, test=0.694) precision: (train=0.886, test=0.642) recall: (train=0.973, test=0.755) total time=  14.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.693) f1: (train=0.927, test=0.709) precision: (train=0.892, test=0.684) recall: (train=0.964, test=0.736) total time=  14.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.883, test=0.634) f1: (train=0.891, test=0.667) precision: (train=0.844, test=0.622) recall: (train=0.943, test=0.719) total time=  17.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.876, test=0.661) f1: (train=0.884, test=0.695) precision: (train=0.843, test=0.640) recall: (train=0.929, test=0.761) total time=  15.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.868, test=0.661) f1: (train=0.877, test=0.695) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.761) total time=  14.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.873, test=0.725) f1: (train=0.881, test=0.741) precision: (train=0.844, test=0.711) recall: (train=0.920, test=0.774) total time=  10.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.918, test=0.620) f1: (train=0.923, test=0.629) precision: (train=0.881, test=0.623) recall: (train=0.969, test=0.635) total time=   9.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.878, test=0.668) f1: (train=0.887, test=0.698) precision: (train=0.835, test=0.649) recall: (train=0.947, test=0.755) total time=  10.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.650) f1: (train=0.920, test=0.669) precision: (train=0.881, test=0.645) recall: (train=0.962, test=0.694) total time=  11.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.917, test=0.629) f1: (train=0.922, test=0.669) precision: (train=0.887, test=0.613) recall: (train=0.959, test=0.736) total time=  11.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.913, test=0.687) f1: (train=0.918, test=0.710) precision: (train=0.882, test=0.670) recall: (train=0.958, test=0.755) total time=  11.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.919, test=0.655) f1: (train=0.924, test=0.682) precision: (train=0.886, test=0.641) recall: (train=0.965, test=0.730) total time=  10.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.875, test=0.643) f1: (train=0.884, test=0.673) precision: (train=0.839, test=0.632) recall: (train=0.934, test=0.719) total time=  10.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.629) f1: (train=0.882, test=0.663) precision: (train=0.835, test=0.616) recall: (train=0.936, test=0.717) total time=  15.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.674) f1: (train=0.879, test=0.703) precision: (train=0.827, test=0.654) recall: (train=0.937, test=0.761) total time=  14.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.867, test=0.712) f1: (train=0.875, test=0.732) precision: (train=0.835, test=0.695) recall: (train=0.920, test=0.774) total time=  15.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.865, test=0.658) f1: (train=0.876, test=0.693) precision: (train=0.823, test=0.637) recall: (train=0.936, test=0.761) total time=  14.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.929, test=0.659) f1: (train=0.933, test=0.684) precision: (train=0.897, test=0.648) recall: (train=0.972, test=0.725) total time=  18.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.922, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.897, test=0.652) recall: (train=0.956, test=0.730) total time=  19.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.919, test=0.620) f1: (train=0.923, test=0.653) precision: (train=0.893, test=0.609) recall: (train=0.956, test=0.704) total time=  23.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.926, test=0.709) f1: (train=0.929, test=0.722) precision: (train=0.900, test=0.702) recall: (train=0.961, test=0.742) total time=  24.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.653) f1: (train=0.887, test=0.686) precision: (train=0.845, test=0.636) recall: (train=0.934, test=0.744) total time=  22.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.921, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.889, test=0.652) recall: (train=0.965, test=0.730) total time=  25.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.665) f1: (train=0.886, test=0.692) precision: (train=0.842, test=0.648) recall: (train=0.936, test=0.742) total time=  25.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.649) f1: (train=0.888, test=0.682) precision: (train=0.847, test=0.631) recall: (train=0.932, test=0.742) total time=  27.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.706) f1: (train=0.885, test=0.718) precision: (train=0.849, test=0.701) recall: (train=0.925, test=0.736) total time=  21.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.877, test=0.658) f1: (train=0.885, test=0.684) precision: (train=0.843, test=0.644) recall: (train=0.932, test=0.730) total time=  22.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.919, test=0.642) f1: (train=0.924, test=0.663) precision: (train=0.879, test=0.636) recall: (train=0.973, test=0.692) total time=  19.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.653) f1: (train=0.927, test=0.675) precision: (train=0.894, test=0.646) recall: (train=0.964, test=0.706) total time=  20.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.932, test=0.687) f1: (train=0.935, test=0.698) precision: (train=0.907, test=0.685) recall: (train=0.965, test=0.711) total time=  15.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.922, test=0.607) f1: (train=0.926, test=0.643) precision: (train=0.893, test=0.597) recall: (train=0.961, test=0.698) total time=  15.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.658) f1: (train=0.927, test=0.686) precision: (train=0.890, test=0.643) recall: (train=0.967, test=0.736) total time=  16.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.879, test=0.650) f1: (train=0.886, test=0.682) precision: (train=0.846, test=0.634) recall: (train=0.931, test=0.738) total time=  17.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.877, test=0.671) f1: (train=0.885, test=0.701) precision: (train=0.842, test=0.651) recall: (train=0.934, test=0.761) total time=  13.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.870, test=0.665) f1: (train=0.880, test=0.696) precision: (train=0.830, test=0.645) recall: (train=0.936, test=0.755) total time=  13.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.875, test=0.709) f1: (train=0.883, test=0.730) precision: (train=0.843, test=0.691) recall: (train=0.926, test=0.774) total time=  14.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.872, test=0.681) f1: (train=0.882, test=0.711) precision: (train=0.833, test=0.658) recall: (train=0.937, test=0.774) total time=  13.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.923, test=0.646) f1: (train=0.927, test=0.671) precision: (train=0.888, test=0.638) recall: (train=0.970, test=0.706) total time=   9.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.629) f1: (train=0.920, test=0.669) precision: (train=0.877, test=0.613) recall: (train=0.967, test=0.736) total time=  10.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.671) f1: (train=0.930, test=0.681) precision: (train=0.892, test=0.671) recall: (train=0.972, test=0.692) total time=  11.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.922, test=0.684) f1: (train=0.926, test=0.706) precision: (train=0.888, test=0.669) recall: (train=0.969, test=0.748) total time=  12.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.658) f1: (train=0.930, test=0.702) precision: (train=0.890, test=0.630) recall: (train=0.975, test=0.792) total time=  13.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.879, test=0.640) f1: (train=0.888, test=0.672) precision: (train=0.843, test=0.627) recall: (train=0.937, test=0.725) total time=  14.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.642) f1: (train=0.883, test=0.676) precision: (train=0.831, test=0.626) recall: (train=0.942, test=0.736) total time=  13.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.658) f1: (train=0.877, test=0.690) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.748) total time=  12.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.862, test=0.712) f1: (train=0.872, test=0.731) precision: (train=0.827, test=0.697) recall: (train=0.922, test=0.767) total time=  11.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.872, test=0.677) f1: (train=0.881, test=0.706) precision: (train=0.831, test=0.658) recall: (train=0.939, test=0.761) total time=  13.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.931, test=0.678) f1: (train=0.935, test=0.702) precision: (train=0.895, test=0.665) recall: (train=0.980, test=0.744) total time=  22.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.928, test=0.681) f1: (train=0.932, test=0.693) precision: (train=0.895, test=0.677) recall: (train=0.973, test=0.711) total time=  25.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.925, test=0.636) f1: (train=0.929, test=0.665) precision: (train=0.893, test=0.624) recall: (train=0.969, test=0.711) total time=  23.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.643) f1: (train=0.887, test=0.678) precision: (train=0.845, test=0.628) recall: (train=0.934, test=0.738) total time=  23.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.924, test=0.639) f1: (train=0.929, test=0.674) precision: (train=0.888, test=0.622) recall: (train=0.973, test=0.736) total time=  26.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.703) f1: (train=0.888, test=0.727) precision: (train=0.846, test=0.681) recall: (train=0.934, test=0.780) total time=  23.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.927, test=0.700) f1: (train=0.931, test=0.712) precision: (train=0.893, test=0.695) recall: (train=0.972, test=0.730) total time=  26.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.883, test=0.652) f1: (train=0.891, test=0.686) precision: (train=0.842, test=0.633) recall: (train=0.947, test=0.748) total time=  25.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.874, test=0.700) f1: (train=0.882, test=0.715) precision: (train=0.843, test=0.690) recall: (train=0.925, test=0.742) total time=  27.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.668) f1: (train=0.888, test=0.692) precision: (train=0.845, test=0.654) recall: (train=0.936, test=0.736) total time=  23.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.653) f1: (train=0.934, test=0.671) precision: (train=0.895, test=0.649) recall: (train=0.976, test=0.694) total time=  16.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.658) f1: (train=0.933, test=0.667) precision: (train=0.902, test=0.660) recall: (train=0.967, test=0.673) total time=  17.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.693) f1: (train=0.927, test=0.709) precision: (train=0.892, test=0.684) recall: (train=0.964, test=0.736) total time=  17.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.928, test=0.607) f1: (train=0.932, test=0.635) precision: (train=0.897, test=0.601) recall: (train=0.970, test=0.673) total time=  17.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.661) f1: (train=0.927, test=0.694) precision: (train=0.886, test=0.642) recall: (train=0.973, test=0.755) total time=  17.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.883, test=0.634) f1: (train=0.891, test=0.667) precision: (train=0.844, test=0.622) recall: (train=0.943, test=0.719) total time=  14.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.876, test=0.661) f1: (train=0.884, test=0.695) precision: (train=0.843, test=0.640) recall: (train=0.929, test=0.761) total time=  16.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.868, test=0.661) f1: (train=0.877, test=0.695) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.761) total time=  14.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.873, test=0.725) f1: (train=0.881, test=0.741) precision: (train=0.844, test=0.711) recall: (train=0.920, test=0.774) total time=  12.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.650) f1: (train=0.920, test=0.669) precision: (train=0.881, test=0.645) recall: (train=0.962, test=0.694) total time=   8.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.878, test=0.668) f1: (train=0.887, test=0.698) precision: (train=0.835, test=0.649) recall: (train=0.947, test=0.755) total time=  10.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.913, test=0.687) f1: (train=0.918, test=0.710) precision: (train=0.882, test=0.670) recall: (train=0.958, test=0.755) total time=   8.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.918, test=0.620) f1: (train=0.923, test=0.629) precision: (train=0.881, test=0.623) recall: (train=0.969, test=0.635) total time=  10.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.917, test=0.629) f1: (train=0.922, test=0.669) precision: (train=0.887, test=0.613) recall: (train=0.959, test=0.736) total time=  10.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.919, test=0.655) f1: (train=0.924, test=0.682) precision: (train=0.886, test=0.641) recall: (train=0.965, test=0.730) total time=   9.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.875, test=0.643) f1: (train=0.884, test=0.673) precision: (train=0.839, test=0.632) recall: (train=0.934, test=0.719) total time=  13.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.865, test=0.658) f1: (train=0.876, test=0.693) precision: (train=0.823, test=0.637) recall: (train=0.936, test=0.761) total time=  14.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.629) f1: (train=0.882, test=0.663) precision: (train=0.835, test=0.616) recall: (train=0.936, test=0.717) total time=  14.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.867, test=0.712) f1: (train=0.875, test=0.732) precision: (train=0.835, test=0.695) recall: (train=0.920, test=0.774) total time=  14.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.674) f1: (train=0.879, test=0.703) precision: (train=0.827, test=0.654) recall: (train=0.937, test=0.761) total time=  13.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.929, test=0.659) f1: (train=0.933, test=0.684) precision: (train=0.897, test=0.648) recall: (train=0.972, test=0.725) total time=  18.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.922, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.897, test=0.652) recall: (train=0.956, test=0.730) total time=  21.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.919, test=0.620) f1: (train=0.923, test=0.653) precision: (train=0.893, test=0.609) recall: (train=0.956, test=0.704) total time=  18.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.926, test=0.709) f1: (train=0.929, test=0.722) precision: (train=0.900, test=0.702) recall: (train=0.961, test=0.742) total time=  23.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.653) f1: (train=0.887, test=0.686) precision: (train=0.845, test=0.636) recall: (train=0.934, test=0.744) total time=  24.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.665) f1: (train=0.886, test=0.692) precision: (train=0.842, test=0.648) recall: (train=0.936, test=0.742) total time=  25.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.921, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.889, test=0.652) recall: (train=0.965, test=0.730) total time=  29.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.649) f1: (train=0.888, test=0.682) precision: (train=0.847, test=0.631) recall: (train=0.932, test=0.742) total time=  24.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.653) f1: (train=0.927, test=0.675) precision: (train=0.894, test=0.646) recall: (train=0.964, test=0.706) total time=  18.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.706) f1: (train=0.885, test=0.718) precision: (train=0.849, test=0.701) recall: (train=0.925, test=0.736) total time=  21.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.877, test=0.658) f1: (train=0.885, test=0.684) precision: (train=0.843, test=0.644) recall: (train=0.932, test=0.730) total time=  21.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.919, test=0.642) f1: (train=0.924, test=0.663) precision: (train=0.879, test=0.636) recall: (train=0.973, test=0.692) total time=  20.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.922, test=0.607) f1: (train=0.926, test=0.643) precision: (train=0.893, test=0.597) recall: (train=0.961, test=0.698) total time=  16.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.932, test=0.687) f1: (train=0.935, test=0.698) precision: (train=0.907, test=0.685) recall: (train=0.965, test=0.711) total time=  14.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.879, test=0.650) f1: (train=0.886, test=0.682) precision: (train=0.846, test=0.634) recall: (train=0.931, test=0.738) total time=  14.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.658) f1: (train=0.927, test=0.686) precision: (train=0.890, test=0.643) recall: (train=0.967, test=0.736) total time=  15.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.877, test=0.671) f1: (train=0.885, test=0.701) precision: (train=0.842, test=0.651) recall: (train=0.934, test=0.761) total time=  10.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.870, test=0.665) f1: (train=0.880, test=0.696) precision: (train=0.830, test=0.645) recall: (train=0.936, test=0.755) total time=  12.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.875, test=0.709) f1: (train=0.883, test=0.730) precision: (train=0.843, test=0.691) recall: (train=0.926, test=0.774) total time=  13.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.872, test=0.681) f1: (train=0.882, test=0.711) precision: (train=0.833, test=0.658) recall: (train=0.937, test=0.774) total time=  15.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.923, test=0.646) f1: (train=0.927, test=0.671) precision: (train=0.888, test=0.638) recall: (train=0.970, test=0.706) total time=  14.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.671) f1: (train=0.930, test=0.681) precision: (train=0.892, test=0.671) recall: (train=0.972, test=0.692) total time=  12.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.629) f1: (train=0.920, test=0.669) precision: (train=0.877, test=0.613) recall: (train=0.967, test=0.736) total time=  12.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.922, test=0.684) f1: (train=0.926, test=0.706) precision: (train=0.888, test=0.669) recall: (train=0.969, test=0.748) total time=  12.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.658) f1: (train=0.930, test=0.702) precision: (train=0.890, test=0.630) recall: (train=0.975, test=0.792) total time=  11.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.879, test=0.640) f1: (train=0.888, test=0.672) precision: (train=0.843, test=0.627) recall: (train=0.937, test=0.725) total time=  10.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.642) f1: (train=0.883, test=0.676) precision: (train=0.831, test=0.626) recall: (train=0.942, test=0.736) total time=   9.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.658) f1: (train=0.877, test=0.690) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.748) total time=  11.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.862, test=0.712) f1: (train=0.872, test=0.731) precision: (train=0.827, test=0.697) recall: (train=0.922, test=0.767) total time=  14.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.872, test=0.677) f1: (train=0.881, test=0.706) precision: (train=0.831, test=0.658) recall: (train=0.939, test=0.761) total time=  20.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.931, test=0.678) f1: (train=0.935, test=0.702) precision: (train=0.895, test=0.665) recall: (train=0.980, test=0.744) total time=  23.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.928, test=0.681) f1: (train=0.932, test=0.693) precision: (train=0.895, test=0.677) recall: (train=0.973, test=0.711) total time=  22.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.927, test=0.700) f1: (train=0.931, test=0.712) precision: (train=0.893, test=0.695) recall: (train=0.972, test=0.730) total time=  23.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.643) f1: (train=0.887, test=0.678) precision: (train=0.845, test=0.628) recall: (train=0.934, test=0.738) total time=  20.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.925, test=0.636) f1: (train=0.929, test=0.665) precision: (train=0.893, test=0.624) recall: (train=0.969, test=0.711) total time=  24.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.924, test=0.639) f1: (train=0.929, test=0.674) precision: (train=0.888, test=0.622) recall: (train=0.973, test=0.736) total time=  24.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.703) f1: (train=0.888, test=0.727) precision: (train=0.846, test=0.681) recall: (train=0.934, test=0.780) total time=  24.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.883, test=0.652) f1: (train=0.891, test=0.686) precision: (train=0.842, test=0.633) recall: (train=0.947, test=0.748) total time=  31.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.653) f1: (train=0.934, test=0.671) precision: (train=0.895, test=0.649) recall: (train=0.976, test=0.694) total time=  14.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.668) f1: (train=0.888, test=0.692) precision: (train=0.845, test=0.654) recall: (train=0.936, test=0.736) total time=  17.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.928, test=0.607) f1: (train=0.932, test=0.635) precision: (train=0.897, test=0.601) recall: (train=0.970, test=0.673) total time=  13.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.658) f1: (train=0.933, test=0.667) precision: (train=0.902, test=0.660) recall: (train=0.967, test=0.673) total time=  16.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.874, test=0.700) f1: (train=0.882, test=0.715) precision: (train=0.843, test=0.690) recall: (train=0.925, test=0.742) total time=  19.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.693) f1: (train=0.927, test=0.709) precision: (train=0.892, test=0.684) recall: (train=0.964, test=0.736) total time=  16.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.883, test=0.634) f1: (train=0.891, test=0.667) precision: (train=0.844, test=0.622) recall: (train=0.943, test=0.719) total time=  13.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.661) f1: (train=0.927, test=0.694) precision: (train=0.886, test=0.642) recall: (train=0.973, test=0.755) total time=  16.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.878, test=0.668) f1: (train=0.887, test=0.698) precision: (train=0.835, test=0.649) recall: (train=0.947, test=0.755) total time=  10.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.873, test=0.725) f1: (train=0.881, test=0.741) precision: (train=0.844, test=0.711) recall: (train=0.920, test=0.774) total time=  11.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.876, test=0.661) f1: (train=0.884, test=0.695) precision: (train=0.843, test=0.640) recall: (train=0.929, test=0.761) total time=  11.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.650) f1: (train=0.920, test=0.669) precision: (train=0.881, test=0.645) recall: (train=0.962, test=0.694) total time=   8.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.868, test=0.661) f1: (train=0.877, test=0.695) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.761) total time=  10.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.918, test=0.620) f1: (train=0.923, test=0.629) precision: (train=0.881, test=0.623) recall: (train=0.969, test=0.635) total time=   6.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.917, test=0.629) f1: (train=0.922, test=0.669) precision: (train=0.887, test=0.613) recall: (train=0.959, test=0.736) total time=   9.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.913, test=0.687) f1: (train=0.918, test=0.710) precision: (train=0.882, test=0.670) recall: (train=0.958, test=0.755) total time=   9.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.629) f1: (train=0.882, test=0.663) precision: (train=0.835, test=0.616) recall: (train=0.936, test=0.717) total time=   8.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.674) f1: (train=0.879, test=0.703) precision: (train=0.827, test=0.654) recall: (train=0.937, test=0.761) total time=  11.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.875, test=0.643) f1: (train=0.884, test=0.673) precision: (train=0.839, test=0.632) recall: (train=0.934, test=0.719) total time=  11.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.867, test=0.712) f1: (train=0.875, test=0.732) precision: (train=0.835, test=0.695) recall: (train=0.920, test=0.774) total time=  11.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.865, test=0.658) f1: (train=0.876, test=0.693) precision: (train=0.823, test=0.637) recall: (train=0.936, test=0.761) total time=  10.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.919, test=0.655) f1: (train=0.924, test=0.682) precision: (train=0.886, test=0.641) recall: (train=0.965, test=0.730) total time=  10.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.922, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.897, test=0.652) recall: (train=0.956, test=0.730) total time=  14.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.929, test=0.659) f1: (train=0.933, test=0.684) precision: (train=0.897, test=0.648) recall: (train=0.972, test=0.725) total time=  14.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.649) f1: (train=0.888, test=0.682) precision: (train=0.847, test=0.631) recall: (train=0.932, test=0.742) total time=  21.0s[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.926, test=0.709) f1: (train=0.929, test=0.722) precision: (train=0.900, test=0.702) recall: (train=0.961, test=0.742) total time=  24.5s\n",
      "\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.919, test=0.620) f1: (train=0.923, test=0.653) precision: (train=0.893, test=0.609) recall: (train=0.956, test=0.704) total time=  24.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.653) f1: (train=0.887, test=0.686) precision: (train=0.845, test=0.636) recall: (train=0.934, test=0.744) total time=  23.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.665) f1: (train=0.886, test=0.692) precision: (train=0.842, test=0.648) recall: (train=0.936, test=0.742) total time=  22.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.921, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.889, test=0.652) recall: (train=0.965, test=0.730) total time=  23.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.706) f1: (train=0.885, test=0.718) precision: (train=0.849, test=0.701) recall: (train=0.925, test=0.736) total time=  17.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.877, test=0.658) f1: (train=0.885, test=0.684) precision: (train=0.843, test=0.644) recall: (train=0.932, test=0.730) total time=  20.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.653) f1: (train=0.927, test=0.675) precision: (train=0.894, test=0.646) recall: (train=0.964, test=0.706) total time=  10.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.919, test=0.642) f1: (train=0.924, test=0.663) precision: (train=0.879, test=0.636) recall: (train=0.973, test=0.692) total time=  11.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.870, test=0.665) f1: (train=0.880, test=0.696) precision: (train=0.830, test=0.645) recall: (train=0.936, test=0.755) total time=  10.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.922, test=0.607) f1: (train=0.926, test=0.643) precision: (train=0.893, test=0.597) recall: (train=0.961, test=0.698) total time=  14.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.879, test=0.650) f1: (train=0.886, test=0.682) precision: (train=0.846, test=0.634) recall: (train=0.931, test=0.738) total time=  11.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.658) f1: (train=0.927, test=0.686) precision: (train=0.890, test=0.643) recall: (train=0.967, test=0.736) total time=  12.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.932, test=0.687) f1: (train=0.935, test=0.698) precision: (train=0.907, test=0.685) recall: (train=0.965, test=0.711) total time=  13.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.877, test=0.671) f1: (train=0.885, test=0.701) precision: (train=0.842, test=0.651) recall: (train=0.934, test=0.761) total time=   8.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.875, test=0.709) f1: (train=0.883, test=0.730) precision: (train=0.843, test=0.691) recall: (train=0.926, test=0.774) total time=   8.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.872, test=0.681) f1: (train=0.882, test=0.711) precision: (train=0.833, test=0.658) recall: (train=0.937, test=0.774) total time=   8.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.629) f1: (train=0.920, test=0.669) precision: (train=0.877, test=0.613) recall: (train=0.967, test=0.736) total time=   8.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.879, test=0.640) f1: (train=0.888, test=0.672) precision: (train=0.843, test=0.627) recall: (train=0.937, test=0.725) total time=   9.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.922, test=0.684) f1: (train=0.926, test=0.706) precision: (train=0.888, test=0.669) recall: (train=0.969, test=0.748) total time=   9.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.923, test=0.646) f1: (train=0.927, test=0.671) precision: (train=0.888, test=0.638) recall: (train=0.970, test=0.706) total time=  10.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.671) f1: (train=0.930, test=0.681) precision: (train=0.892, test=0.671) recall: (train=0.972, test=0.692) total time=  10.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.658) f1: (train=0.930, test=0.702) precision: (train=0.890, test=0.630) recall: (train=0.975, test=0.792) total time=   9.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.642) f1: (train=0.883, test=0.676) precision: (train=0.831, test=0.626) recall: (train=0.942, test=0.736) total time=  19.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.658) f1: (train=0.877, test=0.690) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.748) total time=  17.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.872, test=0.677) f1: (train=0.881, test=0.706) precision: (train=0.831, test=0.658) recall: (train=0.939, test=0.761) total time=  17.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.862, test=0.712) f1: (train=0.872, test=0.731) precision: (train=0.827, test=0.697) recall: (train=0.922, test=0.767) total time=  17.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.925, test=0.636) f1: (train=0.929, test=0.665) precision: (train=0.893, test=0.624) recall: (train=0.969, test=0.711) total time=  22.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.928, test=0.681) f1: (train=0.932, test=0.693) precision: (train=0.895, test=0.677) recall: (train=0.973, test=0.711) total time=  21.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.931, test=0.678) f1: (train=0.935, test=0.702) precision: (train=0.895, test=0.665) recall: (train=0.980, test=0.744) total time=  21.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.927, test=0.700) f1: (train=0.931, test=0.712) precision: (train=0.893, test=0.695) recall: (train=0.972, test=0.730) total time=  20.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.924, test=0.639) f1: (train=0.929, test=0.674) precision: (train=0.888, test=0.622) recall: (train=0.973, test=0.736) total time=  29.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.643) f1: (train=0.887, test=0.678) precision: (train=0.845, test=0.628) recall: (train=0.934, test=0.738) total time=  25.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.703) f1: (train=0.888, test=0.727) precision: (train=0.846, test=0.681) recall: (train=0.934, test=0.780) total time=  26.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.883, test=0.652) f1: (train=0.891, test=0.686) precision: (train=0.842, test=0.633) recall: (train=0.947, test=0.748) total time=  24.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.668) f1: (train=0.888, test=0.692) precision: (train=0.845, test=0.654) recall: (train=0.936, test=0.736) total time=  22.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.653) f1: (train=0.934, test=0.671) precision: (train=0.895, test=0.649) recall: (train=0.976, test=0.694) total time=  16.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.874, test=0.700) f1: (train=0.882, test=0.715) precision: (train=0.843, test=0.690) recall: (train=0.925, test=0.742) total time=  22.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.658) f1: (train=0.933, test=0.667) precision: (train=0.902, test=0.660) recall: (train=0.967, test=0.673) total time=  23.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.693) f1: (train=0.927, test=0.709) precision: (train=0.892, test=0.684) recall: (train=0.964, test=0.736) total time=  17.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.928, test=0.607) f1: (train=0.932, test=0.635) precision: (train=0.897, test=0.601) recall: (train=0.970, test=0.673) total time=  19.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.661) f1: (train=0.927, test=0.694) precision: (train=0.886, test=0.642) recall: (train=0.973, test=0.755) total time=  13.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.876, test=0.661) f1: (train=0.884, test=0.695) precision: (train=0.843, test=0.640) recall: (train=0.929, test=0.761) total time=  13.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.868, test=0.661) f1: (train=0.877, test=0.695) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.761) total time=  13.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.883, test=0.634) f1: (train=0.891, test=0.667) precision: (train=0.844, test=0.622) recall: (train=0.943, test=0.719) total time=  14.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.878, test=0.668) f1: (train=0.887, test=0.698) precision: (train=0.835, test=0.649) recall: (train=0.947, test=0.755) total time=  12.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.873, test=0.725) f1: (train=0.881, test=0.741) precision: (train=0.844, test=0.711) recall: (train=0.920, test=0.774) total time=  12.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.650) f1: (train=0.920, test=0.669) precision: (train=0.881, test=0.645) recall: (train=0.962, test=0.694) total time=  13.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.918, test=0.620) f1: (train=0.923, test=0.629) precision: (train=0.881, test=0.623) recall: (train=0.969, test=0.635) total time=  12.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.917, test=0.629) f1: (train=0.922, test=0.669) precision: (train=0.887, test=0.613) recall: (train=0.959, test=0.736) total time=   9.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.913, test=0.687) f1: (train=0.918, test=0.710) precision: (train=0.882, test=0.670) recall: (train=0.958, test=0.755) total time=   9.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.919, test=0.655) f1: (train=0.924, test=0.682) precision: (train=0.886, test=0.641) recall: (train=0.965, test=0.730) total time=   8.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.875, test=0.643) f1: (train=0.884, test=0.673) precision: (train=0.839, test=0.632) recall: (train=0.934, test=0.719) total time=   8.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.629) f1: (train=0.882, test=0.663) precision: (train=0.835, test=0.616) recall: (train=0.936, test=0.717) total time=   8.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.865, test=0.658) f1: (train=0.876, test=0.693) precision: (train=0.823, test=0.637) recall: (train=0.936, test=0.761) total time=   9.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.867, test=0.712) f1: (train=0.875, test=0.732) precision: (train=0.835, test=0.695) recall: (train=0.920, test=0.774) total time=   7.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.674) f1: (train=0.879, test=0.703) precision: (train=0.827, test=0.654) recall: (train=0.937, test=0.761) total time=  10.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.922, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.897, test=0.652) recall: (train=0.956, test=0.730) total time=  19.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.929, test=0.659) f1: (train=0.933, test=0.684) precision: (train=0.897, test=0.648) recall: (train=0.972, test=0.725) total time=  20.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.926, test=0.709) f1: (train=0.929, test=0.722) precision: (train=0.900, test=0.702) recall: (train=0.961, test=0.742) total time=  23.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.653) f1: (train=0.887, test=0.686) precision: (train=0.845, test=0.636) recall: (train=0.934, test=0.744) total time=  19.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.649) f1: (train=0.888, test=0.682) precision: (train=0.847, test=0.631) recall: (train=0.932, test=0.742) total time=  15.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.919, test=0.620) f1: (train=0.923, test=0.653) precision: (train=0.893, test=0.609) recall: (train=0.956, test=0.704) total time=  23.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.921, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.889, test=0.652) recall: (train=0.965, test=0.730) total time=  24.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.665) f1: (train=0.886, test=0.692) precision: (train=0.842, test=0.648) recall: (train=0.936, test=0.742) total time=  19.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.877, test=0.658) f1: (train=0.885, test=0.684) precision: (train=0.843, test=0.644) recall: (train=0.932, test=0.730) total time=  16.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.706) f1: (train=0.885, test=0.718) precision: (train=0.849, test=0.701) recall: (train=0.925, test=0.736) total time=  19.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.932, test=0.687) f1: (train=0.935, test=0.698) precision: (train=0.907, test=0.685) recall: (train=0.965, test=0.711) total time=  12.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.879, test=0.650) f1: (train=0.886, test=0.682) precision: (train=0.846, test=0.634) recall: (train=0.931, test=0.738) total time=   9.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.658) f1: (train=0.927, test=0.686) precision: (train=0.890, test=0.643) recall: (train=0.967, test=0.736) total time=  12.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.653) f1: (train=0.927, test=0.675) precision: (train=0.894, test=0.646) recall: (train=0.964, test=0.706) total time=  13.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.922, test=0.607) f1: (train=0.926, test=0.643) precision: (train=0.893, test=0.597) recall: (train=0.961, test=0.698) total time=  14.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.919, test=0.642) f1: (train=0.924, test=0.663) precision: (train=0.879, test=0.636) recall: (train=0.973, test=0.692) total time=  13.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.877, test=0.671) f1: (train=0.885, test=0.701) precision: (train=0.842, test=0.651) recall: (train=0.934, test=0.761) total time=   9.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.870, test=0.665) f1: (train=0.880, test=0.696) precision: (train=0.830, test=0.645) recall: (train=0.936, test=0.755) total time=   9.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.872, test=0.681) f1: (train=0.882, test=0.711) precision: (train=0.833, test=0.658) recall: (train=0.937, test=0.774) total time=  10.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.875, test=0.709) f1: (train=0.883, test=0.730) precision: (train=0.843, test=0.691) recall: (train=0.926, test=0.774) total time=  11.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.629) f1: (train=0.920, test=0.669) precision: (train=0.877, test=0.613) recall: (train=0.967, test=0.736) total time=  11.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.671) f1: (train=0.930, test=0.681) precision: (train=0.892, test=0.671) recall: (train=0.972, test=0.692) total time=   9.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.922, test=0.684) f1: (train=0.926, test=0.706) precision: (train=0.888, test=0.669) recall: (train=0.969, test=0.748) total time=   8.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.923, test=0.646) f1: (train=0.927, test=0.671) precision: (train=0.888, test=0.638) recall: (train=0.970, test=0.706) total time=  11.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.658) f1: (train=0.930, test=0.702) precision: (train=0.890, test=0.630) recall: (train=0.975, test=0.792) total time=  13.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.879, test=0.640) f1: (train=0.888, test=0.672) precision: (train=0.843, test=0.627) recall: (train=0.937, test=0.725) total time=  11.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.862, test=0.712) f1: (train=0.872, test=0.731) precision: (train=0.827, test=0.697) recall: (train=0.922, test=0.767) total time=  14.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.642) f1: (train=0.883, test=0.676) precision: (train=0.831, test=0.626) recall: (train=0.942, test=0.736) total time=  13.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.658) f1: (train=0.877, test=0.690) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.748) total time=  13.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.872, test=0.677) f1: (train=0.881, test=0.706) precision: (train=0.831, test=0.658) recall: (train=0.939, test=0.761) total time=  15.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.931, test=0.678) f1: (train=0.935, test=0.702) precision: (train=0.895, test=0.665) recall: (train=0.980, test=0.744) total time=  19.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.928, test=0.681) f1: (train=0.932, test=0.693) precision: (train=0.895, test=0.677) recall: (train=0.973, test=0.711) total time=  19.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.925, test=0.636) f1: (train=0.929, test=0.665) precision: (train=0.893, test=0.624) recall: (train=0.969, test=0.711) total time=  28.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.883, test=0.652) f1: (train=0.891, test=0.686) precision: (train=0.842, test=0.633) recall: (train=0.947, test=0.748) total time=  23.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.703) f1: (train=0.888, test=0.727) precision: (train=0.846, test=0.681) recall: (train=0.934, test=0.780) total time=  22.9s[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.927, test=0.700) f1: (train=0.931, test=0.712) precision: (train=0.893, test=0.695) recall: (train=0.972, test=0.730) total time=  25.9s\n",
      "\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.924, test=0.639) f1: (train=0.929, test=0.674) precision: (train=0.888, test=0.622) recall: (train=0.973, test=0.736) total time=  25.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.643) f1: (train=0.887, test=0.678) precision: (train=0.845, test=0.628) recall: (train=0.934, test=0.738) total time=  23.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.874, test=0.700) f1: (train=0.882, test=0.715) precision: (train=0.843, test=0.690) recall: (train=0.925, test=0.742) total time=  22.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.668) f1: (train=0.888, test=0.692) precision: (train=0.845, test=0.654) recall: (train=0.936, test=0.736) total time=  23.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.653) f1: (train=0.934, test=0.671) precision: (train=0.895, test=0.649) recall: (train=0.976, test=0.694) total time=  18.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.928, test=0.607) f1: (train=0.932, test=0.635) precision: (train=0.897, test=0.601) recall: (train=0.970, test=0.673) total time=  14.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.883, test=0.634) f1: (train=0.891, test=0.667) precision: (train=0.844, test=0.622) recall: (train=0.943, test=0.719) total time=  14.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.693) f1: (train=0.927, test=0.709) precision: (train=0.892, test=0.684) recall: (train=0.964, test=0.736) total time=  16.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.661) f1: (train=0.927, test=0.694) precision: (train=0.886, test=0.642) recall: (train=0.973, test=0.755) total time=  14.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.658) f1: (train=0.933, test=0.667) precision: (train=0.902, test=0.660) recall: (train=0.967, test=0.673) total time=  17.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.876, test=0.661) f1: (train=0.884, test=0.695) precision: (train=0.843, test=0.640) recall: (train=0.929, test=0.761) total time=  11.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.868, test=0.661) f1: (train=0.877, test=0.695) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.761) total time=  13.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.873, test=0.725) f1: (train=0.881, test=0.741) precision: (train=0.844, test=0.711) recall: (train=0.920, test=0.774) total time=  16.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.878, test=0.668) f1: (train=0.887, test=0.698) precision: (train=0.835, test=0.649) recall: (train=0.947, test=0.755) total time=   8.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.650) f1: (train=0.920, test=0.669) precision: (train=0.881, test=0.645) recall: (train=0.962, test=0.694) total time=   8.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.913, test=0.687) f1: (train=0.918, test=0.710) precision: (train=0.882, test=0.670) recall: (train=0.958, test=0.755) total time=   9.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.917, test=0.629) f1: (train=0.922, test=0.669) precision: (train=0.887, test=0.613) recall: (train=0.959, test=0.736) total time=   9.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.918, test=0.620) f1: (train=0.923, test=0.629) precision: (train=0.881, test=0.623) recall: (train=0.969, test=0.635) total time=  10.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.919, test=0.655) f1: (train=0.924, test=0.682) precision: (train=0.886, test=0.641) recall: (train=0.965, test=0.730) total time=   9.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.875, test=0.643) f1: (train=0.884, test=0.673) precision: (train=0.839, test=0.632) recall: (train=0.934, test=0.719) total time=   9.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.629) f1: (train=0.882, test=0.663) precision: (train=0.835, test=0.616) recall: (train=0.936, test=0.717) total time=   9.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.865, test=0.658) f1: (train=0.876, test=0.693) precision: (train=0.823, test=0.637) recall: (train=0.936, test=0.761) total time=  15.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.867, test=0.712) f1: (train=0.875, test=0.732) precision: (train=0.835, test=0.695) recall: (train=0.920, test=0.774) total time=  15.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.674) f1: (train=0.879, test=0.703) precision: (train=0.827, test=0.654) recall: (train=0.937, test=0.761) total time=  15.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.922, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.897, test=0.652) recall: (train=0.956, test=0.730) total time=  18.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.929, test=0.659) f1: (train=0.933, test=0.684) precision: (train=0.897, test=0.648) recall: (train=0.972, test=0.725) total time=  20.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.919, test=0.620) f1: (train=0.923, test=0.653) precision: (train=0.893, test=0.609) recall: (train=0.956, test=0.704) total time=  20.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.926, test=0.709) f1: (train=0.929, test=0.722) precision: (train=0.900, test=0.702) recall: (train=0.961, test=0.742) total time=  21.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.921, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.889, test=0.652) recall: (train=0.965, test=0.730) total time=  21.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.653) f1: (train=0.887, test=0.686) precision: (train=0.845, test=0.636) recall: (train=0.934, test=0.744) total time=  26.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.665) f1: (train=0.886, test=0.692) precision: (train=0.842, test=0.648) recall: (train=0.936, test=0.742) total time=  25.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.649) f1: (train=0.888, test=0.682) precision: (train=0.847, test=0.631) recall: (train=0.932, test=0.742) total time=  25.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.706) f1: (train=0.885, test=0.718) precision: (train=0.849, test=0.701) recall: (train=0.925, test=0.736) total time=  16.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.919, test=0.642) f1: (train=0.924, test=0.663) precision: (train=0.879, test=0.636) recall: (train=0.973, test=0.692) total time=  14.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.653) f1: (train=0.927, test=0.675) precision: (train=0.894, test=0.646) recall: (train=0.964, test=0.706) total time=  17.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.877, test=0.658) f1: (train=0.885, test=0.684) precision: (train=0.843, test=0.644) recall: (train=0.932, test=0.730) total time=  17.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.922, test=0.607) f1: (train=0.926, test=0.643) precision: (train=0.893, test=0.597) recall: (train=0.961, test=0.698) total time=  17.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.932, test=0.687) f1: (train=0.935, test=0.698) precision: (train=0.907, test=0.685) recall: (train=0.965, test=0.711) total time=  16.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.879, test=0.650) f1: (train=0.886, test=0.682) precision: (train=0.846, test=0.634) recall: (train=0.931, test=0.738) total time=  15.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.658) f1: (train=0.927, test=0.686) precision: (train=0.890, test=0.643) recall: (train=0.967, test=0.736) total time=  15.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.877, test=0.671) f1: (train=0.885, test=0.701) precision: (train=0.842, test=0.651) recall: (train=0.934, test=0.761) total time=  10.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.872, test=0.681) f1: (train=0.882, test=0.711) precision: (train=0.833, test=0.658) recall: (train=0.937, test=0.774) total time=  12.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.875, test=0.709) f1: (train=0.883, test=0.730) precision: (train=0.843, test=0.691) recall: (train=0.926, test=0.774) total time=  12.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.870, test=0.665) f1: (train=0.880, test=0.696) precision: (train=0.830, test=0.645) recall: (train=0.936, test=0.755) total time=  13.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.923, test=0.646) f1: (train=0.927, test=0.671) precision: (train=0.888, test=0.638) recall: (train=0.970, test=0.706) total time=  13.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.671) f1: (train=0.930, test=0.681) precision: (train=0.892, test=0.671) recall: (train=0.972, test=0.692) total time=  13.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.629) f1: (train=0.920, test=0.669) precision: (train=0.877, test=0.613) recall: (train=0.967, test=0.736) total time=  12.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.922, test=0.684) f1: (train=0.926, test=0.706) precision: (train=0.888, test=0.669) recall: (train=0.969, test=0.748) total time=  12.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.658) f1: (train=0.930, test=0.702) precision: (train=0.890, test=0.630) recall: (train=0.975, test=0.792) total time=  11.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.658) f1: (train=0.877, test=0.690) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.748) total time=  11.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.642) f1: (train=0.883, test=0.676) precision: (train=0.831, test=0.626) recall: (train=0.942, test=0.736) total time=  11.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.879, test=0.640) f1: (train=0.888, test=0.672) precision: (train=0.843, test=0.627) recall: (train=0.937, test=0.725) total time=  11.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.862, test=0.712) f1: (train=0.872, test=0.731) precision: (train=0.827, test=0.697) recall: (train=0.922, test=0.767) total time=  13.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.872, test=0.677) f1: (train=0.881, test=0.706) precision: (train=0.831, test=0.658) recall: (train=0.939, test=0.761) total time=  10.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.931, test=0.678) f1: (train=0.935, test=0.702) precision: (train=0.895, test=0.665) recall: (train=0.980, test=0.744) total time=  24.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.928, test=0.681) f1: (train=0.932, test=0.693) precision: (train=0.895, test=0.677) recall: (train=0.973, test=0.711) total time=  24.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.703) f1: (train=0.888, test=0.727) precision: (train=0.846, test=0.681) recall: (train=0.934, test=0.780) total time=  20.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.643) f1: (train=0.887, test=0.678) precision: (train=0.845, test=0.628) recall: (train=0.934, test=0.738) total time=  20.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.924, test=0.639) f1: (train=0.929, test=0.674) precision: (train=0.888, test=0.622) recall: (train=0.973, test=0.736) total time=  23.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.927, test=0.700) f1: (train=0.931, test=0.712) precision: (train=0.893, test=0.695) recall: (train=0.972, test=0.730) total time=  23.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.925, test=0.636) f1: (train=0.929, test=0.665) precision: (train=0.893, test=0.624) recall: (train=0.969, test=0.711) total time=  23.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.883, test=0.652) f1: (train=0.891, test=0.686) precision: (train=0.842, test=0.633) recall: (train=0.947, test=0.748) total time=  25.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.874, test=0.700) f1: (train=0.882, test=0.715) precision: (train=0.843, test=0.690) recall: (train=0.925, test=0.742) total time=  25.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.668) f1: (train=0.888, test=0.692) precision: (train=0.845, test=0.654) recall: (train=0.936, test=0.736) total time=  16.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.883, test=0.634) f1: (train=0.891, test=0.667) precision: (train=0.844, test=0.622) recall: (train=0.943, test=0.719) total time=  14.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.653) f1: (train=0.934, test=0.671) precision: (train=0.895, test=0.649) recall: (train=0.976, test=0.694) total time=  16.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.658) f1: (train=0.933, test=0.667) precision: (train=0.902, test=0.660) recall: (train=0.967, test=0.673) total time=  16.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.693) f1: (train=0.927, test=0.709) precision: (train=0.892, test=0.684) recall: (train=0.964, test=0.736) total time=  13.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.928, test=0.607) f1: (train=0.932, test=0.635) precision: (train=0.897, test=0.601) recall: (train=0.970, test=0.673) total time=  15.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.661) f1: (train=0.927, test=0.694) precision: (train=0.886, test=0.642) recall: (train=0.973, test=0.755) total time=  14.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.876, test=0.661) f1: (train=0.884, test=0.695) precision: (train=0.843, test=0.640) recall: (train=0.929, test=0.761) total time=  15.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.868, test=0.661) f1: (train=0.877, test=0.695) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.761) total time=   7.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.917, test=0.629) f1: (train=0.922, test=0.669) precision: (train=0.887, test=0.613) recall: (train=0.959, test=0.736) total time=   9.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.918, test=0.620) f1: (train=0.923, test=0.629) precision: (train=0.881, test=0.623) recall: (train=0.969, test=0.635) total time=   9.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.913, test=0.687) f1: (train=0.918, test=0.710) precision: (train=0.882, test=0.670) recall: (train=0.958, test=0.755) total time=   6.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.650) f1: (train=0.920, test=0.669) precision: (train=0.881, test=0.645) recall: (train=0.962, test=0.694) total time=   9.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.873, test=0.725) f1: (train=0.881, test=0.741) precision: (train=0.844, test=0.711) recall: (train=0.920, test=0.774) total time=   9.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.878, test=0.668) f1: (train=0.887, test=0.698) precision: (train=0.835, test=0.649) recall: (train=0.947, test=0.755) total time=  12.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.919, test=0.655) f1: (train=0.924, test=0.682) precision: (train=0.886, test=0.641) recall: (train=0.965, test=0.730) total time=  15.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.629) f1: (train=0.882, test=0.663) precision: (train=0.835, test=0.616) recall: (train=0.936, test=0.717) total time=  11.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.867, test=0.712) f1: (train=0.875, test=0.732) precision: (train=0.835, test=0.695) recall: (train=0.920, test=0.774) total time=  12.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.875, test=0.643) f1: (train=0.884, test=0.673) precision: (train=0.839, test=0.632) recall: (train=0.934, test=0.719) total time=  12.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.865, test=0.658) f1: (train=0.876, test=0.693) precision: (train=0.823, test=0.637) recall: (train=0.936, test=0.761) total time=  12.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.674) f1: (train=0.879, test=0.703) precision: (train=0.827, test=0.654) recall: (train=0.937, test=0.761) total time=  13.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.929, test=0.659) f1: (train=0.933, test=0.684) precision: (train=0.897, test=0.648) recall: (train=0.972, test=0.725) total time=  14.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.922, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.897, test=0.652) recall: (train=0.956, test=0.730) total time=  22.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.919, test=0.620) f1: (train=0.923, test=0.653) precision: (train=0.893, test=0.609) recall: (train=0.956, test=0.704) total time=  24.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.653) f1: (train=0.887, test=0.686) precision: (train=0.845, test=0.636) recall: (train=0.934, test=0.744) total time=  22.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.926, test=0.709) f1: (train=0.929, test=0.722) precision: (train=0.900, test=0.702) recall: (train=0.961, test=0.742) total time=  22.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.665) f1: (train=0.886, test=0.692) precision: (train=0.842, test=0.648) recall: (train=0.936, test=0.742) total time=  21.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.921, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.889, test=0.652) recall: (train=0.965, test=0.730) total time=  26.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.649) f1: (train=0.888, test=0.682) precision: (train=0.847, test=0.631) recall: (train=0.932, test=0.742) total time=  20.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.706) f1: (train=0.885, test=0.718) precision: (train=0.849, test=0.701) recall: (train=0.925, test=0.736) total time=  23.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.877, test=0.658) f1: (train=0.885, test=0.684) precision: (train=0.843, test=0.644) recall: (train=0.932, test=0.730) total time=  23.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.653) f1: (train=0.927, test=0.675) precision: (train=0.894, test=0.646) recall: (train=0.964, test=0.706) total time=  15.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.919, test=0.642) f1: (train=0.924, test=0.663) precision: (train=0.879, test=0.636) recall: (train=0.973, test=0.692) total time=  12.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.658) f1: (train=0.927, test=0.686) precision: (train=0.890, test=0.643) recall: (train=0.967, test=0.736) total time=  14.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.922, test=0.607) f1: (train=0.926, test=0.643) precision: (train=0.893, test=0.597) recall: (train=0.961, test=0.698) total time=  14.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.879, test=0.650) f1: (train=0.886, test=0.682) precision: (train=0.846, test=0.634) recall: (train=0.931, test=0.738) total time=  14.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.932, test=0.687) f1: (train=0.935, test=0.698) precision: (train=0.907, test=0.685) recall: (train=0.965, test=0.711) total time=  14.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.870, test=0.665) f1: (train=0.880, test=0.696) precision: (train=0.830, test=0.645) recall: (train=0.936, test=0.755) total time=  12.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.877, test=0.671) f1: (train=0.885, test=0.701) precision: (train=0.842, test=0.651) recall: (train=0.934, test=0.761) total time=  12.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.875, test=0.709) f1: (train=0.883, test=0.730) precision: (train=0.843, test=0.691) recall: (train=0.926, test=0.774) total time=  17.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.872, test=0.681) f1: (train=0.882, test=0.711) precision: (train=0.833, test=0.658) recall: (train=0.937, test=0.774) total time=  10.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.879, test=0.640) f1: (train=0.888, test=0.672) precision: (train=0.843, test=0.627) recall: (train=0.937, test=0.725) total time=   8.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.671) f1: (train=0.930, test=0.681) precision: (train=0.892, test=0.671) recall: (train=0.972, test=0.692) total time=  10.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.629) f1: (train=0.920, test=0.669) precision: (train=0.877, test=0.613) recall: (train=0.967, test=0.736) total time=  10.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.923, test=0.646) f1: (train=0.927, test=0.671) precision: (train=0.888, test=0.638) recall: (train=0.970, test=0.706) total time=  10.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.922, test=0.684) f1: (train=0.926, test=0.706) precision: (train=0.888, test=0.669) recall: (train=0.969, test=0.748) total time=  11.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.658) f1: (train=0.930, test=0.702) precision: (train=0.890, test=0.630) recall: (train=0.975, test=0.792) total time=  11.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.642) f1: (train=0.883, test=0.676) precision: (train=0.831, test=0.626) recall: (train=0.942, test=0.736) total time=  10.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.658) f1: (train=0.877, test=0.690) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.748) total time=  16.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.862, test=0.712) f1: (train=0.872, test=0.731) precision: (train=0.827, test=0.697) recall: (train=0.922, test=0.767) total time=  16.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.872, test=0.677) f1: (train=0.881, test=0.706) precision: (train=0.831, test=0.658) recall: (train=0.939, test=0.761) total time=  16.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.931, test=0.678) f1: (train=0.935, test=0.702) precision: (train=0.895, test=0.665) recall: (train=0.980, test=0.744) total time=  22.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.928, test=0.681) f1: (train=0.932, test=0.693) precision: (train=0.895, test=0.677) recall: (train=0.973, test=0.711) total time=  23.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.925, test=0.636) f1: (train=0.929, test=0.665) precision: (train=0.893, test=0.624) recall: (train=0.969, test=0.711) total time=  23.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.927, test=0.700) f1: (train=0.931, test=0.712) precision: (train=0.893, test=0.695) recall: (train=0.972, test=0.730) total time=  25.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.924, test=0.639) f1: (train=0.929, test=0.674) precision: (train=0.888, test=0.622) recall: (train=0.973, test=0.736) total time=  23.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.643) f1: (train=0.887, test=0.678) precision: (train=0.845, test=0.628) recall: (train=0.934, test=0.738) total time=  29.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.703) f1: (train=0.888, test=0.727) precision: (train=0.846, test=0.681) recall: (train=0.934, test=0.780) total time=  30.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.883, test=0.652) f1: (train=0.891, test=0.686) precision: (train=0.842, test=0.633) recall: (train=0.947, test=0.748) total time=  27.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.928, test=0.607) f1: (train=0.932, test=0.635) precision: (train=0.897, test=0.601) recall: (train=0.970, test=0.673) total time=  16.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.653) f1: (train=0.934, test=0.671) precision: (train=0.895, test=0.649) recall: (train=0.976, test=0.694) total time=  18.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.658) f1: (train=0.933, test=0.667) precision: (train=0.902, test=0.660) recall: (train=0.967, test=0.673) total time=  19.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.668) f1: (train=0.888, test=0.692) precision: (train=0.845, test=0.654) recall: (train=0.936, test=0.736) total time=  19.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.874, test=0.700) f1: (train=0.882, test=0.715) precision: (train=0.843, test=0.690) recall: (train=0.925, test=0.742) total time=  20.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.693) f1: (train=0.927, test=0.709) precision: (train=0.892, test=0.684) recall: (train=0.964, test=0.736) total time=  19.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.661) f1: (train=0.927, test=0.694) precision: (train=0.886, test=0.642) recall: (train=0.973, test=0.755) total time=  19.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.883, test=0.634) f1: (train=0.891, test=0.667) precision: (train=0.844, test=0.622) recall: (train=0.943, test=0.719) total time=  14.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.876, test=0.661) f1: (train=0.884, test=0.695) precision: (train=0.843, test=0.640) recall: (train=0.929, test=0.761) total time=  12.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.873, test=0.725) f1: (train=0.881, test=0.741) precision: (train=0.844, test=0.711) recall: (train=0.920, test=0.774) total time=  12.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.878, test=0.668) f1: (train=0.887, test=0.698) precision: (train=0.835, test=0.649) recall: (train=0.947, test=0.755) total time=  12.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.868, test=0.661) f1: (train=0.877, test=0.695) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.761) total time=  12.3s[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.650) f1: (train=0.920, test=0.669) precision: (train=0.881, test=0.645) recall: (train=0.962, test=0.694) total time=  12.3s\n",
      "\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.918, test=0.620) f1: (train=0.923, test=0.629) precision: (train=0.881, test=0.623) recall: (train=0.969, test=0.635) total time=  10.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.917, test=0.629) f1: (train=0.922, test=0.669) precision: (train=0.887, test=0.613) recall: (train=0.959, test=0.736) total time=  11.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.913, test=0.687) f1: (train=0.918, test=0.710) precision: (train=0.882, test=0.670) recall: (train=0.958, test=0.755) total time=  12.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.919, test=0.655) f1: (train=0.924, test=0.682) precision: (train=0.886, test=0.641) recall: (train=0.965, test=0.730) total time=  12.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.629) f1: (train=0.882, test=0.663) precision: (train=0.835, test=0.616) recall: (train=0.936, test=0.717) total time=  11.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.865, test=0.658) f1: (train=0.876, test=0.693) precision: (train=0.823, test=0.637) recall: (train=0.936, test=0.761) total time=  11.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.867, test=0.712) f1: (train=0.875, test=0.732) precision: (train=0.835, test=0.695) recall: (train=0.920, test=0.774) total time=  12.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.875, test=0.643) f1: (train=0.884, test=0.673) precision: (train=0.839, test=0.632) recall: (train=0.934, test=0.719) total time=  13.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.674) f1: (train=0.879, test=0.703) precision: (train=0.827, test=0.654) recall: (train=0.937, test=0.761) total time=  11.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.929, test=0.659) f1: (train=0.933, test=0.684) precision: (train=0.897, test=0.648) recall: (train=0.972, test=0.725) total time=  21.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.922, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.897, test=0.652) recall: (train=0.956, test=0.730) total time=  24.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.653) f1: (train=0.887, test=0.686) precision: (train=0.845, test=0.636) recall: (train=0.934, test=0.744) total time=  20.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.665) f1: (train=0.886, test=0.692) precision: (train=0.842, test=0.648) recall: (train=0.936, test=0.742) total time=  20.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.919, test=0.620) f1: (train=0.923, test=0.653) precision: (train=0.893, test=0.609) recall: (train=0.956, test=0.704) total time=  21.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.921, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.889, test=0.652) recall: (train=0.965, test=0.730) total time=  21.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.926, test=0.709) f1: (train=0.929, test=0.722) precision: (train=0.900, test=0.702) recall: (train=0.961, test=0.742) total time=  24.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.649) f1: (train=0.888, test=0.682) precision: (train=0.847, test=0.631) recall: (train=0.932, test=0.742) total time=  20.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.706) f1: (train=0.885, test=0.718) precision: (train=0.849, test=0.701) recall: (train=0.925, test=0.736) total time=  22.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.877, test=0.658) f1: (train=0.885, test=0.684) precision: (train=0.843, test=0.644) recall: (train=0.932, test=0.730) total time=  19.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.653) f1: (train=0.927, test=0.675) precision: (train=0.894, test=0.646) recall: (train=0.964, test=0.706) total time=  13.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.879, test=0.650) f1: (train=0.886, test=0.682) precision: (train=0.846, test=0.634) recall: (train=0.931, test=0.738) total time=  11.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.919, test=0.642) f1: (train=0.924, test=0.663) precision: (train=0.879, test=0.636) recall: (train=0.973, test=0.692) total time=  12.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.658) f1: (train=0.927, test=0.686) precision: (train=0.890, test=0.643) recall: (train=0.967, test=0.736) total time=  12.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.922, test=0.607) f1: (train=0.926, test=0.643) precision: (train=0.893, test=0.597) recall: (train=0.961, test=0.698) total time=  13.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.932, test=0.687) f1: (train=0.935, test=0.698) precision: (train=0.907, test=0.685) recall: (train=0.965, test=0.711) total time=  15.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.877, test=0.671) f1: (train=0.885, test=0.701) precision: (train=0.842, test=0.651) recall: (train=0.934, test=0.761) total time=  14.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.870, test=0.665) f1: (train=0.880, test=0.696) precision: (train=0.830, test=0.645) recall: (train=0.936, test=0.755) total time=  10.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.923, test=0.646) f1: (train=0.927, test=0.671) precision: (train=0.888, test=0.638) recall: (train=0.970, test=0.706) total time=   9.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.875, test=0.709) f1: (train=0.883, test=0.730) precision: (train=0.843, test=0.691) recall: (train=0.926, test=0.774) total time=  10.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.872, test=0.681) f1: (train=0.882, test=0.711) precision: (train=0.833, test=0.658) recall: (train=0.937, test=0.774) total time=  10.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.671) f1: (train=0.930, test=0.681) precision: (train=0.892, test=0.671) recall: (train=0.972, test=0.692) total time=  12.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.922, test=0.684) f1: (train=0.926, test=0.706) precision: (train=0.888, test=0.669) recall: (train=0.969, test=0.748) total time=  10.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.629) f1: (train=0.920, test=0.669) precision: (train=0.877, test=0.613) recall: (train=0.967, test=0.736) total time=  12.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.658) f1: (train=0.930, test=0.702) precision: (train=0.890, test=0.630) recall: (train=0.975, test=0.792) total time=  12.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.879, test=0.640) f1: (train=0.888, test=0.672) precision: (train=0.843, test=0.627) recall: (train=0.937, test=0.725) total time=  16.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.642) f1: (train=0.883, test=0.676) precision: (train=0.831, test=0.626) recall: (train=0.942, test=0.736) total time=  14.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.658) f1: (train=0.877, test=0.690) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.748) total time=  14.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.862, test=0.712) f1: (train=0.872, test=0.731) precision: (train=0.827, test=0.697) recall: (train=0.922, test=0.767) total time=  15.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.872, test=0.677) f1: (train=0.881, test=0.706) precision: (train=0.831, test=0.658) recall: (train=0.939, test=0.761) total time=  14.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.931, test=0.678) f1: (train=0.935, test=0.702) precision: (train=0.895, test=0.665) recall: (train=0.980, test=0.744) total time=  17.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.928, test=0.681) f1: (train=0.932, test=0.693) precision: (train=0.895, test=0.677) recall: (train=0.973, test=0.711) total time=  19.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.925, test=0.636) f1: (train=0.929, test=0.665) precision: (train=0.893, test=0.624) recall: (train=0.969, test=0.711) total time=  23.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.927, test=0.700) f1: (train=0.931, test=0.712) precision: (train=0.893, test=0.695) recall: (train=0.972, test=0.730) total time=  27.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.883, test=0.652) f1: (train=0.891, test=0.686) precision: (train=0.842, test=0.633) recall: (train=0.947, test=0.748) total time=  22.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.643) f1: (train=0.887, test=0.678) precision: (train=0.845, test=0.628) recall: (train=0.934, test=0.738) total time=  24.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.703) f1: (train=0.888, test=0.727) precision: (train=0.846, test=0.681) recall: (train=0.934, test=0.780) total time=  25.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.924, test=0.639) f1: (train=0.929, test=0.674) precision: (train=0.888, test=0.622) recall: (train=0.973, test=0.736) total time=  25.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.874, test=0.700) f1: (train=0.882, test=0.715) precision: (train=0.843, test=0.690) recall: (train=0.925, test=0.742) total time=  24.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.668) f1: (train=0.888, test=0.692) precision: (train=0.845, test=0.654) recall: (train=0.936, test=0.736) total time=  23.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.653) f1: (train=0.934, test=0.671) precision: (train=0.895, test=0.649) recall: (train=0.976, test=0.694) total time=  22.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.658) f1: (train=0.933, test=0.667) precision: (train=0.902, test=0.660) recall: (train=0.967, test=0.673) total time=  15.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.928, test=0.607) f1: (train=0.932, test=0.635) precision: (train=0.897, test=0.601) recall: (train=0.970, test=0.673) total time=  16.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.693) f1: (train=0.927, test=0.709) precision: (train=0.892, test=0.684) recall: (train=0.964, test=0.736) total time=  16.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.661) f1: (train=0.927, test=0.694) precision: (train=0.886, test=0.642) recall: (train=0.973, test=0.755) total time=  15.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.883, test=0.634) f1: (train=0.891, test=0.667) precision: (train=0.844, test=0.622) recall: (train=0.943, test=0.719) total time=  15.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.876, test=0.661) f1: (train=0.884, test=0.695) precision: (train=0.843, test=0.640) recall: (train=0.929, test=0.761) total time=  13.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.868, test=0.661) f1: (train=0.877, test=0.695) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.761) total time=  13.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.873, test=0.725) f1: (train=0.881, test=0.741) precision: (train=0.844, test=0.711) recall: (train=0.920, test=0.774) total time=  16.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.878, test=0.668) f1: (train=0.887, test=0.698) precision: (train=0.835, test=0.649) recall: (train=0.947, test=0.755) total time=   8.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.650) f1: (train=0.920, test=0.669) precision: (train=0.881, test=0.645) recall: (train=0.962, test=0.694) total time=   7.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.918, test=0.620) f1: (train=0.923, test=0.629) precision: (train=0.881, test=0.623) recall: (train=0.969, test=0.635) total time=   8.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.917, test=0.629) f1: (train=0.922, test=0.669) precision: (train=0.887, test=0.613) recall: (train=0.959, test=0.736) total time=   7.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.913, test=0.687) f1: (train=0.918, test=0.710) precision: (train=0.882, test=0.670) recall: (train=0.958, test=0.755) total time=   8.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.875, test=0.643) f1: (train=0.884, test=0.673) precision: (train=0.839, test=0.632) recall: (train=0.934, test=0.719) total time=   8.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.919, test=0.655) f1: (train=0.924, test=0.682) precision: (train=0.886, test=0.641) recall: (train=0.965, test=0.730) total time=   9.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.629) f1: (train=0.882, test=0.663) precision: (train=0.835, test=0.616) recall: (train=0.936, test=0.717) total time=   8.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.865, test=0.658) f1: (train=0.876, test=0.693) precision: (train=0.823, test=0.637) recall: (train=0.936, test=0.761) total time=  16.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.867, test=0.712) f1: (train=0.875, test=0.732) precision: (train=0.835, test=0.695) recall: (train=0.920, test=0.774) total time=  15.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.674) f1: (train=0.879, test=0.703) precision: (train=0.827, test=0.654) recall: (train=0.937, test=0.761) total time=  15.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.919, test=0.620) f1: (train=0.923, test=0.653) precision: (train=0.893, test=0.609) recall: (train=0.956, test=0.704) total time=  17.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.922, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.897, test=0.652) recall: (train=0.956, test=0.730) total time=  18.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.926, test=0.709) f1: (train=0.929, test=0.722) precision: (train=0.900, test=0.702) recall: (train=0.961, test=0.742) total time=  22.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.929, test=0.659) f1: (train=0.933, test=0.684) precision: (train=0.897, test=0.648) recall: (train=0.972, test=0.725) total time=  19.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.921, test=0.665) f1: (train=0.926, test=0.688) precision: (train=0.889, test=0.652) recall: (train=0.965, test=0.730) total time=  22.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.653) f1: (train=0.887, test=0.686) precision: (train=0.845, test=0.636) recall: (train=0.934, test=0.744) total time=  27.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.665) f1: (train=0.886, test=0.692) precision: (train=0.842, test=0.648) recall: (train=0.936, test=0.742) total time=  22.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.649) f1: (train=0.888, test=0.682) precision: (train=0.847, test=0.631) recall: (train=0.932, test=0.742) total time=  22.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.919, test=0.642) f1: (train=0.924, test=0.663) precision: (train=0.879, test=0.636) recall: (train=0.973, test=0.692) total time=  14.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.653) f1: (train=0.927, test=0.675) precision: (train=0.894, test=0.646) recall: (train=0.964, test=0.706) total time=  15.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.878, test=0.706) f1: (train=0.885, test=0.718) precision: (train=0.849, test=0.701) recall: (train=0.925, test=0.736) total time=  17.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.877, test=0.658) f1: (train=0.885, test=0.684) precision: (train=0.843, test=0.644) recall: (train=0.932, test=0.730) total time=  16.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.922, test=0.607) f1: (train=0.926, test=0.643) precision: (train=0.893, test=0.597) recall: (train=0.961, test=0.698) total time=  17.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.932, test=0.687) f1: (train=0.935, test=0.698) precision: (train=0.907, test=0.685) recall: (train=0.965, test=0.711) total time=  17.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.658) f1: (train=0.927, test=0.686) precision: (train=0.890, test=0.643) recall: (train=0.967, test=0.736) total time=  16.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.879, test=0.650) f1: (train=0.886, test=0.682) precision: (train=0.846, test=0.634) recall: (train=0.931, test=0.738) total time=  11.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.870, test=0.665) f1: (train=0.880, test=0.696) precision: (train=0.830, test=0.645) recall: (train=0.936, test=0.755) total time=  11.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.877, test=0.671) f1: (train=0.885, test=0.701) precision: (train=0.842, test=0.651) recall: (train=0.934, test=0.761) total time=  12.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.872, test=0.681) f1: (train=0.882, test=0.711) precision: (train=0.833, test=0.658) recall: (train=0.937, test=0.774) total time=  10.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.875, test=0.709) f1: (train=0.883, test=0.730) precision: (train=0.843, test=0.691) recall: (train=0.926, test=0.774) total time=   9.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.923, test=0.646) f1: (train=0.927, test=0.671) precision: (train=0.888, test=0.638) recall: (train=0.970, test=0.706) total time=  12.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.671) f1: (train=0.930, test=0.681) precision: (train=0.892, test=0.671) recall: (train=0.972, test=0.692) total time=  14.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.922, test=0.684) f1: (train=0.926, test=0.706) precision: (train=0.888, test=0.669) recall: (train=0.969, test=0.748) total time=   8.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.915, test=0.629) f1: (train=0.920, test=0.669) precision: (train=0.877, test=0.613) recall: (train=0.967, test=0.736) total time=   9.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.868, test=0.658) f1: (train=0.877, test=0.690) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.748) total time=   9.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.879, test=0.640) f1: (train=0.888, test=0.672) precision: (train=0.843, test=0.627) recall: (train=0.937, test=0.725) total time=   8.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.873, test=0.642) f1: (train=0.883, test=0.676) precision: (train=0.831, test=0.626) recall: (train=0.942, test=0.736) total time=   8.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.926, test=0.658) f1: (train=0.930, test=0.702) precision: (train=0.890, test=0.630) recall: (train=0.975, test=0.792) total time=   9.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.862, test=0.712) f1: (train=0.872, test=0.731) precision: (train=0.827, test=0.697) recall: (train=0.922, test=0.767) total time=  10.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.872, test=0.677) f1: (train=0.881, test=0.706) precision: (train=0.831, test=0.658) recall: (train=0.939, test=0.761) total time=  10.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.931, test=0.678) f1: (train=0.935, test=0.702) precision: (train=0.895, test=0.665) recall: (train=0.980, test=0.744) total time=  22.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.927, test=0.700) f1: (train=0.931, test=0.712) precision: (train=0.893, test=0.695) recall: (train=0.972, test=0.730) total time=  16.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.925, test=0.636) f1: (train=0.929, test=0.665) precision: (train=0.893, test=0.624) recall: (train=0.969, test=0.711) total time=  19.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.879, test=0.643) f1: (train=0.887, test=0.678) precision: (train=0.845, test=0.628) recall: (train=0.934, test=0.738) total time=  23.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.703) f1: (train=0.888, test=0.727) precision: (train=0.846, test=0.681) recall: (train=0.934, test=0.780) total time=  16.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.924, test=0.639) f1: (train=0.929, test=0.674) precision: (train=0.888, test=0.622) recall: (train=0.973, test=0.736) total time=  24.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.928, test=0.681) f1: (train=0.932, test=0.693) precision: (train=0.895, test=0.677) recall: (train=0.973, test=0.711) total time=  23.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.883, test=0.652) f1: (train=0.891, test=0.686) precision: (train=0.842, test=0.633) recall: (train=0.947, test=0.748) total time=  20.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.883, test=0.634) f1: (train=0.891, test=0.667) precision: (train=0.844, test=0.622) recall: (train=0.943, test=0.719) total time=   5.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.653) f1: (train=0.934, test=0.671) precision: (train=0.895, test=0.649) recall: (train=0.976, test=0.694) total time=  12.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.930, test=0.658) f1: (train=0.933, test=0.667) precision: (train=0.902, test=0.660) recall: (train=0.967, test=0.673) total time=  12.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.874, test=0.700) f1: (train=0.882, test=0.715) precision: (train=0.843, test=0.690) recall: (train=0.925, test=0.742) total time=  13.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.693) f1: (train=0.927, test=0.709) precision: (train=0.892, test=0.684) recall: (train=0.964, test=0.736) total time=  10.3s[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.880, test=0.668) f1: (train=0.888, test=0.692) precision: (train=0.845, test=0.654) recall: (train=0.936, test=0.736) total time=  13.4s\n",
      "\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.928, test=0.607) f1: (train=0.932, test=0.635) precision: (train=0.897, test=0.601) recall: (train=0.970, test=0.673) total time=  11.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.923, test=0.661) f1: (train=0.927, test=0.694) precision: (train=0.886, test=0.642) recall: (train=0.973, test=0.755) total time=  11.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.868, test=0.661) f1: (train=0.877, test=0.695) precision: (train=0.828, test=0.640) recall: (train=0.932, test=0.761) total time=   7.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.876, test=0.661) f1: (train=0.884, test=0.695) precision: (train=0.843, test=0.640) recall: (train=0.929, test=0.761) total time=   8.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.873, test=0.725) f1: (train=0.881, test=0.741) precision: (train=0.844, test=0.711) recall: (train=0.920, test=0.774) total time=   7.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.671) f1: (train=0.961, test=0.687) precision: (train=0.943, test=0.665) recall: (train=0.980, test=0.711) total time=  10.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=CountVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.878, test=0.668) f1: (train=0.887, test=0.698) precision: (train=0.835, test=0.649) recall: (train=0.947, test=0.755) total time=   9.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.645) f1: (train=0.952, test=0.667) precision: (train=0.922, test=0.638) recall: (train=0.984, test=0.698) total time=  11.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.960, test=0.649) f1: (train=0.961, test=0.667) precision: (train=0.944, test=0.643) recall: (train=0.980, test=0.692) total time=  10.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.621) f1: (train=0.952, test=0.643) precision: (train=0.931, test=0.618) recall: (train=0.975, test=0.669) total time=  12.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.910, test=0.618) f1: (train=0.916, test=0.645) precision: (train=0.867, test=0.612) recall: (train=0.972, test=0.681) total time=   9.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.905, test=0.665) f1: (train=0.912, test=0.690) precision: (train=0.864, test=0.650) recall: (train=0.965, test=0.736) total time=  10.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.956, test=0.623) f1: (train=0.958, test=0.651) precision: (train=0.932, test=0.615) recall: (train=0.986, test=0.692) total time=  11.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.899, test=0.687) f1: (train=0.906, test=0.710) precision: (train=0.861, test=0.670) recall: (train=0.956, test=0.755) total time=  11.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.649) f1: (train=0.918, test=0.680) precision: (train=0.866, test=0.632) recall: (train=0.976, test=0.736) total time=  11.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.904, test=0.668) f1: (train=0.912, test=0.694) precision: (train=0.858, test=0.652) recall: (train=0.973, test=0.742) total time=  12.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.959, test=0.636) f1: (train=0.961, test=0.644) precision: (train=0.936, test=0.640) recall: (train=0.987, test=0.648) total time=  15.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.669) f1: (train=0.960, test=0.689) precision: (train=0.932, test=0.661) recall: (train=0.989, test=0.719) total time=  15.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.613) f1: (train=0.965, test=0.641) precision: (train=0.946, test=0.607) recall: (train=0.984, test=0.679) total time=  24.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.919, test=0.618) f1: (train=0.925, test=0.643) precision: (train=0.877, test=0.614) recall: (train=0.978, test=0.675) total time=  22.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.962, test=0.610) f1: (train=0.964, test=0.633) precision: (train=0.940, test=0.607) recall: (train=0.989, test=0.660) total time=  24.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.916, test=0.639) f1: (train=0.921, test=0.674) precision: (train=0.880, test=0.622) recall: (train=0.967, test=0.736) total time=  17.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.915, test=0.681) f1: (train=0.921, test=0.704) precision: (train=0.877, test=0.665) recall: (train=0.970, test=0.748) total time=  22.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.918, test=0.674) f1: (train=0.923, test=0.700) precision: (train=0.880, test=0.657) recall: (train=0.970, test=0.748) total time=  18.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.965, test=0.671) f1: (train=0.966, test=0.679) precision: (train=0.949, test=0.673) recall: (train=0.984, test=0.686) total time=  26.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.700) f1: (train=0.927, test=0.720) precision: (train=0.894, test=0.684) recall: (train=0.962, test=0.761) total time=  20.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.955, test=0.659) f1: (train=0.957, test=0.671) precision: (train=0.934, test=0.661) recall: (train=0.981, test=0.681) total time=  10.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.962, test=0.626) f1: (train=0.964, test=0.651) precision: (train=0.942, test=0.619) recall: (train=0.987, test=0.686) total time=  10.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.956, test=0.665) f1: (train=0.958, test=0.669) precision: (train=0.941, test=0.671) recall: (train=0.975, test=0.667) total time=  12.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.645) f1: (train=0.955, test=0.671) precision: (train=0.926, test=0.635) recall: (train=0.986, test=0.711) total time=  11.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.646) f1: (train=0.922, test=0.676) precision: (train=0.872, test=0.634) recall: (train=0.978, test=0.725) total time=  10.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.917, test=0.642) f1: (train=0.923, test=0.689) precision: (train=0.871, test=0.617) recall: (train=0.983, test=0.780) total time=  10.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.910, test=0.684) f1: (train=0.916, test=0.715) precision: (train=0.873, test=0.660) recall: (train=0.962, test=0.780) total time=  10.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.633) f1: (train=0.955, test=0.659) precision: (train=0.929, test=0.624) recall: (train=0.983, test=0.698) total time=  13.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.911, test=0.693) f1: (train=0.916, test=0.714) precision: (train=0.876, test=0.678) recall: (train=0.961, test=0.755) total time=  12.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.911, test=0.668) f1: (train=0.917, test=0.703) precision: (train=0.866, test=0.644) recall: (train=0.975, test=0.774) total time=  10.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.597) f1: (train=0.956, test=0.611) precision: (train=0.938, test=0.600) recall: (train=0.975, test=0.623) total time=  13.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.637) f1: (train=0.918, test=0.663) precision: (train=0.866, test=0.629) recall: (train=0.976, test=0.700) total time=   8.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.621) f1: (train=0.957, test=0.632) precision: (train=0.929, test=0.626) recall: (train=0.987, test=0.637) total time=  13.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.957, test=0.629) f1: (train=0.959, test=0.646) precision: (train=0.932, test=0.627) recall: (train=0.987, test=0.667) total time=  12.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.613) f1: (train=0.957, test=0.639) precision: (train=0.932, test=0.608) recall: (train=0.984, test=0.673) total time=  10.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.956, test=0.652) f1: (train=0.958, test=0.678) precision: (train=0.932, test=0.639) recall: (train=0.986, test=0.723) total time=  12.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.906, test=0.665) f1: (train=0.913, test=0.692) precision: (train=0.859, test=0.648) recall: (train=0.975, test=0.742) total time=  16.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.655) f1: (train=0.918, test=0.691) precision: (train=0.865, test=0.634) recall: (train=0.978, test=0.761) total time=  16.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.901, test=0.671) f1: (train=0.908, test=0.698) precision: (train=0.859, test=0.654) recall: (train=0.964, test=0.748) total time=  17.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.905, test=0.652) f1: (train=0.912, test=0.682) precision: (train=0.860, test=0.636) recall: (train=0.972, test=0.736) total time=  19.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.624) f1: (train=0.960, test=0.638) precision: (train=0.931, test=0.627) recall: (train=0.991, test=0.650) total time=  24.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.696) f1: (train=0.965, test=0.720) precision: (train=0.940, test=0.678) recall: (train=0.991, test=0.767) total time=  22.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.951, test=0.639) f1: (train=0.953, test=0.661) precision: (train=0.930, test=0.632) recall: (train=0.978, test=0.692) total time=  22.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.960, test=0.613) f1: (train=0.962, test=0.645) precision: (train=0.937, test=0.604) recall: (train=0.987, test=0.692) total time=  24.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.966, test=0.649) f1: (train=0.967, test=0.663) precision: (train=0.943, test=0.647) recall: (train=0.992, test=0.679) total time=  27.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.919, test=0.624) f1: (train=0.923, test=0.649) precision: (train=0.884, test=0.619) recall: (train=0.967, test=0.681) total time=  25.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.916, test=0.681) f1: (train=0.921, test=0.709) precision: (train=0.883, test=0.659) recall: (train=0.962, test=0.767) total time=  31.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.649) f1: (train=0.925, test=0.693) precision: (train=0.886, test=0.623) recall: (train=0.967, test=0.780) total time=  26.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.952, test=0.605) f1: (train=0.954, test=0.622) precision: (train=0.924, test=0.607) recall: (train=0.987, test=0.637) total time=  17.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.709) f1: (train=0.925, test=0.728) precision: (train=0.885, test=0.693) recall: (train=0.969, test=0.767) total time=  18.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.959, test=0.613) f1: (train=0.961, test=0.630) precision: (train=0.936, test=0.613) recall: (train=0.987, test=0.648) total time=  22.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.905, test=0.652) f1: (train=0.912, test=0.684) precision: (train=0.863, test=0.634) recall: (train=0.967, test=0.742) total time=  23.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.969, test=0.588) f1: (train=0.970, test=0.622) precision: (train=0.949, test=0.582) recall: (train=0.992, test=0.667) total time=  24.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.965, test=0.677) f1: (train=0.966, test=0.697) precision: (train=0.941, test=0.667) recall: (train=0.994, test=0.730) total time=  18.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.964, test=0.620) f1: (train=0.966, test=0.643) precision: (train=0.943, test=0.615) recall: (train=0.989, test=0.673) total time=  20.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.918, test=0.637) f1: (train=0.923, test=0.661) precision: (train=0.882, test=0.631) recall: (train=0.967, test=0.694) total time=  18.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.918, test=0.690) f1: (train=0.923, test=0.717) precision: (train=0.881, test=0.668) recall: (train=0.969, test=0.774) total time=  11.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.913, test=0.626) f1: (train=0.920, test=0.665) precision: (train=0.867, test=0.611) recall: (train=0.980, test=0.730) total time=  13.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.653) f1: (train=0.960, test=0.677) precision: (train=0.937, test=0.644) recall: (train=0.984, test=0.713) total time=  12.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.919, test=0.706) f1: (train=0.923, test=0.726) precision: (train=0.885, test=0.689) recall: (train=0.965, test=0.767) total time=  13.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.909, test=0.652) f1: (train=0.915, test=0.684) precision: (train=0.870, test=0.634) recall: (train=0.965, test=0.742) total time=  12.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.613) f1: (train=0.961, test=0.645) precision: (train=0.936, test=0.604) recall: (train=0.987, test=0.692) total time=  13.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.957, test=0.626) f1: (train=0.959, test=0.640) precision: (train=0.938, test=0.627) recall: (train=0.980, test=0.654) total time=  13.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.687) f1: (train=0.960, test=0.707) precision: (train=0.941, test=0.674) recall: (train=0.980, test=0.742) total time=  14.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.588) f1: (train=0.956, test=0.613) precision: (train=0.933, test=0.586) recall: (train=0.981, test=0.642) total time=  13.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.637) f1: (train=0.918, test=0.665) precision: (train=0.869, test=0.628) recall: (train=0.972, test=0.706) total time=  11.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.902, test=0.658) f1: (train=0.909, test=0.682) precision: (train=0.856, test=0.646) recall: (train=0.970, test=0.723) total time=  15.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.633) f1: (train=0.917, test=0.672) precision: (train=0.865, test=0.615) recall: (train=0.976, test=0.742) total time=  15.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.896, test=0.690) f1: (train=0.904, test=0.724) precision: (train=0.852, test=0.661) recall: (train=0.964, test=0.799) total time=  15.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.896, test=0.684) f1: (train=0.904, test=0.706) precision: (train=0.857, test=0.669) recall: (train=0.956, test=0.748) total time=  15.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.964, test=0.643) f1: (train=0.965, test=0.665) precision: (train=0.943, test=0.638) recall: (train=0.989, test=0.694) total time=  17.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.607) f1: (train=0.965, test=0.635) precision: (train=0.947, test=0.601) recall: (train=0.983, test=0.673) total time=  24.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.961, test=0.629) f1: (train=0.963, test=0.637) precision: (train=0.936, test=0.634) recall: (train=0.991, test=0.642) total time=  28.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.964, test=0.668) f1: (train=0.965, test=0.687) precision: (train=0.947, test=0.659) recall: (train=0.984, test=0.717) total time=  24.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.623) f1: (train=0.925, test=0.669) precision: (train=0.882, test=0.604) recall: (train=0.973, test=0.748) total time=  21.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.918, test=0.668) f1: (train=0.923, test=0.692) precision: (train=0.880, test=0.654) recall: (train=0.970, test=0.736) total time=  24.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.621) f1: (train=0.928, test=0.643) precision: (train=0.888, test=0.618) recall: (train=0.972, test=0.669) total time=  24.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.642) f1: (train=0.960, test=0.671) precision: (train=0.936, test=0.630) recall: (train=0.986, test=0.717) total time=  25.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.922, test=0.696) f1: (train=0.926, test=0.723) precision: (train=0.888, test=0.674) recall: (train=0.969, test=0.780) total time=  24.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.914, test=0.645) f1: (train=0.920, test=0.673) precision: (train=0.875, test=0.633) recall: (train=0.969, test=0.717) total time=  19.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.955, test=0.623) f1: (train=0.958, test=0.647) precision: (train=0.927, test=0.617) recall: (train=0.991, test=0.679) total time=  13.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.958, test=0.643) f1: (train=0.960, test=0.654) precision: (train=0.932, test=0.646) recall: (train=0.989, test=0.662) total time=  15.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.963, test=0.591) f1: (train=0.965, test=0.628) precision: (train=0.943, test=0.584) recall: (train=0.987, test=0.679) total time=  15.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.681) f1: (train=0.962, test=0.695) precision: (train=0.943, test=0.675) recall: (train=0.981, test=0.717) total time=  11.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.601) f1: (train=0.955, test=0.633) precision: (train=0.929, test=0.593) recall: (train=0.983, test=0.679) total time=  11.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.915, test=0.637) f1: (train=0.920, test=0.657) precision: (train=0.877, test=0.634) recall: (train=0.967, test=0.681) total time=  13.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.908, test=0.671) f1: (train=0.914, test=0.703) precision: (train=0.870, test=0.649) recall: (train=0.964, test=0.767) total time=  13.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.923, test=0.639) f1: (train=0.927, test=0.685) precision: (train=0.886, test=0.615) recall: (train=0.973, test=0.774) total time=  14.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.915, test=0.661) f1: (train=0.921, test=0.690) precision: (train=0.881, test=0.645) recall: (train=0.964, test=0.742) total time=  13.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.910, test=0.671) f1: (train=0.916, test=0.705) precision: (train=0.866, test=0.647) recall: (train=0.973, test=0.774) total time=  12.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.954, test=0.611) f1: (train=0.956, test=0.641) precision: (train=0.926, test=0.606) recall: (train=0.987, test=0.681) total time=  14.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.626) f1: (train=0.960, test=0.649) precision: (train=0.935, test=0.621) recall: (train=0.986, test=0.679) total time=  13.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.952, test=0.652) f1: (train=0.954, test=0.673) precision: (train=0.930, test=0.644) recall: (train=0.980, test=0.704) total time=  13.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.604) f1: (train=0.961, test=0.622) precision: (train=0.944, test=0.604) recall: (train=0.978, test=0.642) total time=  15.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.960, test=0.613) f1: (train=0.962, test=0.625) precision: (train=0.939, test=0.616) recall: (train=0.986, test=0.635) total time=  13.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.631) f1: (train=0.916, test=0.640) precision: (train=0.873, test=0.636) recall: (train=0.964, test=0.644) total time=  19.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.907, test=0.652) f1: (train=0.913, test=0.678) precision: (train=0.869, test=0.639) recall: (train=0.961, test=0.723) total time=  17.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.623) f1: (train=0.918, test=0.669) precision: (train=0.869, test=0.604) recall: (train=0.972, test=0.748) total time=  17.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.902, test=0.706) f1: (train=0.909, test=0.731) precision: (train=0.863, test=0.683) recall: (train=0.959, test=0.786) total time=  15.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.901, test=0.658) f1: (train=0.908, test=0.690) precision: (train=0.863, test=0.640) recall: (train=0.958, test=0.748) total time=  21.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.959, test=0.585) f1: (train=0.961, test=0.618) precision: (train=0.943, test=0.580) recall: (train=0.980, test=0.660) total time=  26.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.643) f1: (train=0.960, test=0.654) precision: (train=0.932, test=0.646) recall: (train=0.989, test=0.662) total time=  28.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.966, test=0.633) f1: (train=0.967, test=0.657) precision: (train=0.941, test=0.625) recall: (train=0.995, test=0.692) total time=  28.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.966, test=0.645) f1: (train=0.967, test=0.667) precision: (train=0.942, test=0.638) recall: (train=0.994, test=0.698) total time=  26.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.961, test=0.617) f1: (train=0.962, test=0.634) precision: (train=0.941, test=0.615) recall: (train=0.984, test=0.654) total time=  31.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.643) f1: (train=0.925, test=0.669) precision: (train=0.882, test=0.635) recall: (train=0.973, test=0.706) total time=  28.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.914, test=0.677) f1: (train=0.919, test=0.706) precision: (train=0.881, test=0.658) recall: (train=0.961, test=0.761) total time=  29.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.626) f1: (train=0.925, test=0.667) precision: (train=0.882, test=0.609) recall: (train=0.973, test=0.736) total time=  26.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.677) f1: (train=0.925, test=0.700) precision: (train=0.886, test=0.663) recall: (train=0.967, test=0.742) total time=  23.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.961, test=0.618) f1: (train=0.963, test=0.634) precision: (train=0.934, test=0.619) recall: (train=0.994, test=0.650) total time=  22.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.911, test=0.668) f1: (train=0.917, test=0.694) precision: (train=0.871, test=0.652) recall: (train=0.969, test=0.742) total time=  25.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.961, test=0.620) f1: (train=0.963, test=0.634) precision: (train=0.935, test=0.620) recall: (train=0.992, test=0.648) total time=  19.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.684) f1: (train=0.962, test=0.704) precision: (train=0.932, test=0.670) recall: (train=0.994, test=0.742) total time=  18.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.962, test=0.588) f1: (train=0.963, test=0.617) precision: (train=0.943, test=0.584) recall: (train=0.984, test=0.654) total time=  18.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.957, test=0.620) f1: (train=0.959, test=0.636) precision: (train=0.938, test=0.619) recall: (train=0.980, test=0.654) total time=  18.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.640) f1: (train=0.921, test=0.663) precision: (train=0.879, test=0.634) recall: (train=0.969, test=0.694) total time=  14.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.925, test=0.629) f1: (train=0.930, test=0.674) precision: (train=0.887, test=0.609) recall: (train=0.976, test=0.755) total time=  14.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.919, test=0.661) f1: (train=0.923, test=0.683) precision: (train=0.885, test=0.651) recall: (train=0.965, test=0.717) total time=  13.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.706) f1: (train=0.921, test=0.737) precision: (train=0.882, test=0.675) recall: (train=0.964, test=0.811) total time=  14.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.908, test=0.671) f1: (train=0.915, test=0.700) precision: (train=0.867, test=0.652) recall: (train=0.969, test=0.755) total time=  15.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.645) f1: (train=0.952, test=0.667) precision: (train=0.922, test=0.638) recall: (train=0.984, test=0.698) total time=   9.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.621) f1: (train=0.952, test=0.643) precision: (train=0.931, test=0.618) recall: (train=0.975, test=0.669) total time=  11.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.960, test=0.649) f1: (train=0.961, test=0.667) precision: (train=0.944, test=0.643) recall: (train=0.980, test=0.692) total time=  10.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.671) f1: (train=0.961, test=0.687) precision: (train=0.943, test=0.665) recall: (train=0.980, test=0.711) total time=  10.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.910, test=0.618) f1: (train=0.916, test=0.645) precision: (train=0.867, test=0.612) recall: (train=0.972, test=0.681) total time=  11.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.956, test=0.623) f1: (train=0.958, test=0.651) precision: (train=0.932, test=0.615) recall: (train=0.986, test=0.692) total time=  11.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.649) f1: (train=0.918, test=0.680) precision: (train=0.866, test=0.632) recall: (train=0.976, test=0.736) total time=  10.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.905, test=0.665) f1: (train=0.912, test=0.690) precision: (train=0.864, test=0.650) recall: (train=0.965, test=0.736) total time=  10.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.899, test=0.687) f1: (train=0.906, test=0.710) precision: (train=0.861, test=0.670) recall: (train=0.956, test=0.755) total time=  19.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.904, test=0.668) f1: (train=0.912, test=0.694) precision: (train=0.858, test=0.652) recall: (train=0.973, test=0.742) total time=  18.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.669) f1: (train=0.960, test=0.689) precision: (train=0.932, test=0.661) recall: (train=0.989, test=0.719) total time=  22.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.959, test=0.636) f1: (train=0.961, test=0.644) precision: (train=0.936, test=0.640) recall: (train=0.987, test=0.648) total time=  22.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.919, test=0.618) f1: (train=0.925, test=0.643) precision: (train=0.877, test=0.614) recall: (train=0.978, test=0.675) total time=  20.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.613) f1: (train=0.965, test=0.641) precision: (train=0.946, test=0.607) recall: (train=0.984, test=0.679) total time=  23.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.965, test=0.671) f1: (train=0.966, test=0.679) precision: (train=0.949, test=0.673) recall: (train=0.984, test=0.686) total time=  23.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.962, test=0.610) f1: (train=0.964, test=0.633) precision: (train=0.940, test=0.607) recall: (train=0.989, test=0.660) total time=  21.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.915, test=0.681) f1: (train=0.921, test=0.704) precision: (train=0.877, test=0.665) recall: (train=0.970, test=0.748) total time=  24.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.916, test=0.639) f1: (train=0.921, test=0.674) precision: (train=0.880, test=0.622) recall: (train=0.967, test=0.736) total time=  24.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.700) f1: (train=0.927, test=0.720) precision: (train=0.894, test=0.684) recall: (train=0.962, test=0.761) total time=  16.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.956, test=0.665) f1: (train=0.958, test=0.669) precision: (train=0.941, test=0.671) recall: (train=0.975, test=0.667) total time=  14.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.955, test=0.659) f1: (train=0.957, test=0.671) precision: (train=0.934, test=0.661) recall: (train=0.981, test=0.681) total time=  14.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.962, test=0.626) f1: (train=0.964, test=0.651) precision: (train=0.942, test=0.619) recall: (train=0.987, test=0.686) total time=  15.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.645) f1: (train=0.955, test=0.671) precision: (train=0.926, test=0.635) recall: (train=0.986, test=0.711) total time=  14.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.633) f1: (train=0.955, test=0.659) precision: (train=0.929, test=0.624) recall: (train=0.983, test=0.698) total time=  14.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.918, test=0.674) f1: (train=0.923, test=0.700) precision: (train=0.880, test=0.657) recall: (train=0.970, test=0.748) total time=  14.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.646) f1: (train=0.922, test=0.676) precision: (train=0.872, test=0.634) recall: (train=0.978, test=0.725) total time=  13.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.910, test=0.684) f1: (train=0.916, test=0.715) precision: (train=0.873, test=0.660) recall: (train=0.962, test=0.780) total time=  15.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.911, test=0.693) f1: (train=0.916, test=0.714) precision: (train=0.876, test=0.678) recall: (train=0.961, test=0.755) total time=  10.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.917, test=0.642) f1: (train=0.923, test=0.689) precision: (train=0.871, test=0.617) recall: (train=0.983, test=0.780) total time=  10.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.911, test=0.668) f1: (train=0.917, test=0.703) precision: (train=0.866, test=0.644) recall: (train=0.975, test=0.774) total time=  11.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.951, test=0.615) f1: (train=0.954, test=0.639) precision: (train=0.925, test=0.611) recall: (train=0.984, test=0.669) total time=  14.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.954, test=0.674) f1: (train=0.956, test=0.698) precision: (train=0.933, test=0.659) recall: (train=0.980, test=0.742) total time=   9.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.952, test=0.633) f1: (train=0.954, test=0.637) precision: (train=0.929, test=0.639) recall: (train=0.981, test=0.635) total time=  13.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.953, test=0.607) f1: (train=0.955, test=0.628) precision: (train=0.929, test=0.605) recall: (train=0.983, test=0.654) total time=  13.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.957, test=0.610) f1: (train=0.959, test=0.633) precision: (train=0.938, test=0.607) recall: (train=0.980, test=0.660) total time=  14.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.910, test=0.631) f1: (train=0.916, test=0.655) precision: (train=0.869, test=0.625) recall: (train=0.969, test=0.688) total time=  15.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.907, test=0.661) f1: (train=0.914, test=0.690) precision: (train=0.862, test=0.645) recall: (train=0.973, test=0.742) total time=  13.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.914, test=0.642) f1: (train=0.920, test=0.680) precision: (train=0.872, test=0.623) recall: (train=0.973, test=0.748) total time=  13.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.903, test=0.645) f1: (train=0.911, test=0.680) precision: (train=0.856, test=0.628) recall: (train=0.973, test=0.742) total time=  14.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.907, test=0.716) f1: (train=0.914, test=0.746) precision: (train=0.863, test=0.682) recall: (train=0.970, test=0.824) total time=  14.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.620) f1: (train=0.960, test=0.634) precision: (train=0.933, test=0.620) recall: (train=0.989, test=0.648) total time=  23.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.957, test=0.653) f1: (train=0.959, test=0.665) precision: (train=0.934, test=0.655) recall: (train=0.984, test=0.675) total time=  27.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.610) f1: (train=0.960, test=0.637) precision: (train=0.937, test=0.605) recall: (train=0.984, test=0.673) total time=  26.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.653) f1: (train=0.927, test=0.675) precision: (train=0.888, test=0.646) recall: (train=0.970, test=0.706) total time=  26.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.956, test=0.623) f1: (train=0.958, test=0.649) precision: (train=0.933, test=0.616) recall: (train=0.984, test=0.686) total time=  29.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.910, test=0.677) f1: (train=0.916, test=0.706) precision: (train=0.872, test=0.658) recall: (train=0.964, test=0.761) total time=  23.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.919, test=0.633) f1: (train=0.924, test=0.676) precision: (train=0.878, test=0.612) recall: (train=0.975, test=0.755) total time=  27.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.687) f1: (train=0.965, test=0.698) precision: (train=0.938, test=0.685) recall: (train=0.994, test=0.711) total time=  29.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.921, test=0.706) f1: (train=0.926, test=0.723) precision: (train=0.889, test=0.694) recall: (train=0.965, test=0.755) total time=  26.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.909, test=0.652) f1: (train=0.915, test=0.682) precision: (train=0.869, test=0.636) recall: (train=0.967, test=0.736) total time=  26.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.958, test=0.634) f1: (train=0.960, test=0.661) precision: (train=0.933, test=0.626) recall: (train=0.987, test=0.700) total time=  23.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.963, test=0.617) f1: (train=0.965, test=0.647) precision: (train=0.944, test=0.608) recall: (train=0.986, test=0.692) total time=  18.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.955, test=0.649) f1: (train=0.957, test=0.663) precision: (train=0.929, test=0.647) recall: (train=0.986, test=0.679) total time=  20.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.919, test=0.637) f1: (train=0.925, test=0.661) precision: (train=0.881, test=0.631) recall: (train=0.973, test=0.694) total time=  15.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.957, test=0.693) f1: (train=0.959, test=0.716) precision: (train=0.931, test=0.676) recall: (train=0.989, test=0.761) total time=  19.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.956, test=0.633) f1: (train=0.958, test=0.646) precision: (train=0.934, test=0.633) recall: (train=0.983, test=0.660) total time=  20.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.912, test=0.693) f1: (train=0.918, test=0.716) precision: (train=0.874, test=0.676) recall: (train=0.967, test=0.761) total time=  15.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.912, test=0.642) f1: (train=0.919, test=0.685) precision: (train=0.869, test=0.619) recall: (train=0.975, test=0.767) total time=  16.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.913, test=0.677) f1: (train=0.918, test=0.702) precision: (train=0.882, test=0.661) recall: (train=0.958, test=0.748) total time=  15.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.653) f1: (train=0.960, test=0.677) precision: (train=0.937, test=0.644) recall: (train=0.984, test=0.713) total time=  11.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.907, test=0.665) f1: (train=0.914, test=0.701) precision: (train=0.863, test=0.641) recall: (train=0.972, test=0.774) total time=  11.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.613) f1: (train=0.961, test=0.645) precision: (train=0.936, test=0.604) recall: (train=0.987, test=0.692) total time=  13.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.687) f1: (train=0.960, test=0.707) precision: (train=0.941, test=0.674) recall: (train=0.980, test=0.742) total time=  11.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.957, test=0.626) f1: (train=0.959, test=0.640) precision: (train=0.938, test=0.627) recall: (train=0.980, test=0.654) total time=  12.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.588) f1: (train=0.956, test=0.613) precision: (train=0.933, test=0.586) recall: (train=0.981, test=0.642) total time=  12.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.637) f1: (train=0.918, test=0.665) precision: (train=0.869, test=0.628) recall: (train=0.972, test=0.706) total time=  12.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.902, test=0.658) f1: (train=0.909, test=0.682) precision: (train=0.856, test=0.646) recall: (train=0.970, test=0.723) total time=  11.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.896, test=0.684) f1: (train=0.904, test=0.706) precision: (train=0.857, test=0.669) recall: (train=0.956, test=0.748) total time=  16.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.633) f1: (train=0.917, test=0.672) precision: (train=0.865, test=0.615) recall: (train=0.976, test=0.742) total time=  20.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.896, test=0.690) f1: (train=0.904, test=0.724) precision: (train=0.852, test=0.661) recall: (train=0.964, test=0.799) total time=  20.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.964, test=0.643) f1: (train=0.965, test=0.665) precision: (train=0.943, test=0.638) recall: (train=0.989, test=0.694) total time=  24.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.961, test=0.629) f1: (train=0.963, test=0.637) precision: (train=0.936, test=0.634) recall: (train=0.991, test=0.642) total time=  26.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.964, test=0.668) f1: (train=0.965, test=0.687) precision: (train=0.947, test=0.659) recall: (train=0.984, test=0.717) total time=  24.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.607) f1: (train=0.965, test=0.635) precision: (train=0.947, test=0.601) recall: (train=0.983, test=0.673) total time=  25.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.642) f1: (train=0.960, test=0.671) precision: (train=0.936, test=0.630) recall: (train=0.986, test=0.717) total time=  27.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.621) f1: (train=0.928, test=0.643) precision: (train=0.888, test=0.618) recall: (train=0.972, test=0.669) total time=  22.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.623) f1: (train=0.925, test=0.669) precision: (train=0.882, test=0.604) recall: (train=0.973, test=0.748) total time=  22.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.918, test=0.668) f1: (train=0.923, test=0.692) precision: (train=0.880, test=0.654) recall: (train=0.970, test=0.736) total time=  25.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.922, test=0.696) f1: (train=0.926, test=0.723) precision: (train=0.888, test=0.674) recall: (train=0.969, test=0.780) total time=  20.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.914, test=0.645) f1: (train=0.920, test=0.673) precision: (train=0.875, test=0.633) recall: (train=0.969, test=0.717) total time=  17.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.958, test=0.643) f1: (train=0.960, test=0.654) precision: (train=0.932, test=0.646) recall: (train=0.989, test=0.662) total time=  14.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.955, test=0.623) f1: (train=0.958, test=0.647) precision: (train=0.927, test=0.617) recall: (train=0.991, test=0.679) total time=  15.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.963, test=0.591) f1: (train=0.965, test=0.628) precision: (train=0.943, test=0.584) recall: (train=0.987, test=0.679) total time=  15.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.681) f1: (train=0.962, test=0.695) precision: (train=0.943, test=0.675) recall: (train=0.981, test=0.717) total time=  15.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.915, test=0.637) f1: (train=0.920, test=0.657) precision: (train=0.877, test=0.634) recall: (train=0.967, test=0.681) total time=  13.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.601) f1: (train=0.955, test=0.633) precision: (train=0.929, test=0.593) recall: (train=0.983, test=0.679) total time=  16.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.908, test=0.671) f1: (train=0.914, test=0.703) precision: (train=0.870, test=0.649) recall: (train=0.964, test=0.767) total time=  13.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.923, test=0.639) f1: (train=0.927, test=0.685) precision: (train=0.886, test=0.615) recall: (train=0.973, test=0.774) total time=  12.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.915, test=0.661) f1: (train=0.921, test=0.690) precision: (train=0.881, test=0.645) recall: (train=0.964, test=0.742) total time=  11.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.910, test=0.671) f1: (train=0.916, test=0.705) precision: (train=0.866, test=0.647) recall: (train=0.973, test=0.774) total time=  11.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.951, test=0.634) f1: (train=0.954, test=0.653) precision: (train=0.922, test=0.632) recall: (train=0.987, test=0.675) total time=  13.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.629) f1: (train=0.958, test=0.651) precision: (train=0.925, test=0.624) recall: (train=0.992, test=0.679) total time=  14.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.700) f1: (train=0.952, test=0.710) precision: (train=0.923, test=0.697) recall: (train=0.983, test=0.723) total time=  14.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.960, test=0.626) f1: (train=0.962, test=0.636) precision: (train=0.940, test=0.630) recall: (train=0.984, test=0.642) total time=  15.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.617) f1: (train=0.959, test=0.634) precision: (train=0.937, test=0.615) recall: (train=0.983, test=0.654) total time=  12.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.631) f1: (train=0.916, test=0.640) precision: (train=0.873, test=0.636) recall: (train=0.964, test=0.644) total time=  12.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.907, test=0.652) f1: (train=0.913, test=0.678) precision: (train=0.869, test=0.639) recall: (train=0.961, test=0.723) total time=  13.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.623) f1: (train=0.918, test=0.669) precision: (train=0.869, test=0.604) recall: (train=0.972, test=0.748) total time=  17.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.902, test=0.706) f1: (train=0.909, test=0.731) precision: (train=0.863, test=0.683) recall: (train=0.959, test=0.786) total time=  19.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.901, test=0.658) f1: (train=0.908, test=0.690) precision: (train=0.863, test=0.640) recall: (train=0.958, test=0.748) total time=  18.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.957, test=0.646) f1: (train=0.959, test=0.665) precision: (train=0.932, test=0.643) recall: (train=0.987, test=0.688) total time=  25.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.956, test=0.658) f1: (train=0.958, test=0.675) precision: (train=0.929, test=0.653) recall: (train=0.989, test=0.698) total time=  25.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.968, test=0.597) f1: (train=0.969, test=0.625) precision: (train=0.952, test=0.593) recall: (train=0.987, test=0.660) total time=  25.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.951, test=0.617) f1: (train=0.953, test=0.649) precision: (train=0.925, test=0.607) recall: (train=0.983, test=0.698) total time=  23.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.962, test=0.690) f1: (train=0.963, test=0.703) precision: (train=0.939, test=0.685) recall: (train=0.989, test=0.723) total time=  24.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.643) f1: (train=0.925, test=0.669) precision: (train=0.882, test=0.635) recall: (train=0.973, test=0.706) total time=  23.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.914, test=0.677) f1: (train=0.919, test=0.706) precision: (train=0.881, test=0.658) recall: (train=0.961, test=0.761) total time=  26.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.626) f1: (train=0.925, test=0.667) precision: (train=0.882, test=0.609) recall: (train=0.973, test=0.736) total time=  24.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.677) f1: (train=0.925, test=0.700) precision: (train=0.886, test=0.663) recall: (train=0.967, test=0.742) total time=  21.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.615) f1: (train=0.955, test=0.628) precision: (train=0.926, test=0.618) recall: (train=0.986, test=0.637) total time=  19.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.911, test=0.668) f1: (train=0.917, test=0.694) precision: (train=0.871, test=0.652) recall: (train=0.969, test=0.742) total time=  23.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.617) f1: (train=0.962, test=0.636) precision: (train=0.930, test=0.614) recall: (train=0.997, test=0.660) total time=  19.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.665) f1: (train=0.962, test=0.687) precision: (train=0.935, test=0.653) recall: (train=0.991, test=0.723) total time=  17.6s[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.961, test=0.607) f1: (train=0.962, test=0.639) precision: (train=0.941, test=0.599) recall: (train=0.984, test=0.686) total time=  19.9s\n",
      "\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.957, test=0.613) f1: (train=0.959, test=0.649) precision: (train=0.933, test=0.602) recall: (train=0.986, test=0.704) total time=  16.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.640) f1: (train=0.921, test=0.663) precision: (train=0.879, test=0.634) recall: (train=0.969, test=0.694) total time=  17.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.925, test=0.629) f1: (train=0.930, test=0.674) precision: (train=0.887, test=0.609) recall: (train=0.976, test=0.755) total time=  11.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.919, test=0.661) f1: (train=0.923, test=0.683) precision: (train=0.885, test=0.651) recall: (train=0.965, test=0.717) total time=  14.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.706) f1: (train=0.921, test=0.737) precision: (train=0.882, test=0.675) recall: (train=0.964, test=0.811) total time=  12.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.908, test=0.671) f1: (train=0.915, test=0.700) precision: (train=0.867, test=0.652) recall: (train=0.969, test=0.755) total time=  10.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.960, test=0.649) f1: (train=0.961, test=0.667) precision: (train=0.944, test=0.643) recall: (train=0.980, test=0.692) total time=  11.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.645) f1: (train=0.952, test=0.667) precision: (train=0.922, test=0.638) recall: (train=0.984, test=0.698) total time=  12.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.621) f1: (train=0.952, test=0.643) precision: (train=0.931, test=0.618) recall: (train=0.975, test=0.669) total time=  12.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.671) f1: (train=0.961, test=0.687) precision: (train=0.943, test=0.665) recall: (train=0.980, test=0.711) total time=  13.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.956, test=0.623) f1: (train=0.958, test=0.651) precision: (train=0.932, test=0.615) recall: (train=0.986, test=0.692) total time=  12.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.910, test=0.618) f1: (train=0.916, test=0.645) precision: (train=0.867, test=0.612) recall: (train=0.972, test=0.681) total time=  12.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.905, test=0.665) f1: (train=0.912, test=0.690) precision: (train=0.864, test=0.650) recall: (train=0.965, test=0.736) total time=  13.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.649) f1: (train=0.918, test=0.680) precision: (train=0.866, test=0.632) recall: (train=0.976, test=0.736) total time=  13.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.899, test=0.687) f1: (train=0.906, test=0.710) precision: (train=0.861, test=0.670) recall: (train=0.956, test=0.755) total time=  15.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.904, test=0.668) f1: (train=0.912, test=0.694) precision: (train=0.858, test=0.652) recall: (train=0.973, test=0.742) total time=  18.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.669) f1: (train=0.960, test=0.689) precision: (train=0.932, test=0.661) recall: (train=0.989, test=0.719) total time=  21.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.959, test=0.636) f1: (train=0.961, test=0.644) precision: (train=0.936, test=0.640) recall: (train=0.987, test=0.648) total time=  23.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.965, test=0.671) f1: (train=0.966, test=0.679) precision: (train=0.949, test=0.673) recall: (train=0.984, test=0.686) total time=  21.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.613) f1: (train=0.965, test=0.641) precision: (train=0.946, test=0.607) recall: (train=0.984, test=0.679) total time=  22.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.962, test=0.610) f1: (train=0.964, test=0.633) precision: (train=0.940, test=0.607) recall: (train=0.989, test=0.660) total time=  22.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.919, test=0.618) f1: (train=0.925, test=0.643) precision: (train=0.877, test=0.614) recall: (train=0.978, test=0.675) total time=  22.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.915, test=0.681) f1: (train=0.921, test=0.704) precision: (train=0.877, test=0.665) recall: (train=0.970, test=0.748) total time=  23.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.916, test=0.639) f1: (train=0.921, test=0.674) precision: (train=0.880, test=0.622) recall: (train=0.967, test=0.736) total time=  25.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.700) f1: (train=0.927, test=0.720) precision: (train=0.894, test=0.684) recall: (train=0.962, test=0.761) total time=  20.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.955, test=0.659) f1: (train=0.957, test=0.671) precision: (train=0.934, test=0.661) recall: (train=0.981, test=0.681) total time=  16.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.645) f1: (train=0.955, test=0.671) precision: (train=0.926, test=0.635) recall: (train=0.986, test=0.711) total time=  16.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.956, test=0.665) f1: (train=0.958, test=0.669) precision: (train=0.941, test=0.671) recall: (train=0.975, test=0.667) total time=  13.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.918, test=0.674) f1: (train=0.923, test=0.700) precision: (train=0.880, test=0.657) recall: (train=0.970, test=0.748) total time=  20.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.962, test=0.626) f1: (train=0.964, test=0.651) precision: (train=0.942, test=0.619) recall: (train=0.987, test=0.686) total time=  18.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.633) f1: (train=0.955, test=0.659) precision: (train=0.929, test=0.624) recall: (train=0.983, test=0.698) total time=  14.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.646) f1: (train=0.922, test=0.676) precision: (train=0.872, test=0.634) recall: (train=0.978, test=0.725) total time=  17.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.910, test=0.684) f1: (train=0.916, test=0.715) precision: (train=0.873, test=0.660) recall: (train=0.962, test=0.780) total time=  13.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.917, test=0.642) f1: (train=0.923, test=0.689) precision: (train=0.871, test=0.617) recall: (train=0.983, test=0.780) total time=  11.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.911, test=0.693) f1: (train=0.916, test=0.714) precision: (train=0.876, test=0.678) recall: (train=0.961, test=0.755) total time=  12.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.911, test=0.668) f1: (train=0.917, test=0.703) precision: (train=0.866, test=0.644) recall: (train=0.975, test=0.774) total time=  12.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.948, test=0.618) f1: (train=0.950, test=0.627) precision: (train=0.929, test=0.623) recall: (train=0.972, test=0.631) total time=  13.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.633) f1: (train=0.961, test=0.642) precision: (train=0.941, test=0.636) recall: (train=0.981, test=0.648) total time=  14.3s[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.949, test=0.645) f1: (train=0.951, test=0.667) precision: (train=0.921, test=0.638) recall: (train=0.984, test=0.698) total time=  15.9s\n",
      "\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.681) f1: (train=0.957, test=0.701) precision: (train=0.933, test=0.669) recall: (train=0.983, test=0.736) total time=  13.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.952, test=0.629) f1: (train=0.954, test=0.648) precision: (train=0.927, test=0.626) recall: (train=0.983, test=0.673) total time=  16.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.910, test=0.631) f1: (train=0.916, test=0.655) precision: (train=0.869, test=0.625) recall: (train=0.969, test=0.688) total time=  12.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.907, test=0.661) f1: (train=0.914, test=0.690) precision: (train=0.862, test=0.645) recall: (train=0.973, test=0.742) total time=  13.9s[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.914, test=0.642) f1: (train=0.920, test=0.680) precision: (train=0.872, test=0.623) recall: (train=0.973, test=0.748) total time=  11.9s\n",
      "\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.907, test=0.716) f1: (train=0.914, test=0.746) precision: (train=0.863, test=0.682) recall: (train=0.970, test=0.824) total time=  16.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.903, test=0.645) f1: (train=0.911, test=0.680) precision: (train=0.856, test=0.628) recall: (train=0.973, test=0.742) total time=  21.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.653) f1: (train=0.959, test=0.656) precision: (train=0.936, test=0.662) recall: (train=0.984, test=0.650) total time=  22.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.964, test=0.604) f1: (train=0.965, test=0.629) precision: (train=0.946, test=0.600) recall: (train=0.986, test=0.660) total time=  26.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.653) f1: (train=0.927, test=0.675) precision: (train=0.888, test=0.646) recall: (train=0.970, test=0.706) total time=  20.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.636) f1: (train=0.960, test=0.648) precision: (train=0.932, test=0.636) recall: (train=0.989, test=0.660) total time=  28.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.956, test=0.677) f1: (train=0.958, test=0.695) precision: (train=0.928, test=0.669) recall: (train=0.991, test=0.723) total time=  24.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.967, test=0.626) f1: (train=0.969, test=0.653) precision: (train=0.947, test=0.618) recall: (train=0.991, test=0.692) total time=  27.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.910, test=0.677) f1: (train=0.916, test=0.706) precision: (train=0.872, test=0.658) recall: (train=0.964, test=0.761) total time=  24.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.919, test=0.633) f1: (train=0.924, test=0.676) precision: (train=0.878, test=0.612) recall: (train=0.975, test=0.755) total time=  24.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.921, test=0.706) f1: (train=0.926, test=0.723) precision: (train=0.889, test=0.694) recall: (train=0.965, test=0.755) total time=  25.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.909, test=0.652) f1: (train=0.915, test=0.682) precision: (train=0.869, test=0.636) recall: (train=0.967, test=0.736) total time=  15.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.627) f1: (train=0.955, test=0.649) precision: (train=0.925, test=0.624) recall: (train=0.987, test=0.675) total time=  18.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.962, test=0.613) f1: (train=0.964, test=0.643) precision: (train=0.947, test=0.606) recall: (train=0.981, test=0.686) total time=  18.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.964, test=0.661) f1: (train=0.966, test=0.667) precision: (train=0.942, test=0.667) recall: (train=0.991, test=0.667) total time=  20.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.962, test=0.687) f1: (train=0.964, test=0.703) precision: (train=0.939, test=0.678) recall: (train=0.991, test=0.730) total time=  16.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.919, test=0.637) f1: (train=0.925, test=0.661) precision: (train=0.881, test=0.631) recall: (train=0.973, test=0.694) total time=  14.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.912, test=0.693) f1: (train=0.918, test=0.716) precision: (train=0.874, test=0.676) recall: (train=0.967, test=0.761) total time=  13.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.952, test=0.620) f1: (train=0.954, test=0.651) precision: (train=0.930, test=0.610) recall: (train=0.980, test=0.698) total time=  18.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.912, test=0.642) f1: (train=0.919, test=0.685) precision: (train=0.869, test=0.619) recall: (train=0.975, test=0.767) total time=  12.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.913, test=0.677) f1: (train=0.918, test=0.702) precision: (train=0.882, test=0.661) recall: (train=0.958, test=0.748) total time=  11.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.907, test=0.665) f1: (train=0.914, test=0.701) precision: (train=0.863, test=0.641) recall: (train=0.972, test=0.774) total time=  11.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.613) f1: (train=0.961, test=0.645) precision: (train=0.936, test=0.604) recall: (train=0.987, test=0.692) total time=   9.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.653) f1: (train=0.960, test=0.677) precision: (train=0.937, test=0.644) recall: (train=0.984, test=0.713) total time=  12.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.957, test=0.626) f1: (train=0.959, test=0.640) precision: (train=0.938, test=0.627) recall: (train=0.980, test=0.654) total time=  11.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.687) f1: (train=0.960, test=0.707) precision: (train=0.941, test=0.674) recall: (train=0.980, test=0.742) total time=  10.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.588) f1: (train=0.956, test=0.613) precision: (train=0.933, test=0.586) recall: (train=0.981, test=0.642) total time=  11.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.637) f1: (train=0.918, test=0.665) precision: (train=0.869, test=0.628) recall: (train=0.972, test=0.706) total time=  11.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.902, test=0.658) f1: (train=0.909, test=0.682) precision: (train=0.856, test=0.646) recall: (train=0.970, test=0.723) total time=  14.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.896, test=0.690) f1: (train=0.904, test=0.724) precision: (train=0.852, test=0.661) recall: (train=0.964, test=0.799) total time=  14.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.633) f1: (train=0.917, test=0.672) precision: (train=0.865, test=0.615) recall: (train=0.976, test=0.742) total time=  15.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.896, test=0.684) f1: (train=0.904, test=0.706) precision: (train=0.857, test=0.669) recall: (train=0.956, test=0.748) total time=  18.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.961, test=0.629) f1: (train=0.963, test=0.637) precision: (train=0.936, test=0.634) recall: (train=0.991, test=0.642) total time=  21.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.964, test=0.643) f1: (train=0.965, test=0.665) precision: (train=0.943, test=0.638) recall: (train=0.989, test=0.694) total time=  22.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.607) f1: (train=0.965, test=0.635) precision: (train=0.947, test=0.601) recall: (train=0.983, test=0.673) total time=  23.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.964, test=0.668) f1: (train=0.965, test=0.687) precision: (train=0.947, test=0.659) recall: (train=0.984, test=0.717) total time=  24.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.642) f1: (train=0.960, test=0.671) precision: (train=0.936, test=0.630) recall: (train=0.986, test=0.717) total time=  22.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.621) f1: (train=0.928, test=0.643) precision: (train=0.888, test=0.618) recall: (train=0.972, test=0.669) total time=  22.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.918, test=0.668) f1: (train=0.923, test=0.692) precision: (train=0.880, test=0.654) recall: (train=0.970, test=0.736) total time=  24.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.623) f1: (train=0.925, test=0.669) precision: (train=0.882, test=0.604) recall: (train=0.973, test=0.748) total time=  23.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.922, test=0.696) f1: (train=0.926, test=0.723) precision: (train=0.888, test=0.674) recall: (train=0.969, test=0.780) total time=  19.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.958, test=0.643) f1: (train=0.960, test=0.654) precision: (train=0.932, test=0.646) recall: (train=0.989, test=0.662) total time=  17.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.914, test=0.645) f1: (train=0.920, test=0.673) precision: (train=0.875, test=0.633) recall: (train=0.969, test=0.717) total time=  22.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.955, test=0.623) f1: (train=0.958, test=0.647) precision: (train=0.927, test=0.617) recall: (train=0.991, test=0.679) total time=  18.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.963, test=0.591) f1: (train=0.965, test=0.628) precision: (train=0.943, test=0.584) recall: (train=0.987, test=0.679) total time=  16.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.681) f1: (train=0.962, test=0.695) precision: (train=0.943, test=0.675) recall: (train=0.981, test=0.717) total time=  17.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.601) f1: (train=0.955, test=0.633) precision: (train=0.929, test=0.593) recall: (train=0.983, test=0.679) total time=  17.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.915, test=0.637) f1: (train=0.920, test=0.657) precision: (train=0.877, test=0.634) recall: (train=0.967, test=0.681) total time=  14.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.908, test=0.671) f1: (train=0.914, test=0.703) precision: (train=0.870, test=0.649) recall: (train=0.964, test=0.767) total time=  14.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.923, test=0.639) f1: (train=0.927, test=0.685) precision: (train=0.886, test=0.615) recall: (train=0.973, test=0.774) total time=  14.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.915, test=0.661) f1: (train=0.921, test=0.690) precision: (train=0.881, test=0.645) recall: (train=0.964, test=0.742) total time=  16.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.951, test=0.634) f1: (train=0.954, test=0.653) precision: (train=0.922, test=0.632) recall: (train=0.987, test=0.675) total time=  12.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.910, test=0.671) f1: (train=0.916, test=0.705) precision: (train=0.866, test=0.647) recall: (train=0.973, test=0.774) total time=  14.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.629) f1: (train=0.958, test=0.651) precision: (train=0.925, test=0.624) recall: (train=0.992, test=0.679) total time=  13.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.960, test=0.626) f1: (train=0.962, test=0.636) precision: (train=0.940, test=0.630) recall: (train=0.984, test=0.642) total time=  13.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.617) f1: (train=0.959, test=0.634) precision: (train=0.937, test=0.615) recall: (train=0.983, test=0.654) total time=  12.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.700) f1: (train=0.952, test=0.710) precision: (train=0.923, test=0.697) recall: (train=0.983, test=0.723) total time=  15.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.631) f1: (train=0.916, test=0.640) precision: (train=0.873, test=0.636) recall: (train=0.964, test=0.644) total time=  13.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.907, test=0.652) f1: (train=0.913, test=0.678) precision: (train=0.869, test=0.639) recall: (train=0.961, test=0.723) total time=  14.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.623) f1: (train=0.918, test=0.669) precision: (train=0.869, test=0.604) recall: (train=0.972, test=0.748) total time=  14.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.902, test=0.706) f1: (train=0.909, test=0.731) precision: (train=0.863, test=0.683) recall: (train=0.959, test=0.786) total time=  14.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.901, test=0.658) f1: (train=0.908, test=0.690) precision: (train=0.863, test=0.640) recall: (train=0.958, test=0.748) total time=  15.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.957, test=0.646) f1: (train=0.959, test=0.665) precision: (train=0.932, test=0.643) recall: (train=0.987, test=0.688) total time=  23.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.956, test=0.658) f1: (train=0.958, test=0.675) precision: (train=0.929, test=0.653) recall: (train=0.989, test=0.698) total time=  23.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.968, test=0.597) f1: (train=0.969, test=0.625) precision: (train=0.952, test=0.593) recall: (train=0.987, test=0.660) total time=  24.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.962, test=0.690) f1: (train=0.963, test=0.703) precision: (train=0.939, test=0.685) recall: (train=0.989, test=0.723) total time=  26.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.643) f1: (train=0.925, test=0.669) precision: (train=0.882, test=0.635) recall: (train=0.973, test=0.706) total time=  22.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.951, test=0.617) f1: (train=0.953, test=0.649) precision: (train=0.925, test=0.607) recall: (train=0.983, test=0.698) total time=  24.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.914, test=0.677) f1: (train=0.919, test=0.706) precision: (train=0.881, test=0.658) recall: (train=0.961, test=0.761) total time=  22.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.626) f1: (train=0.925, test=0.667) precision: (train=0.882, test=0.609) recall: (train=0.973, test=0.736) total time=  24.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.677) f1: (train=0.925, test=0.700) precision: (train=0.886, test=0.663) recall: (train=0.967, test=0.742) total time=  23.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.911, test=0.668) f1: (train=0.917, test=0.694) precision: (train=0.871, test=0.652) recall: (train=0.969, test=0.742) total time=  18.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.615) f1: (train=0.955, test=0.628) precision: (train=0.926, test=0.618) recall: (train=0.986, test=0.637) total time=  16.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.961, test=0.607) f1: (train=0.962, test=0.639) precision: (train=0.941, test=0.599) recall: (train=0.984, test=0.686) total time=  14.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.617) f1: (train=0.962, test=0.636) precision: (train=0.930, test=0.614) recall: (train=0.997, test=0.660) total time=  19.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.640) f1: (train=0.921, test=0.663) precision: (train=0.879, test=0.634) recall: (train=0.969, test=0.694) total time=  15.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.665) f1: (train=0.962, test=0.687) precision: (train=0.935, test=0.653) recall: (train=0.991, test=0.723) total time=  21.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.957, test=0.613) f1: (train=0.959, test=0.649) precision: (train=0.933, test=0.602) recall: (train=0.986, test=0.704) total time=  19.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.919, test=0.661) f1: (train=0.923, test=0.683) precision: (train=0.885, test=0.651) recall: (train=0.965, test=0.717) total time=  16.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.925, test=0.629) f1: (train=0.930, test=0.674) precision: (train=0.887, test=0.609) recall: (train=0.976, test=0.755) total time=  15.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.706) f1: (train=0.921, test=0.737) precision: (train=0.882, test=0.675) recall: (train=0.964, test=0.811) total time=  16.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.8, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.908, test=0.671) f1: (train=0.915, test=0.700) precision: (train=0.867, test=0.652) recall: (train=0.969, test=0.755) total time=  13.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.645) f1: (train=0.952, test=0.667) precision: (train=0.922, test=0.638) recall: (train=0.984, test=0.698) total time=  11.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.621) f1: (train=0.952, test=0.643) precision: (train=0.931, test=0.618) recall: (train=0.975, test=0.669) total time=  14.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.960, test=0.649) f1: (train=0.961, test=0.667) precision: (train=0.944, test=0.643) recall: (train=0.980, test=0.692) total time=  12.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.671) f1: (train=0.961, test=0.687) precision: (train=0.943, test=0.665) recall: (train=0.980, test=0.711) total time=  11.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.956, test=0.623) f1: (train=0.958, test=0.651) precision: (train=0.932, test=0.615) recall: (train=0.986, test=0.692) total time=  12.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.910, test=0.618) f1: (train=0.916, test=0.645) precision: (train=0.867, test=0.612) recall: (train=0.972, test=0.681) total time=  10.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.905, test=0.665) f1: (train=0.912, test=0.690) precision: (train=0.864, test=0.650) recall: (train=0.965, test=0.736) total time=  11.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.649) f1: (train=0.918, test=0.680) precision: (train=0.866, test=0.632) recall: (train=0.976, test=0.736) total time=  14.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.899, test=0.687) f1: (train=0.906, test=0.710) precision: (train=0.861, test=0.670) recall: (train=0.956, test=0.755) total time=  16.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.904, test=0.668) f1: (train=0.912, test=0.694) precision: (train=0.858, test=0.652) recall: (train=0.973, test=0.742) total time=  17.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.669) f1: (train=0.960, test=0.689) precision: (train=0.932, test=0.661) recall: (train=0.989, test=0.719) total time=  22.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.959, test=0.636) f1: (train=0.961, test=0.644) precision: (train=0.936, test=0.640) recall: (train=0.987, test=0.648) total time=  22.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.613) f1: (train=0.965, test=0.641) precision: (train=0.946, test=0.607) recall: (train=0.984, test=0.679) total time=  22.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.965, test=0.671) f1: (train=0.966, test=0.679) precision: (train=0.949, test=0.673) recall: (train=0.984, test=0.686) total time=  23.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.962, test=0.610) f1: (train=0.964, test=0.633) precision: (train=0.940, test=0.607) recall: (train=0.989, test=0.660) total time=  23.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.919, test=0.618) f1: (train=0.925, test=0.643) precision: (train=0.877, test=0.614) recall: (train=0.978, test=0.675) total time=  21.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.915, test=0.681) f1: (train=0.921, test=0.704) precision: (train=0.877, test=0.665) recall: (train=0.970, test=0.748) total time=  23.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.916, test=0.639) f1: (train=0.921, test=0.674) precision: (train=0.880, test=0.622) recall: (train=0.967, test=0.736) total time=  25.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.918, test=0.674) f1: (train=0.923, test=0.700) precision: (train=0.880, test=0.657) recall: (train=0.970, test=0.748) total time=  17.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.700) f1: (train=0.927, test=0.720) precision: (train=0.894, test=0.684) recall: (train=0.962, test=0.761) total time=  19.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.955, test=0.659) f1: (train=0.957, test=0.671) precision: (train=0.934, test=0.661) recall: (train=0.981, test=0.681) total time=  17.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.645) f1: (train=0.955, test=0.671) precision: (train=0.926, test=0.635) recall: (train=0.986, test=0.711) total time=  16.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.962, test=0.626) f1: (train=0.964, test=0.651) precision: (train=0.942, test=0.619) recall: (train=0.987, test=0.686) total time=  16.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.956, test=0.665) f1: (train=0.958, test=0.669) precision: (train=0.941, test=0.671) recall: (train=0.975, test=0.667) total time=  16.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.633) f1: (train=0.955, test=0.659) precision: (train=0.929, test=0.624) recall: (train=0.983, test=0.698) total time=  16.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.646) f1: (train=0.922, test=0.676) precision: (train=0.872, test=0.634) recall: (train=0.978, test=0.725) total time=  16.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.910, test=0.684) f1: (train=0.916, test=0.715) precision: (train=0.873, test=0.660) recall: (train=0.962, test=0.780) total time=  13.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.917, test=0.642) f1: (train=0.923, test=0.689) precision: (train=0.871, test=0.617) recall: (train=0.983, test=0.780) total time=  13.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.911, test=0.693) f1: (train=0.916, test=0.714) precision: (train=0.876, test=0.678) recall: (train=0.961, test=0.755) total time=  12.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.911, test=0.668) f1: (train=0.917, test=0.703) precision: (train=0.866, test=0.644) recall: (train=0.975, test=0.774) total time=  12.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.621) f1: (train=0.957, test=0.632) precision: (train=0.929, test=0.626) recall: (train=0.987, test=0.637) total time=  14.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.957, test=0.629) f1: (train=0.959, test=0.646) precision: (train=0.932, test=0.627) recall: (train=0.987, test=0.667) total time=  13.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.597) f1: (train=0.956, test=0.611) precision: (train=0.938, test=0.600) recall: (train=0.975, test=0.623) total time=  13.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.956, test=0.652) f1: (train=0.958, test=0.678) precision: (train=0.932, test=0.639) recall: (train=0.986, test=0.723) total time=  14.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.613) f1: (train=0.957, test=0.639) precision: (train=0.932, test=0.608) recall: (train=0.984, test=0.673) total time=  16.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.637) f1: (train=0.918, test=0.663) precision: (train=0.866, test=0.629) recall: (train=0.976, test=0.700) total time=  15.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.906, test=0.665) f1: (train=0.913, test=0.692) precision: (train=0.859, test=0.648) recall: (train=0.975, test=0.742) total time=  15.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.655) f1: (train=0.918, test=0.691) precision: (train=0.865, test=0.634) recall: (train=0.978, test=0.761) total time=  16.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.901, test=0.671) f1: (train=0.908, test=0.698) precision: (train=0.859, test=0.654) recall: (train=0.964, test=0.748) total time=  18.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.905, test=0.652) f1: (train=0.912, test=0.682) precision: (train=0.860, test=0.636) recall: (train=0.972, test=0.736) total time=  17.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.624) f1: (train=0.960, test=0.638) precision: (train=0.931, test=0.627) recall: (train=0.991, test=0.650) total time=  24.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.966, test=0.649) f1: (train=0.967, test=0.663) precision: (train=0.943, test=0.647) recall: (train=0.992, test=0.679) total time=  24.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.960, test=0.613) f1: (train=0.962, test=0.645) precision: (train=0.937, test=0.604) recall: (train=0.987, test=0.692) total time=  24.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.951, test=0.639) f1: (train=0.953, test=0.661) precision: (train=0.930, test=0.632) recall: (train=0.978, test=0.692) total time=  22.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.696) f1: (train=0.965, test=0.720) precision: (train=0.940, test=0.678) recall: (train=0.991, test=0.767) total time=  27.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.919, test=0.624) f1: (train=0.923, test=0.649) precision: (train=0.884, test=0.619) recall: (train=0.967, test=0.681) total time=  24.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.649) f1: (train=0.925, test=0.693) precision: (train=0.886, test=0.623) recall: (train=0.967, test=0.780) total time=  27.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.916, test=0.681) f1: (train=0.921, test=0.709) precision: (train=0.883, test=0.659) recall: (train=0.962, test=0.767) total time=  27.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.709) f1: (train=0.925, test=0.728) precision: (train=0.885, test=0.693) recall: (train=0.969, test=0.767) total time=  23.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.905, test=0.652) f1: (train=0.912, test=0.684) precision: (train=0.863, test=0.634) recall: (train=0.967, test=0.742) total time=  24.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.952, test=0.605) f1: (train=0.954, test=0.622) precision: (train=0.924, test=0.607) recall: (train=0.987, test=0.637) total time=  19.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.959, test=0.613) f1: (train=0.961, test=0.630) precision: (train=0.936, test=0.613) recall: (train=0.987, test=0.648) total time=  20.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.969, test=0.588) f1: (train=0.970, test=0.622) precision: (train=0.949, test=0.582) recall: (train=0.992, test=0.667) total time=  19.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.964, test=0.620) f1: (train=0.966, test=0.643) precision: (train=0.943, test=0.615) recall: (train=0.989, test=0.673) total time=  16.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.965, test=0.677) f1: (train=0.966, test=0.697) precision: (train=0.941, test=0.667) recall: (train=0.994, test=0.730) total time=  18.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.918, test=0.637) f1: (train=0.923, test=0.661) precision: (train=0.882, test=0.631) recall: (train=0.967, test=0.694) total time=  18.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.918, test=0.690) f1: (train=0.923, test=0.717) precision: (train=0.881, test=0.668) recall: (train=0.969, test=0.774) total time=  16.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.913, test=0.626) f1: (train=0.920, test=0.665) precision: (train=0.867, test=0.611) recall: (train=0.980, test=0.730) total time=  15.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.919, test=0.706) f1: (train=0.923, test=0.726) precision: (train=0.885, test=0.689) recall: (train=0.965, test=0.767) total time=  13.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.653) f1: (train=0.960, test=0.677) precision: (train=0.937, test=0.644) recall: (train=0.984, test=0.713) total time=  11.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.909, test=0.652) f1: (train=0.915, test=0.684) precision: (train=0.870, test=0.634) recall: (train=0.965, test=0.742) total time=  11.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.957, test=0.626) f1: (train=0.959, test=0.640) precision: (train=0.938, test=0.627) recall: (train=0.980, test=0.654) total time=  12.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.613) f1: (train=0.961, test=0.645) precision: (train=0.936, test=0.604) recall: (train=0.987, test=0.692) total time=  11.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.687) f1: (train=0.960, test=0.707) precision: (train=0.941, test=0.674) recall: (train=0.980, test=0.742) total time=  12.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.637) f1: (train=0.918, test=0.665) precision: (train=0.869, test=0.628) recall: (train=0.972, test=0.706) total time=  12.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.588) f1: (train=0.956, test=0.613) precision: (train=0.933, test=0.586) recall: (train=0.981, test=0.642) total time=  13.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.902, test=0.658) f1: (train=0.909, test=0.682) precision: (train=0.856, test=0.646) recall: (train=0.970, test=0.723) total time=  14.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.896, test=0.690) f1: (train=0.904, test=0.724) precision: (train=0.852, test=0.661) recall: (train=0.964, test=0.799) total time=  15.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.633) f1: (train=0.917, test=0.672) precision: (train=0.865, test=0.615) recall: (train=0.976, test=0.742) total time=  14.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.896, test=0.684) f1: (train=0.904, test=0.706) precision: (train=0.857, test=0.669) recall: (train=0.956, test=0.748) total time=  14.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.964, test=0.643) f1: (train=0.965, test=0.665) precision: (train=0.943, test=0.638) recall: (train=0.989, test=0.694) total time=  22.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.961, test=0.629) f1: (train=0.963, test=0.637) precision: (train=0.936, test=0.634) recall: (train=0.991, test=0.642) total time=  23.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.607) f1: (train=0.965, test=0.635) precision: (train=0.947, test=0.601) recall: (train=0.983, test=0.673) total time=  23.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.964, test=0.668) f1: (train=0.965, test=0.687) precision: (train=0.947, test=0.659) recall: (train=0.984, test=0.717) total time=  20.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.621) f1: (train=0.928, test=0.643) precision: (train=0.888, test=0.618) recall: (train=0.972, test=0.669) total time=  21.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.642) f1: (train=0.960, test=0.671) precision: (train=0.936, test=0.630) recall: (train=0.986, test=0.717) total time=  24.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.918, test=0.668) f1: (train=0.923, test=0.692) precision: (train=0.880, test=0.654) recall: (train=0.970, test=0.736) total time=  24.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.623) f1: (train=0.925, test=0.669) precision: (train=0.882, test=0.604) recall: (train=0.973, test=0.748) total time=  24.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.922, test=0.696) f1: (train=0.926, test=0.723) precision: (train=0.888, test=0.674) recall: (train=0.969, test=0.780) total time=  19.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.955, test=0.623) f1: (train=0.958, test=0.647) precision: (train=0.927, test=0.617) recall: (train=0.991, test=0.679) total time=  13.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.914, test=0.645) f1: (train=0.920, test=0.673) precision: (train=0.875, test=0.633) recall: (train=0.969, test=0.717) total time=  15.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.958, test=0.643) f1: (train=0.960, test=0.654) precision: (train=0.932, test=0.646) recall: (train=0.989, test=0.662) total time=  16.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.963, test=0.591) f1: (train=0.965, test=0.628) precision: (train=0.943, test=0.584) recall: (train=0.987, test=0.679) total time=  14.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.601) f1: (train=0.955, test=0.633) precision: (train=0.929, test=0.593) recall: (train=0.983, test=0.679) total time=  14.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.681) f1: (train=0.962, test=0.695) precision: (train=0.943, test=0.675) recall: (train=0.981, test=0.717) total time=  15.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.915, test=0.637) f1: (train=0.920, test=0.657) precision: (train=0.877, test=0.634) recall: (train=0.967, test=0.681) total time=  16.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.908, test=0.671) f1: (train=0.914, test=0.703) precision: (train=0.870, test=0.649) recall: (train=0.964, test=0.767) total time=  13.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.923, test=0.639) f1: (train=0.927, test=0.685) precision: (train=0.886, test=0.615) recall: (train=0.973, test=0.774) total time=  12.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.915, test=0.661) f1: (train=0.921, test=0.690) precision: (train=0.881, test=0.645) recall: (train=0.964, test=0.742) total time=  12.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.954, test=0.611) f1: (train=0.956, test=0.641) precision: (train=0.926, test=0.606) recall: (train=0.987, test=0.681) total time=  13.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.910, test=0.671) f1: (train=0.916, test=0.705) precision: (train=0.866, test=0.647) recall: (train=0.973, test=0.774) total time=  14.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.626) f1: (train=0.960, test=0.649) precision: (train=0.935, test=0.621) recall: (train=0.986, test=0.679) total time=  14.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.952, test=0.652) f1: (train=0.954, test=0.673) precision: (train=0.930, test=0.644) recall: (train=0.980, test=0.704) total time=  11.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.604) f1: (train=0.961, test=0.622) precision: (train=0.944, test=0.604) recall: (train=0.978, test=0.642) total time=  13.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.960, test=0.613) f1: (train=0.962, test=0.625) precision: (train=0.939, test=0.616) recall: (train=0.986, test=0.635) total time=  13.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.631) f1: (train=0.916, test=0.640) precision: (train=0.873, test=0.636) recall: (train=0.964, test=0.644) total time=  17.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.907, test=0.652) f1: (train=0.913, test=0.678) precision: (train=0.869, test=0.639) recall: (train=0.961, test=0.723) total time=  15.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.623) f1: (train=0.918, test=0.669) precision: (train=0.869, test=0.604) recall: (train=0.972, test=0.748) total time=  14.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.902, test=0.706) f1: (train=0.909, test=0.731) precision: (train=0.863, test=0.683) recall: (train=0.959, test=0.786) total time=  19.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.901, test=0.658) f1: (train=0.908, test=0.690) precision: (train=0.863, test=0.640) recall: (train=0.958, test=0.748) total time=  20.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.643) f1: (train=0.960, test=0.654) precision: (train=0.932, test=0.646) recall: (train=0.989, test=0.662) total time=  23.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.959, test=0.585) f1: (train=0.961, test=0.618) precision: (train=0.943, test=0.580) recall: (train=0.980, test=0.660) total time=  21.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.966, test=0.633) f1: (train=0.967, test=0.657) precision: (train=0.941, test=0.625) recall: (train=0.995, test=0.692) total time=  25.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.966, test=0.645) f1: (train=0.967, test=0.667) precision: (train=0.942, test=0.638) recall: (train=0.994, test=0.698) total time=  24.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.961, test=0.617) f1: (train=0.962, test=0.634) precision: (train=0.941, test=0.615) recall: (train=0.984, test=0.654) total time=  27.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.643) f1: (train=0.925, test=0.669) precision: (train=0.882, test=0.635) recall: (train=0.973, test=0.706) total time=  24.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.626) f1: (train=0.925, test=0.667) precision: (train=0.882, test=0.609) recall: (train=0.973, test=0.736) total time=  24.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.914, test=0.677) f1: (train=0.919, test=0.706) precision: (train=0.881, test=0.658) recall: (train=0.961, test=0.761) total time=  24.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.911, test=0.668) f1: (train=0.917, test=0.694) precision: (train=0.871, test=0.652) recall: (train=0.969, test=0.742) total time=  21.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.677) f1: (train=0.925, test=0.700) precision: (train=0.886, test=0.663) recall: (train=0.967, test=0.742) total time=  22.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.961, test=0.618) f1: (train=0.963, test=0.634) precision: (train=0.934, test=0.619) recall: (train=0.994, test=0.650) total time=  24.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.961, test=0.620) f1: (train=0.963, test=0.634) precision: (train=0.935, test=0.620) recall: (train=0.992, test=0.648) total time=  20.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.962, test=0.588) f1: (train=0.963, test=0.617) precision: (train=0.943, test=0.584) recall: (train=0.984, test=0.654) total time=  21.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.684) f1: (train=0.962, test=0.704) precision: (train=0.932, test=0.670) recall: (train=0.994, test=0.742) total time=  18.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.640) f1: (train=0.921, test=0.663) precision: (train=0.879, test=0.634) recall: (train=0.969, test=0.694) total time=  16.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.919, test=0.661) f1: (train=0.923, test=0.683) precision: (train=0.885, test=0.651) recall: (train=0.965, test=0.717) total time=  13.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.957, test=0.620) f1: (train=0.959, test=0.636) precision: (train=0.938, test=0.619) recall: (train=0.980, test=0.654) total time=  18.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.925, test=0.629) f1: (train=0.930, test=0.674) precision: (train=0.887, test=0.609) recall: (train=0.976, test=0.755) total time=  16.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.706) f1: (train=0.921, test=0.737) precision: (train=0.882, test=0.675) recall: (train=0.964, test=0.811) total time=  15.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.621) f1: (train=0.952, test=0.643) precision: (train=0.931, test=0.618) recall: (train=0.975, test=0.669) total time=  14.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=3000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.908, test=0.671) f1: (train=0.915, test=0.700) precision: (train=0.867, test=0.652) recall: (train=0.969, test=0.755) total time=  14.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.645) f1: (train=0.952, test=0.667) precision: (train=0.922, test=0.638) recall: (train=0.984, test=0.698) total time=  14.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.960, test=0.649) f1: (train=0.961, test=0.667) precision: (train=0.944, test=0.643) recall: (train=0.980, test=0.692) total time=  12.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.671) f1: (train=0.961, test=0.687) precision: (train=0.943, test=0.665) recall: (train=0.980, test=0.711) total time=  11.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.956, test=0.623) f1: (train=0.958, test=0.651) precision: (train=0.932, test=0.615) recall: (train=0.986, test=0.692) total time=  12.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.910, test=0.618) f1: (train=0.916, test=0.645) precision: (train=0.867, test=0.612) recall: (train=0.972, test=0.681) total time=  11.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.905, test=0.665) f1: (train=0.912, test=0.690) precision: (train=0.864, test=0.650) recall: (train=0.965, test=0.736) total time=  13.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.899, test=0.687) f1: (train=0.906, test=0.710) precision: (train=0.861, test=0.670) recall: (train=0.956, test=0.755) total time=  12.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.649) f1: (train=0.918, test=0.680) precision: (train=0.866, test=0.632) recall: (train=0.976, test=0.736) total time=  16.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.904, test=0.668) f1: (train=0.912, test=0.694) precision: (train=0.858, test=0.652) recall: (train=0.973, test=0.742) total time=  13.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.959, test=0.636) f1: (train=0.961, test=0.644) precision: (train=0.936, test=0.640) recall: (train=0.987, test=0.648) total time=  21.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.669) f1: (train=0.960, test=0.689) precision: (train=0.932, test=0.661) recall: (train=0.989, test=0.719) total time=  23.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.613) f1: (train=0.965, test=0.641) precision: (train=0.946, test=0.607) recall: (train=0.984, test=0.679) total time=  23.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.919, test=0.618) f1: (train=0.925, test=0.643) precision: (train=0.877, test=0.614) recall: (train=0.978, test=0.675) total time=  20.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.965, test=0.671) f1: (train=0.966, test=0.679) precision: (train=0.949, test=0.673) recall: (train=0.984, test=0.686) total time=  21.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.915, test=0.681) f1: (train=0.921, test=0.704) precision: (train=0.877, test=0.665) recall: (train=0.970, test=0.748) total time=  23.1s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.916, test=0.639) f1: (train=0.921, test=0.674) precision: (train=0.880, test=0.622) recall: (train=0.967, test=0.736) total time=  20.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.962, test=0.610) f1: (train=0.964, test=0.633) precision: (train=0.940, test=0.607) recall: (train=0.989, test=0.660) total time=  24.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.700) f1: (train=0.927, test=0.720) precision: (train=0.894, test=0.684) recall: (train=0.962, test=0.761) total time=  15.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.918, test=0.674) f1: (train=0.923, test=0.700) precision: (train=0.880, test=0.657) recall: (train=0.970, test=0.748) total time=  16.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.645) f1: (train=0.955, test=0.671) precision: (train=0.926, test=0.635) recall: (train=0.986, test=0.711) total time=  14.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.955, test=0.659) f1: (train=0.957, test=0.671) precision: (train=0.934, test=0.661) recall: (train=0.981, test=0.681) total time=  14.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.633) f1: (train=0.955, test=0.659) precision: (train=0.929, test=0.624) recall: (train=0.983, test=0.698) total time=  11.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.646) f1: (train=0.922, test=0.676) precision: (train=0.872, test=0.634) recall: (train=0.978, test=0.725) total time=  12.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.956, test=0.665) f1: (train=0.958, test=0.669) precision: (train=0.941, test=0.671) recall: (train=0.975, test=0.667) total time=  14.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.962, test=0.626) f1: (train=0.964, test=0.651) precision: (train=0.942, test=0.619) recall: (train=0.987, test=0.686) total time=  13.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.910, test=0.684) f1: (train=0.916, test=0.715) precision: (train=0.873, test=0.660) recall: (train=0.962, test=0.780) total time=  12.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.917, test=0.642) f1: (train=0.923, test=0.689) precision: (train=0.871, test=0.617) recall: (train=0.983, test=0.780) total time=  10.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.911, test=0.693) f1: (train=0.916, test=0.714) precision: (train=0.876, test=0.678) recall: (train=0.961, test=0.755) total time=  13.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.911, test=0.668) f1: (train=0.917, test=0.703) precision: (train=0.866, test=0.644) recall: (train=0.975, test=0.774) total time=  13.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.952, test=0.633) f1: (train=0.954, test=0.637) precision: (train=0.929, test=0.639) recall: (train=0.981, test=0.635) total time=  13.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.954, test=0.674) f1: (train=0.956, test=0.698) precision: (train=0.933, test=0.659) recall: (train=0.980, test=0.742) total time=  11.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.953, test=0.607) f1: (train=0.955, test=0.628) precision: (train=0.929, test=0.605) recall: (train=0.983, test=0.654) total time=  13.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.951, test=0.615) f1: (train=0.954, test=0.639) precision: (train=0.925, test=0.611) recall: (train=0.984, test=0.669) total time=  13.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.957, test=0.610) f1: (train=0.959, test=0.633) precision: (train=0.938, test=0.607) recall: (train=0.980, test=0.660) total time=  16.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.910, test=0.631) f1: (train=0.916, test=0.655) precision: (train=0.869, test=0.625) recall: (train=0.969, test=0.688) total time=  16.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.903, test=0.645) f1: (train=0.911, test=0.680) precision: (train=0.856, test=0.628) recall: (train=0.973, test=0.742) total time=  14.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.907, test=0.661) f1: (train=0.914, test=0.690) precision: (train=0.862, test=0.645) recall: (train=0.973, test=0.742) total time=  16.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.907, test=0.716) f1: (train=0.914, test=0.746) precision: (train=0.863, test=0.682) recall: (train=0.970, test=0.824) total time=  17.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.914, test=0.642) f1: (train=0.920, test=0.680) precision: (train=0.872, test=0.623) recall: (train=0.973, test=0.748) total time=  16.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.957, test=0.653) f1: (train=0.959, test=0.665) precision: (train=0.934, test=0.655) recall: (train=0.984, test=0.675) total time=  25.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.620) f1: (train=0.960, test=0.634) precision: (train=0.933, test=0.620) recall: (train=0.989, test=0.648) total time=  24.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.610) f1: (train=0.960, test=0.637) precision: (train=0.937, test=0.605) recall: (train=0.984, test=0.673) total time=  28.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.910, test=0.677) f1: (train=0.916, test=0.706) precision: (train=0.872, test=0.658) recall: (train=0.964, test=0.761) total time=  22.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.687) f1: (train=0.965, test=0.698) precision: (train=0.938, test=0.685) recall: (train=0.994, test=0.711) total time=  27.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.919, test=0.633) f1: (train=0.924, test=0.676) precision: (train=0.878, test=0.612) recall: (train=0.975, test=0.755) total time=  22.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.653) f1: (train=0.927, test=0.675) precision: (train=0.888, test=0.646) recall: (train=0.970, test=0.706) total time=  24.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.956, test=0.623) f1: (train=0.958, test=0.649) precision: (train=0.933, test=0.616) recall: (train=0.984, test=0.686) total time=  29.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.909, test=0.652) f1: (train=0.915, test=0.682) precision: (train=0.869, test=0.636) recall: (train=0.967, test=0.736) total time=  24.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.921, test=0.706) f1: (train=0.926, test=0.723) precision: (train=0.889, test=0.694) recall: (train=0.965, test=0.755) total time=  27.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.958, test=0.634) f1: (train=0.960, test=0.661) precision: (train=0.933, test=0.626) recall: (train=0.987, test=0.700) total time=  16.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.956, test=0.633) f1: (train=0.958, test=0.646) precision: (train=0.934, test=0.633) recall: (train=0.983, test=0.660) total time=  15.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.955, test=0.649) f1: (train=0.957, test=0.663) precision: (train=0.929, test=0.647) recall: (train=0.986, test=0.679) total time=  18.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.963, test=0.617) f1: (train=0.965, test=0.647) precision: (train=0.944, test=0.608) recall: (train=0.986, test=0.692) total time=  18.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.957, test=0.693) f1: (train=0.959, test=0.716) precision: (train=0.931, test=0.676) recall: (train=0.989, test=0.761) total time=  18.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.919, test=0.637) f1: (train=0.925, test=0.661) precision: (train=0.881, test=0.631) recall: (train=0.973, test=0.694) total time=  16.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.912, test=0.693) f1: (train=0.918, test=0.716) precision: (train=0.874, test=0.676) recall: (train=0.967, test=0.761) total time=  13.5s[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.912, test=0.642) f1: (train=0.919, test=0.685) precision: (train=0.869, test=0.619) recall: (train=0.975, test=0.767) total time=  12.3s\n",
      "\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.913, test=0.677) f1: (train=0.918, test=0.702) precision: (train=0.882, test=0.661) recall: (train=0.958, test=0.748) total time=  13.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.907, test=0.665) f1: (train=0.914, test=0.701) precision: (train=0.863, test=0.641) recall: (train=0.972, test=0.774) total time=  10.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.653) f1: (train=0.960, test=0.677) precision: (train=0.937, test=0.644) recall: (train=0.984, test=0.713) total time=  11.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.957, test=0.626) f1: (train=0.959, test=0.640) precision: (train=0.938, test=0.627) recall: (train=0.980, test=0.654) total time=  10.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.637) f1: (train=0.918, test=0.665) precision: (train=0.869, test=0.628) recall: (train=0.972, test=0.706) total time=  10.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.687) f1: (train=0.960, test=0.707) precision: (train=0.941, test=0.674) recall: (train=0.980, test=0.742) total time=  10.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.613) f1: (train=0.961, test=0.645) precision: (train=0.936, test=0.604) recall: (train=0.987, test=0.692) total time=  12.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.588) f1: (train=0.956, test=0.613) precision: (train=0.933, test=0.586) recall: (train=0.981, test=0.642) total time=  10.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.902, test=0.658) f1: (train=0.909, test=0.682) precision: (train=0.856, test=0.646) recall: (train=0.970, test=0.723) total time=  17.4s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.633) f1: (train=0.917, test=0.672) precision: (train=0.865, test=0.615) recall: (train=0.976, test=0.742) total time=  15.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.896, test=0.690) f1: (train=0.904, test=0.724) precision: (train=0.852, test=0.661) recall: (train=0.964, test=0.799) total time=  15.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.896, test=0.684) f1: (train=0.904, test=0.706) precision: (train=0.857, test=0.669) recall: (train=0.956, test=0.748) total time=  15.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.961, test=0.629) f1: (train=0.963, test=0.637) precision: (train=0.936, test=0.634) recall: (train=0.991, test=0.642) total time=  20.5s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.964, test=0.668) f1: (train=0.965, test=0.687) precision: (train=0.947, test=0.659) recall: (train=0.984, test=0.717) total time=  17.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.964, test=0.643) f1: (train=0.965, test=0.665) precision: (train=0.943, test=0.638) recall: (train=0.989, test=0.694) total time=  21.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.607) f1: (train=0.965, test=0.635) precision: (train=0.947, test=0.601) recall: (train=0.983, test=0.673) total time=  22.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.642) f1: (train=0.960, test=0.671) precision: (train=0.936, test=0.630) recall: (train=0.986, test=0.717) total time=  20.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.621) f1: (train=0.928, test=0.643) precision: (train=0.888, test=0.618) recall: (train=0.972, test=0.669) total time=  24.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.918, test=0.668) f1: (train=0.923, test=0.692) precision: (train=0.880, test=0.654) recall: (train=0.970, test=0.736) total time=  23.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.623) f1: (train=0.925, test=0.669) precision: (train=0.882, test=0.604) recall: (train=0.973, test=0.748) total time=  24.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.958, test=0.643) f1: (train=0.960, test=0.654) precision: (train=0.932, test=0.646) recall: (train=0.989, test=0.662) total time=  16.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.955, test=0.623) f1: (train=0.958, test=0.647) precision: (train=0.927, test=0.617) recall: (train=0.991, test=0.679) total time=  15.2s[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.922, test=0.696) f1: (train=0.926, test=0.723) precision: (train=0.888, test=0.674) recall: (train=0.969, test=0.780) total time=  17.7s\n",
      "\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.914, test=0.645) f1: (train=0.920, test=0.673) precision: (train=0.875, test=0.633) recall: (train=0.969, test=0.717) total time=  17.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.963, test=0.591) f1: (train=0.965, test=0.628) precision: (train=0.943, test=0.584) recall: (train=0.987, test=0.679) total time=  16.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.681) f1: (train=0.962, test=0.695) precision: (train=0.943, test=0.675) recall: (train=0.981, test=0.717) total time=  13.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.915, test=0.637) f1: (train=0.920, test=0.657) precision: (train=0.877, test=0.634) recall: (train=0.967, test=0.681) total time=  12.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.915, test=0.661) f1: (train=0.921, test=0.690) precision: (train=0.881, test=0.645) recall: (train=0.964, test=0.742) total time=  12.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.601) f1: (train=0.955, test=0.633) precision: (train=0.929, test=0.593) recall: (train=0.983, test=0.679) total time=  12.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.910, test=0.671) f1: (train=0.916, test=0.705) precision: (train=0.866, test=0.647) recall: (train=0.973, test=0.774) total time=  11.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.908, test=0.671) f1: (train=0.914, test=0.703) precision: (train=0.870, test=0.649) recall: (train=0.964, test=0.767) total time=  14.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.923, test=0.639) f1: (train=0.927, test=0.685) precision: (train=0.886, test=0.615) recall: (train=0.973, test=0.774) total time=  13.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.951, test=0.634) f1: (train=0.954, test=0.653) precision: (train=0.922, test=0.632) recall: (train=0.987, test=0.675) total time=  15.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.629) f1: (train=0.958, test=0.651) precision: (train=0.925, test=0.624) recall: (train=0.992, test=0.679) total time=  16.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.631) f1: (train=0.916, test=0.640) precision: (train=0.873, test=0.636) recall: (train=0.964, test=0.644) total time=   9.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.617) f1: (train=0.959, test=0.634) precision: (train=0.937, test=0.615) recall: (train=0.983, test=0.654) total time=  14.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.623) f1: (train=0.918, test=0.669) precision: (train=0.869, test=0.604) recall: (train=0.972, test=0.748) total time=  10.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.700) f1: (train=0.952, test=0.710) precision: (train=0.923, test=0.697) recall: (train=0.983, test=0.723) total time=  13.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.907, test=0.652) f1: (train=0.913, test=0.678) precision: (train=0.869, test=0.639) recall: (train=0.961, test=0.723) total time=  11.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.960, test=0.626) f1: (train=0.962, test=0.636) precision: (train=0.940, test=0.630) recall: (train=0.984, test=0.642) total time=  14.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.902, test=0.706) f1: (train=0.909, test=0.731) precision: (train=0.863, test=0.683) recall: (train=0.959, test=0.786) total time=   8.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.901, test=0.658) f1: (train=0.908, test=0.690) precision: (train=0.863, test=0.640) recall: (train=0.958, test=0.748) total time=  10.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.957, test=0.646) f1: (train=0.959, test=0.665) precision: (train=0.932, test=0.643) recall: (train=0.987, test=0.688) total time=  17.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.643) f1: (train=0.925, test=0.669) precision: (train=0.882, test=0.635) recall: (train=0.973, test=0.706) total time=  18.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.914, test=0.677) f1: (train=0.919, test=0.706) precision: (train=0.881, test=0.658) recall: (train=0.961, test=0.761) total time=  17.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.968, test=0.597) f1: (train=0.969, test=0.625) precision: (train=0.952, test=0.593) recall: (train=0.987, test=0.660) total time=  21.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.956, test=0.658) f1: (train=0.958, test=0.675) precision: (train=0.929, test=0.653) recall: (train=0.989, test=0.698) total time=  22.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.626) f1: (train=0.925, test=0.667) precision: (train=0.882, test=0.609) recall: (train=0.973, test=0.736) total time=  14.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.951, test=0.617) f1: (train=0.953, test=0.649) precision: (train=0.925, test=0.607) recall: (train=0.983, test=0.698) total time=  22.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.962, test=0.690) f1: (train=0.963, test=0.703) precision: (train=0.939, test=0.685) recall: (train=0.989, test=0.723) total time=  23.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.677) f1: (train=0.925, test=0.700) precision: (train=0.886, test=0.663) recall: (train=0.967, test=0.742) total time=  14.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.615) f1: (train=0.955, test=0.628) precision: (train=0.926, test=0.618) recall: (train=0.986, test=0.637) total time=  14.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.640) f1: (train=0.921, test=0.663) precision: (train=0.879, test=0.634) recall: (train=0.969, test=0.694) total time=  15.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.911, test=0.668) f1: (train=0.917, test=0.694) precision: (train=0.871, test=0.652) recall: (train=0.969, test=0.742) total time=  15.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.617) f1: (train=0.962, test=0.636) precision: (train=0.930, test=0.614) recall: (train=0.997, test=0.660) total time=  19.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.961, test=0.607) f1: (train=0.962, test=0.639) precision: (train=0.941, test=0.599) recall: (train=0.984, test=0.686) total time=  18.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.665) f1: (train=0.962, test=0.687) precision: (train=0.935, test=0.653) recall: (train=0.991, test=0.723) total time=  18.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.957, test=0.613) f1: (train=0.959, test=0.649) precision: (train=0.933, test=0.602) recall: (train=0.986, test=0.704) total time=  17.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.919, test=0.661) f1: (train=0.923, test=0.683) precision: (train=0.885, test=0.651) recall: (train=0.965, test=0.717) total time=  14.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.925, test=0.629) f1: (train=0.930, test=0.674) precision: (train=0.887, test=0.609) recall: (train=0.976, test=0.755) total time=  10.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.908, test=0.671) f1: (train=0.915, test=0.700) precision: (train=0.867, test=0.652) recall: (train=0.969, test=0.755) total time=  11.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=5000, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.706) f1: (train=0.921, test=0.737) precision: (train=0.882, test=0.675) recall: (train=0.964, test=0.811) total time=  11.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.671) f1: (train=0.961, test=0.687) precision: (train=0.943, test=0.665) recall: (train=0.980, test=0.711) total time=  13.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.645) f1: (train=0.952, test=0.667) precision: (train=0.922, test=0.638) recall: (train=0.984, test=0.698) total time=  12.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.960, test=0.649) f1: (train=0.961, test=0.667) precision: (train=0.944, test=0.643) recall: (train=0.980, test=0.692) total time=  12.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.621) f1: (train=0.952, test=0.643) precision: (train=0.931, test=0.618) recall: (train=0.975, test=0.669) total time=  15.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.956, test=0.623) f1: (train=0.958, test=0.651) precision: (train=0.932, test=0.615) recall: (train=0.986, test=0.692) total time=  14.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.910, test=0.618) f1: (train=0.916, test=0.645) precision: (train=0.867, test=0.612) recall: (train=0.972, test=0.681) total time=  14.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.905, test=0.665) f1: (train=0.912, test=0.690) precision: (train=0.864, test=0.650) recall: (train=0.965, test=0.736) total time=  15.4s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.899, test=0.687) f1: (train=0.906, test=0.710) precision: (train=0.861, test=0.670) recall: (train=0.956, test=0.755) total time=  13.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.649) f1: (train=0.918, test=0.680) precision: (train=0.866, test=0.632) recall: (train=0.976, test=0.736) total time=  14.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.904, test=0.668) f1: (train=0.912, test=0.694) precision: (train=0.858, test=0.652) recall: (train=0.973, test=0.742) total time=  14.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.959, test=0.636) f1: (train=0.961, test=0.644) precision: (train=0.936, test=0.640) recall: (train=0.987, test=0.648) total time=  17.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.669) f1: (train=0.960, test=0.689) precision: (train=0.932, test=0.661) recall: (train=0.989, test=0.719) total time=  21.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.613) f1: (train=0.965, test=0.641) precision: (train=0.946, test=0.607) recall: (train=0.984, test=0.679) total time=  21.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.965, test=0.671) f1: (train=0.966, test=0.679) precision: (train=0.949, test=0.673) recall: (train=0.984, test=0.686) total time=  24.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.919, test=0.618) f1: (train=0.925, test=0.643) precision: (train=0.877, test=0.614) recall: (train=0.978, test=0.675) total time=  21.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.915, test=0.681) f1: (train=0.921, test=0.704) precision: (train=0.877, test=0.665) recall: (train=0.970, test=0.748) total time=  21.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.962, test=0.610) f1: (train=0.964, test=0.633) precision: (train=0.940, test=0.607) recall: (train=0.989, test=0.660) total time=  24.0s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.916, test=0.639) f1: (train=0.921, test=0.674) precision: (train=0.880, test=0.622) recall: (train=0.967, test=0.736) total time=  23.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.700) f1: (train=0.927, test=0.720) precision: (train=0.894, test=0.684) recall: (train=0.962, test=0.761) total time=  22.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.918, test=0.674) f1: (train=0.923, test=0.700) precision: (train=0.880, test=0.657) recall: (train=0.970, test=0.748) total time=  22.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.955, test=0.659) f1: (train=0.957, test=0.671) precision: (train=0.934, test=0.661) recall: (train=0.981, test=0.681) total time=  21.4s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.645) f1: (train=0.955, test=0.671) precision: (train=0.926, test=0.635) recall: (train=0.986, test=0.711) total time=  14.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.956, test=0.665) f1: (train=0.958, test=0.669) precision: (train=0.941, test=0.671) recall: (train=0.975, test=0.667) total time=  15.9s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.646) f1: (train=0.922, test=0.676) precision: (train=0.872, test=0.634) recall: (train=0.978, test=0.725) total time=  13.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.962, test=0.626) f1: (train=0.964, test=0.651) precision: (train=0.942, test=0.619) recall: (train=0.987, test=0.686) total time=  16.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.633) f1: (train=0.955, test=0.659) precision: (train=0.929, test=0.624) recall: (train=0.983, test=0.698) total time=  15.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.910, test=0.684) f1: (train=0.916, test=0.715) precision: (train=0.873, test=0.660) recall: (train=0.962, test=0.780) total time=  14.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.917, test=0.642) f1: (train=0.923, test=0.689) precision: (train=0.871, test=0.617) recall: (train=0.983, test=0.780) total time=  16.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.911, test=0.693) f1: (train=0.916, test=0.714) precision: (train=0.876, test=0.678) recall: (train=0.961, test=0.755) total time=  14.7s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.911, test=0.668) f1: (train=0.917, test=0.703) precision: (train=0.866, test=0.644) recall: (train=0.975, test=0.774) total time=  11.6s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.948, test=0.618) f1: (train=0.950, test=0.627) precision: (train=0.929, test=0.623) recall: (train=0.972, test=0.631) total time=  13.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.949, test=0.645) f1: (train=0.951, test=0.667) precision: (train=0.921, test=0.638) recall: (train=0.984, test=0.698) total time=  13.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.633) f1: (train=0.961, test=0.642) precision: (train=0.941, test=0.636) recall: (train=0.981, test=0.648) total time=  14.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.681) f1: (train=0.957, test=0.701) precision: (train=0.933, test=0.669) recall: (train=0.983, test=0.736) total time=  14.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.952, test=0.629) f1: (train=0.954, test=0.648) precision: (train=0.927, test=0.626) recall: (train=0.983, test=0.673) total time=  12.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.907, test=0.661) f1: (train=0.914, test=0.690) precision: (train=0.862, test=0.645) recall: (train=0.973, test=0.742) total time=  11.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.910, test=0.631) f1: (train=0.916, test=0.655) precision: (train=0.869, test=0.625) recall: (train=0.969, test=0.688) total time=  12.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.914, test=0.642) f1: (train=0.920, test=0.680) precision: (train=0.872, test=0.623) recall: (train=0.973, test=0.748) total time=  12.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.907, test=0.716) f1: (train=0.914, test=0.746) precision: (train=0.863, test=0.682) recall: (train=0.970, test=0.824) total time=  19.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.903, test=0.645) f1: (train=0.911, test=0.680) precision: (train=0.856, test=0.628) recall: (train=0.973, test=0.742) total time=  21.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.653) f1: (train=0.959, test=0.656) precision: (train=0.936, test=0.662) recall: (train=0.984, test=0.650) total time=  24.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.653) f1: (train=0.927, test=0.675) precision: (train=0.888, test=0.646) recall: (train=0.970, test=0.706) total time=  16.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.636) f1: (train=0.960, test=0.648) precision: (train=0.932, test=0.636) recall: (train=0.989, test=0.660) total time=  23.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.967, test=0.626) f1: (train=0.969, test=0.653) precision: (train=0.947, test=0.618) recall: (train=0.991, test=0.692) total time=  24.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.956, test=0.677) f1: (train=0.958, test=0.695) precision: (train=0.928, test=0.669) recall: (train=0.991, test=0.723) total time=  24.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.964, test=0.604) f1: (train=0.965, test=0.629) precision: (train=0.946, test=0.600) recall: (train=0.986, test=0.660) total time=  25.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.910, test=0.677) f1: (train=0.916, test=0.706) precision: (train=0.872, test=0.658) recall: (train=0.964, test=0.761) total time=  20.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.919, test=0.633) f1: (train=0.924, test=0.676) precision: (train=0.878, test=0.612) recall: (train=0.975, test=0.755) total time=  23.3s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.909, test=0.652) f1: (train=0.915, test=0.682) precision: (train=0.869, test=0.636) recall: (train=0.967, test=0.736) total time=  14.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.921, test=0.706) f1: (train=0.926, test=0.723) precision: (train=0.889, test=0.694) recall: (train=0.965, test=0.755) total time=  16.0s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.962, test=0.687) f1: (train=0.964, test=0.703) precision: (train=0.939, test=0.678) recall: (train=0.991, test=0.730) total time=  15.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.962, test=0.613) f1: (train=0.964, test=0.643) precision: (train=0.947, test=0.606) recall: (train=0.981, test=0.686) total time=  16.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.627) f1: (train=0.955, test=0.649) precision: (train=0.925, test=0.624) recall: (train=0.987, test=0.675) total time=  19.2s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.964, test=0.661) f1: (train=0.966, test=0.667) precision: (train=0.942, test=0.667) recall: (train=0.991, test=0.667) total time=  18.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.919, test=0.637) f1: (train=0.925, test=0.661) precision: (train=0.881, test=0.631) recall: (train=0.973, test=0.694) total time=  12.5s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.952, test=0.620) f1: (train=0.954, test=0.651) precision: (train=0.930, test=0.610) recall: (train=0.980, test=0.698) total time=  14.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.912, test=0.693) f1: (train=0.918, test=0.716) precision: (train=0.874, test=0.676) recall: (train=0.967, test=0.761) total time=   9.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.653) f1: (train=0.960, test=0.677) precision: (train=0.937, test=0.644) recall: (train=0.984, test=0.713) total time=   9.8s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.912, test=0.642) f1: (train=0.919, test=0.685) precision: (train=0.869, test=0.619) recall: (train=0.975, test=0.767) total time=  11.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.913, test=0.677) f1: (train=0.918, test=0.702) precision: (train=0.882, test=0.661) recall: (train=0.958, test=0.748) total time=  10.4s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=2, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.907, test=0.665) f1: (train=0.914, test=0.701) precision: (train=0.863, test=0.641) recall: (train=0.972, test=0.774) total time=   9.9s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.959, test=0.613) f1: (train=0.961, test=0.645) precision: (train=0.936, test=0.604) recall: (train=0.987, test=0.692) total time=  10.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.957, test=0.626) f1: (train=0.959, test=0.640) precision: (train=0.938, test=0.627) recall: (train=0.980, test=0.654) total time=   9.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.687) f1: (train=0.960, test=0.707) precision: (train=0.941, test=0.674) recall: (train=0.980, test=0.742) total time=  10.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.588) f1: (train=0.956, test=0.613) precision: (train=0.933, test=0.586) recall: (train=0.981, test=0.642) total time=  12.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.637) f1: (train=0.918, test=0.665) precision: (train=0.869, test=0.628) recall: (train=0.972, test=0.706) total time=  11.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.902, test=0.658) f1: (train=0.909, test=0.682) precision: (train=0.856, test=0.646) recall: (train=0.970, test=0.723) total time=  10.7s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.633) f1: (train=0.917, test=0.672) precision: (train=0.865, test=0.615) recall: (train=0.976, test=0.742) total time=  12.7s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.896, test=0.690) f1: (train=0.904, test=0.724) precision: (train=0.852, test=0.661) recall: (train=0.964, test=0.799) total time=  13.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.896, test=0.684) f1: (train=0.904, test=0.706) precision: (train=0.857, test=0.669) recall: (train=0.956, test=0.748) total time=  12.3s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.964, test=0.643) f1: (train=0.965, test=0.665) precision: (train=0.943, test=0.638) recall: (train=0.989, test=0.694) total time=  22.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.961, test=0.629) f1: (train=0.963, test=0.637) precision: (train=0.936, test=0.634) recall: (train=0.991, test=0.642) total time=  23.5s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.963, test=0.607) f1: (train=0.965, test=0.635) precision: (train=0.947, test=0.601) recall: (train=0.983, test=0.673) total time=  21.9s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.964, test=0.668) f1: (train=0.965, test=0.687) precision: (train=0.947, test=0.659) recall: (train=0.984, test=0.717) total time=  20.8s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.918, test=0.668) f1: (train=0.923, test=0.692) precision: (train=0.880, test=0.654) recall: (train=0.970, test=0.736) total time=  21.7s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.923, test=0.621) f1: (train=0.928, test=0.643) precision: (train=0.888, test=0.618) recall: (train=0.972, test=0.669) total time=  24.2s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.623) f1: (train=0.925, test=0.669) precision: (train=0.882, test=0.604) recall: (train=0.973, test=0.748) total time=  21.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.958, test=0.642) f1: (train=0.960, test=0.671) precision: (train=0.936, test=0.630) recall: (train=0.986, test=0.717) total time=  26.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.922, test=0.696) f1: (train=0.926, test=0.723) precision: (train=0.888, test=0.674) recall: (train=0.969, test=0.780) total time=  23.2s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.914, test=0.645) f1: (train=0.920, test=0.673) precision: (train=0.875, test=0.633) recall: (train=0.969, test=0.717) total time=  20.0s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.955, test=0.623) f1: (train=0.958, test=0.647) precision: (train=0.927, test=0.617) recall: (train=0.991, test=0.679) total time=  18.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.958, test=0.643) f1: (train=0.960, test=0.654) precision: (train=0.932, test=0.646) recall: (train=0.989, test=0.662) total time=  20.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.681) f1: (train=0.962, test=0.695) precision: (train=0.943, test=0.675) recall: (train=0.981, test=0.717) total time=  14.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.963, test=0.591) f1: (train=0.965, test=0.628) precision: (train=0.943, test=0.584) recall: (train=0.987, test=0.679) total time=  14.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.601) f1: (train=0.955, test=0.633) precision: (train=0.929, test=0.593) recall: (train=0.983, test=0.679) total time=  17.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.915, test=0.637) f1: (train=0.920, test=0.657) precision: (train=0.877, test=0.634) recall: (train=0.967, test=0.681) total time=  16.6s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.908, test=0.671) f1: (train=0.914, test=0.703) precision: (train=0.870, test=0.649) recall: (train=0.964, test=0.767) total time=  16.2s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.915, test=0.661) f1: (train=0.921, test=0.690) precision: (train=0.881, test=0.645) recall: (train=0.964, test=0.742) total time=  11.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.923, test=0.639) f1: (train=0.927, test=0.685) precision: (train=0.886, test=0.615) recall: (train=0.973, test=0.774) total time=  14.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 1), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.910, test=0.671) f1: (train=0.916, test=0.705) precision: (train=0.866, test=0.647) recall: (train=0.973, test=0.774) total time=  11.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.955, test=0.629) f1: (train=0.958, test=0.651) precision: (train=0.925, test=0.624) recall: (train=0.992, test=0.679) total time=  13.5s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.951, test=0.634) f1: (train=0.954, test=0.653) precision: (train=0.922, test=0.632) recall: (train=0.987, test=0.675) total time=  15.6s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.950, test=0.700) f1: (train=0.952, test=0.710) precision: (train=0.923, test=0.697) recall: (train=0.983, test=0.723) total time=  13.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.960, test=0.626) f1: (train=0.962, test=0.636) precision: (train=0.940, test=0.630) recall: (train=0.984, test=0.642) total time=  15.1s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_only at 0x000002648A354540>; accuracy: (train=0.958, test=0.617) f1: (train=0.959, test=0.634) precision: (train=0.937, test=0.615) recall: (train=0.983, test=0.654) total time=  13.1s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.631) f1: (train=0.916, test=0.640) precision: (train=0.873, test=0.636) recall: (train=0.964, test=0.644) total time=  11.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.907, test=0.652) f1: (train=0.913, test=0.678) precision: (train=0.869, test=0.639) recall: (train=0.961, test=0.723) total time=  13.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.911, test=0.623) f1: (train=0.918, test=0.669) precision: (train=0.869, test=0.604) recall: (train=0.972, test=0.748) total time=  16.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.902, test=0.706) f1: (train=0.909, test=0.731) precision: (train=0.863, test=0.683) recall: (train=0.959, test=0.786) total time=  20.0s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lower_stop at 0x000002648A3549A0>; accuracy: (train=0.901, test=0.658) f1: (train=0.908, test=0.690) precision: (train=0.863, test=0.640) recall: (train=0.958, test=0.748) total time=  19.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.968, test=0.597) f1: (train=0.969, test=0.625) precision: (train=0.952, test=0.593) recall: (train=0.987, test=0.660) total time=  24.2s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.957, test=0.646) f1: (train=0.959, test=0.665) precision: (train=0.932, test=0.643) recall: (train=0.987, test=0.688) total time=  27.1s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.956, test=0.658) f1: (train=0.958, test=0.675) precision: (train=0.929, test=0.653) recall: (train=0.989, test=0.698) total time=  25.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.962, test=0.690) f1: (train=0.963, test=0.703) precision: (train=0.939, test=0.685) recall: (train=0.989, test=0.723) total time=  24.0s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.643) f1: (train=0.925, test=0.669) precision: (train=0.882, test=0.635) recall: (train=0.973, test=0.706) total time=  20.9s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_only at 0x000002648A354D60>; accuracy: (train=0.951, test=0.617) f1: (train=0.953, test=0.649) precision: (train=0.925, test=0.607) recall: (train=0.983, test=0.698) total time=  27.3s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.914, test=0.677) f1: (train=0.919, test=0.706) precision: (train=0.881, test=0.658) recall: (train=0.961, test=0.761) total time=  24.9s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.626) f1: (train=0.925, test=0.667) precision: (train=0.882, test=0.609) recall: (train=0.973, test=0.736) total time=  27.3s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.920, test=0.677) f1: (train=0.925, test=0.700) precision: (train=0.886, test=0.663) recall: (train=0.967, test=0.742) total time=  17.5s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.617) f1: (train=0.962, test=0.636) precision: (train=0.930, test=0.614) recall: (train=0.997, test=0.660) total time=  19.3s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.961, test=0.607) f1: (train=0.962, test=0.639) precision: (train=0.941, test=0.599) recall: (train=0.984, test=0.686) total time=  16.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function stem_stop at 0x000002648A354E00>; accuracy: (train=0.911, test=0.668) f1: (train=0.917, test=0.694) precision: (train=0.871, test=0.652) recall: (train=0.969, test=0.742) total time=  20.8s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.953, test=0.615) f1: (train=0.955, test=0.628) precision: (train=0.926, test=0.618) recall: (train=0.986, test=0.637) total time=  22.4s\n",
      "[CV 1/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.640) f1: (train=0.921, test=0.663) precision: (train=0.879, test=0.634) recall: (train=0.969, test=0.694) total time=  15.8s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.957, test=0.613) f1: (train=0.959, test=0.649) precision: (train=0.933, test=0.602) recall: (train=0.986, test=0.704) total time=  17.1s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_only at 0x000002648A354EA0>; accuracy: (train=0.960, test=0.665) f1: (train=0.962, test=0.687) precision: (train=0.935, test=0.653) recall: (train=0.991, test=0.723) total time=  23.7s\n",
      "[CV 2/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.919, test=0.661) f1: (train=0.923, test=0.683) precision: (train=0.885, test=0.651) recall: (train=0.965, test=0.717) total time=  10.6s\n",
      "[CV 3/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.925, test=0.629) f1: (train=0.930, test=0.674) precision: (train=0.887, test=0.609) recall: (train=0.976, test=0.755) total time=   9.8s\n",
      "[CV 4/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.916, test=0.706) f1: (train=0.921, test=0.737) precision: (train=0.882, test=0.675) recall: (train=0.964, test=0.811) total time=   9.6s\n",
      "[CV 5/5] END classifier=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), vectorizer=TfidfVectorizer(token_pattern=None), vectorizer__max_df=0.9, vectorizer__max_features=None, vectorizer__min_df=3, vectorizer__ngram_range=(1, 2), vectorizer__tokenizer=<function lem_stop at 0x000002648A354F40>; accuracy: (train=0.908, test=0.671) f1: (train=0.915, test=0.700) precision: (train=0.867, test=0.652) recall: (train=0.969, test=0.755) total time=   9.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "3 fits failed out of a total of 1440.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1389, in fit_transform\n",
      "    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1276, in _count_vocab\n",
      "    for feature in analyze(doc):\n",
      "                   ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 112, in _analyze\n",
      "    doc = tokenizer(doc)\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Home\\AppData\\Local\\Temp\\ipykernel_3372\\3587977024.py\", line 38, in lem_only\n",
      "    return [lemmatizer.lemmatize(token) for token in tokens if token not in related_words and token.isalpha()]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\nltk\\stem\\wordnet.py\", line 45, in lemmatize\n",
      "    lemmas = wn._morphy(word, pos)\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\nltk\\corpus\\util.py\", line 121, in __getattr__\n",
      "    self.__load()\n",
      "  File \"C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\nltk\\corpus\\util.py\", line 95, in __load\n",
      "    args, kwargs = self.__args, self.__kwargs\n",
      "                   ^^^^^^^^^^^\n",
      "AttributeError: 'WordNetCorpusReader' object has no attribute '_LazyCorpusLoader__args'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.64814717 0.6634867  0.66347653 0.66603651        nan 0.67498423\n",
      " 0.65773387 0.66604465 0.66665921 0.67307137 0.65453491 0.66988258\n",
      " 0.64814717 0.6634867  0.66347653 0.66603651 0.64942309 0.67498423\n",
      " 0.65773387 0.66604465 0.66665921 0.67307137 0.65453491 0.66988258\n",
      " 0.64814717 0.6634867  0.66347653 0.66603651 0.64942309 0.67498423\n",
      " 0.65773387 0.66604465 0.66665921 0.67307137 0.65453491 0.66988258\n",
      " 0.64814717 0.6634867  0.66347653 0.66603651 0.64942309 0.67498423\n",
      " 0.65773387 0.66604465 0.66665921 0.67307137 0.65453491 0.66988258\n",
      " 0.64814717 0.6634867  0.66347653 0.66603651 0.64942309 0.67498423\n",
      " 0.65773387 0.66604465 0.66665921 0.67307137 0.65453491 0.66988258\n",
      " 0.64814717 0.6634867  0.66347653 0.66603651 0.64942309 0.67498423\n",
      " 0.65773387 0.66604465 0.66665921 0.67307137 0.65453491 0.66988258\n",
      " 0.64814717 0.6634867  0.66347653 0.66603651 0.64942309 0.67498423\n",
      " 0.65773387 0.66604465 0.66665921 0.67307137 0.65453491 0.66988258\n",
      " 0.64814717 0.6634867  0.66347653 0.66603651 0.64942309 0.67498423\n",
      " 0.65773387 0.66604465 0.66665921 0.67307137 0.65453491 0.66988258\n",
      " 0.64814717 0.6634867  0.66347653 0.66603651 0.64942309 0.67498423\n",
      " 0.65773387 0.66604465 0.66665921 0.67307137 0.65453491 0.66988258\n",
      " 0.64814717 0.6634867  0.66347653 0.66603651 0.64942309 0.67498423\n",
      " 0.65773387 0.66604465 0.66665921 0.67307137 0.65453491 0.66988258\n",
      " 0.64814717 0.6634867  0.66347653 0.66603651 0.64942309 0.67498423\n",
      " 0.65773387 0.66604465 0.66665921 0.67307137 0.65453491 0.66988258\n",
      " 0.64814717 0.6634867  0.66347653 0.66603651 0.64942309 0.67498423\n",
      " 0.65773387 0.66604465 0.66665921 0.67307137 0.65453491 0.66988258\n",
      " 0.64177571 0.6571132  0.63982825 0.66222503 0.64558515 0.66667955\n",
      " 0.62260638 0.65582304 0.64432958 0.66285993 0.62069962 0.66221282\n",
      " 0.63344865 0.66029588 0.6379276  0.65072139 0.62770395 0.65582304\n",
      " 0.62133453 0.65391018 0.62450907 0.65837488 0.6258033  0.6615718\n",
      " 0.64177571 0.6571132  0.63982825 0.66222503 0.64558515 0.66667955\n",
      " 0.62772227 0.659022   0.63856047 0.66411957 0.64496245 0.66285179\n",
      " 0.63344865 0.66029588 0.6379276  0.65072139 0.62770395 0.65582304\n",
      " 0.64112859 0.65391018 0.64175943 0.65837488 0.62324943 0.6615718\n",
      " 0.64177571 0.6571132  0.63982825 0.66222503 0.64558515 0.66667955\n",
      " 0.64113876 0.659022   0.63919945 0.66411957 0.64177164 0.66285179\n",
      " 0.63344865 0.66029588 0.6379276  0.65072139 0.62770395 0.65582304\n",
      " 0.64112859 0.65391018 0.64175943 0.65837488 0.62324943 0.6615718\n",
      " 0.64177571 0.6571132  0.63982825 0.66222503 0.64558515 0.66667955\n",
      " 0.62260638 0.65582304 0.64432958 0.66285993 0.62069962 0.66221282\n",
      " 0.63344865 0.66029588 0.6379276  0.65072139 0.62770395 0.65582304\n",
      " 0.62133453 0.65391018 0.62450907 0.65837488 0.6258033  0.6615718\n",
      " 0.64177571 0.6571132  0.63982825 0.66222503 0.64558515 0.66667955\n",
      " 0.62772227 0.659022   0.63856047 0.66411957 0.64496245 0.66285179\n",
      " 0.63344865 0.66029588 0.6379276  0.65072139 0.62770395 0.65582304\n",
      " 0.64112859 0.65391018 0.64175943 0.65837488 0.62324943 0.6615718\n",
      " 0.64177571 0.6571132  0.63982825 0.66222503 0.64558515 0.66667955\n",
      " 0.64113876 0.659022   0.63919945 0.66411957 0.64177164 0.66285179\n",
      " 0.63344865 0.66029588 0.6379276  0.65072139 0.62770395 0.65582304\n",
      " 0.64112859 0.65391018 0.64175943 0.65837488 0.62324943 0.6615718 ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.91634709 0.86973271 0.92337253 0.87851227        nan 0.87452172\n",
      " 0.92209458 0.87069104 0.9270441  0.87931036 0.926565   0.87548006\n",
      " 0.91634709 0.86973271 0.92337253 0.87851227 0.92369087 0.87452172\n",
      " 0.92209458 0.87069104 0.9270441  0.87931036 0.926565   0.87548006\n",
      " 0.91634709 0.86973271 0.92337253 0.87851227 0.92369087 0.87452172\n",
      " 0.92209458 0.87069104 0.9270441  0.87931036 0.926565   0.87548006\n",
      " 0.91634709 0.86973271 0.92337253 0.87851227 0.92369087 0.87452172\n",
      " 0.92209458 0.87069104 0.9270441  0.87931036 0.926565   0.87548006\n",
      " 0.91634709 0.86973271 0.92337253 0.87851227 0.92369087 0.87452172\n",
      " 0.92209458 0.87069104 0.9270441  0.87931036 0.926565   0.87548006\n",
      " 0.91634709 0.86973271 0.92337253 0.87851227 0.92369087 0.87452172\n",
      " 0.92209458 0.87069104 0.9270441  0.87931036 0.926565   0.87548006\n",
      " 0.91634709 0.86973271 0.92337253 0.87851227 0.92369087 0.87452172\n",
      " 0.92209458 0.87069104 0.9270441  0.87931036 0.926565   0.87548006\n",
      " 0.91634709 0.86973271 0.92337253 0.87851227 0.92369087 0.87452172\n",
      " 0.92209458 0.87069104 0.9270441  0.87931036 0.926565   0.87548006\n",
      " 0.91634709 0.86973271 0.92337253 0.87851227 0.92369087 0.87452172\n",
      " 0.92209458 0.87069104 0.9270441  0.87931036 0.926565   0.87548006\n",
      " 0.91634709 0.86973271 0.92337253 0.87851227 0.92369087 0.87452172\n",
      " 0.92209458 0.87069104 0.9270441  0.87931036 0.926565   0.87548006\n",
      " 0.91634709 0.86973271 0.92337253 0.87851227 0.92369087 0.87452172\n",
      " 0.92209458 0.87069104 0.9270441  0.87931036 0.926565   0.87548006\n",
      " 0.91634709 0.86973271 0.92337253 0.87851227 0.92369087 0.87452172\n",
      " 0.92209458 0.87069104 0.9270441  0.87931036 0.926565   0.87548006\n",
      " 0.95513974 0.90597123 0.96152557 0.91826326 0.95593859 0.91283578\n",
      " 0.95561936 0.90692918 0.95961016 0.9160285  0.96184391 0.91523028\n",
      " 0.95753527 0.903258   0.96216505 0.91938122 0.95785438 0.91411246\n",
      " 0.9565768  0.90629059 0.9618448  0.91714607 0.96008952 0.9168262\n",
      " 0.95513974 0.90597123 0.96152557 0.91826326 0.95593859 0.91283578\n",
      " 0.95338408 0.90820587 0.95865233 0.91618875 0.95769476 0.91283629\n",
      " 0.95753527 0.903258   0.96216505 0.91938122 0.95785438 0.91411246\n",
      " 0.95482063 0.90629059 0.95865233 0.91714607 0.95817285 0.9168262\n",
      " 0.95513974 0.90597123 0.96152557 0.91826326 0.95593859 0.91283578\n",
      " 0.95274511 0.90820587 0.96056786 0.91618875 0.95881131 0.91283629\n",
      " 0.95753527 0.903258   0.96216505 0.91938122 0.95785438 0.91411246\n",
      " 0.95482063 0.90629059 0.95865233 0.91714607 0.95817285 0.9168262\n",
      " 0.95513974 0.90597123 0.96152557 0.91826326 0.95593859 0.91283578\n",
      " 0.95561936 0.90692918 0.95961016 0.9160285  0.96184391 0.91523028\n",
      " 0.95753527 0.903258   0.96216505 0.91938122 0.95785438 0.91411246\n",
      " 0.9565768  0.90629059 0.9618448  0.91714607 0.96008952 0.9168262\n",
      " 0.95513974 0.90597123 0.96152557 0.91826326 0.95593859 0.91283578\n",
      " 0.95338408 0.90820587 0.95865233 0.91618875 0.95769476 0.91283629\n",
      " 0.95753527 0.903258   0.96216505 0.91938122 0.95785438 0.91411246\n",
      " 0.95482063 0.90629059 0.95865233 0.91714607 0.95817285 0.9168262\n",
      " 0.95513974 0.90597123 0.96152557 0.91826326 0.95593859 0.91283578\n",
      " 0.95274511 0.90820587 0.96056786 0.91618875 0.95881131 0.91283629\n",
      " 0.95753527 0.903258   0.96216505 0.91938122 0.95785438 0.91411246\n",
      " 0.95482063 0.90629059 0.95865233 0.91714607 0.95817285 0.9168262 ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.70981918 0.74626572 0.72613208 0.73868711        nan 0.76007862\n",
      " 0.73496069 0.74751572 0.72610849 0.74875786 0.7060456  0.75381289\n",
      " 0.70981918 0.74626572 0.72613208 0.73868711 0.7085456  0.76007862\n",
      " 0.73496069 0.74751572 0.72610849 0.74875786 0.7060456  0.75381289\n",
      " 0.70981918 0.74626572 0.72613208 0.73868711 0.7085456  0.76007862\n",
      " 0.73496069 0.74751572 0.72610849 0.74875786 0.7060456  0.75381289\n",
      " 0.70981918 0.74626572 0.72613208 0.73868711 0.7085456  0.76007862\n",
      " 0.73496069 0.74751572 0.72610849 0.74875786 0.7060456  0.75381289\n",
      " 0.70981918 0.74626572 0.72613208 0.73868711 0.7085456  0.76007862\n",
      " 0.73496069 0.74751572 0.72610849 0.74875786 0.7060456  0.75381289\n",
      " 0.70981918 0.74626572 0.72613208 0.73868711 0.7085456  0.76007862\n",
      " 0.73496069 0.74751572 0.72610849 0.74875786 0.7060456  0.75381289\n",
      " 0.70981918 0.74626572 0.72613208 0.73868711 0.7085456  0.76007862\n",
      " 0.73496069 0.74751572 0.72610849 0.74875786 0.7060456  0.75381289\n",
      " 0.70981918 0.74626572 0.72613208 0.73868711 0.7085456  0.76007862\n",
      " 0.73496069 0.74751572 0.72610849 0.74875786 0.7060456  0.75381289\n",
      " 0.70981918 0.74626572 0.72613208 0.73868711 0.7085456  0.76007862\n",
      " 0.73496069 0.74751572 0.72610849 0.74875786 0.7060456  0.75381289\n",
      " 0.70981918 0.74626572 0.72613208 0.73868711 0.7085456  0.76007862\n",
      " 0.73496069 0.74751572 0.72610849 0.74875786 0.7060456  0.75381289\n",
      " 0.70981918 0.74626572 0.72613208 0.73868711 0.7085456  0.76007862\n",
      " 0.73496069 0.74751572 0.72610849 0.74875786 0.7060456  0.75381289\n",
      " 0.70981918 0.74626572 0.72613208 0.73868711 0.7085456  0.76007862\n",
      " 0.73496069 0.74751572 0.72610849 0.74875786 0.7060456  0.75381289\n",
      " 0.69224057 0.72996069 0.67834119 0.73374214 0.68845126 0.76261006\n",
      " 0.66460692 0.73748428 0.69603774 0.74757075 0.67089623 0.74126572\n",
      " 0.68841195 0.74376572 0.68843553 0.72997642 0.6834434  0.74757075\n",
      " 0.66832547 0.73000786 0.6733805  0.73747642 0.66962264 0.74629717\n",
      " 0.69224057 0.72996069 0.67834119 0.73374214 0.68845126 0.76261006\n",
      " 0.67211478 0.74882075 0.67839623 0.74250786 0.69849057 0.74881289\n",
      " 0.68841195 0.74376572 0.68843553 0.72997642 0.6834434  0.74757075\n",
      " 0.67462264 0.73000786 0.69347484 0.73747642 0.68221698 0.74629717\n",
      " 0.69224057 0.72996069 0.67834119 0.73374214 0.68845126 0.76261006\n",
      " 0.6771934  0.74882075 0.67716981 0.74250786 0.69097484 0.74881289\n",
      " 0.68841195 0.74376572 0.68843553 0.72997642 0.6834434  0.74757075\n",
      " 0.67462264 0.73000786 0.69347484 0.73747642 0.68221698 0.74629717\n",
      " 0.69224057 0.72996069 0.67834119 0.73374214 0.68845126 0.76261006\n",
      " 0.66460692 0.73748428 0.69603774 0.74757075 0.67089623 0.74126572\n",
      " 0.68841195 0.74376572 0.68843553 0.72997642 0.6834434  0.74757075\n",
      " 0.66832547 0.73000786 0.6733805  0.73747642 0.66962264 0.74629717\n",
      " 0.69224057 0.72996069 0.67834119 0.73374214 0.68845126 0.76261006\n",
      " 0.67211478 0.74882075 0.67839623 0.74250786 0.69849057 0.74881289\n",
      " 0.68841195 0.74376572 0.68843553 0.72997642 0.6834434  0.74757075\n",
      " 0.67462264 0.73000786 0.69347484 0.73747642 0.68221698 0.74629717\n",
      " 0.69224057 0.72996069 0.67834119 0.73374214 0.68845126 0.76261006\n",
      " 0.6771934  0.74882075 0.67716981 0.74250786 0.69097484 0.74881289\n",
      " 0.68841195 0.74376572 0.68843553 0.72997642 0.6834434  0.74757075\n",
      " 0.67462264 0.73000786 0.69347484 0.73747642 0.68221698 0.74629717]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.96262551 0.93247534 0.96200053 0.9318474         nan 0.93278833\n",
      " 0.97047728 0.93436016 0.97330598 0.93498712 0.97016528 0.93436213\n",
      " 0.96262551 0.93247534 0.96200053 0.9318474  0.9660797  0.93278833\n",
      " 0.97047728 0.93436016 0.97330598 0.93498712 0.97016528 0.93436213\n",
      " 0.96262551 0.93247534 0.96200053 0.9318474  0.9660797  0.93278833\n",
      " 0.97047728 0.93436016 0.97330598 0.93498712 0.97016528 0.93436213\n",
      " 0.96262551 0.93247534 0.96200053 0.9318474  0.9660797  0.93278833\n",
      " 0.97047728 0.93436016 0.97330598 0.93498712 0.97016528 0.93436213\n",
      " 0.96262551 0.93247534 0.96200053 0.9318474  0.9660797  0.93278833\n",
      " 0.97047728 0.93436016 0.97330598 0.93498712 0.97016528 0.93436213\n",
      " 0.96262551 0.93247534 0.96200053 0.9318474  0.9660797  0.93278833\n",
      " 0.97047728 0.93436016 0.97330598 0.93498712 0.97016528 0.93436213\n",
      " 0.96262551 0.93247534 0.96200053 0.9318474  0.9660797  0.93278833\n",
      " 0.97047728 0.93436016 0.97330598 0.93498712 0.97016528 0.93436213\n",
      " 0.96262551 0.93247534 0.96200053 0.9318474  0.9660797  0.93278833\n",
      " 0.97047728 0.93436016 0.97330598 0.93498712 0.97016528 0.93436213\n",
      " 0.96262551 0.93247534 0.96200053 0.9318474  0.9660797  0.93278833\n",
      " 0.97047728 0.93436016 0.97330598 0.93498712 0.97016528 0.93436213\n",
      " 0.96262551 0.93247534 0.96200053 0.9318474  0.9660797  0.93278833\n",
      " 0.97047728 0.93436016 0.97330598 0.93498712 0.97016528 0.93436213\n",
      " 0.96262551 0.93247534 0.96200053 0.9318474  0.9660797  0.93278833\n",
      " 0.97047728 0.93436016 0.97330598 0.93498712 0.97016528 0.93436213\n",
      " 0.96262551 0.93247534 0.96200053 0.9318474  0.9660797  0.93278833\n",
      " 0.97047728 0.93436016 0.97330598 0.93498712 0.97016528 0.93436213\n",
      " 0.98083983 0.96859394 0.98680973 0.96953783 0.98241166 0.97173563\n",
      " 0.98398349 0.97299103 0.98775214 0.96639466 0.98994895 0.9692204\n",
      " 0.98241265 0.96765202 0.98649576 0.97047777 0.98618179 0.96827849\n",
      " 0.98335555 0.96262601 0.98837959 0.96859443 0.98869504 0.96859295\n",
      " 0.98083983 0.96859394 0.98680973 0.96953783 0.98241166 0.97173563\n",
      " 0.98147073 0.97173267 0.98712222 0.96827947 0.98618129 0.96890841\n",
      " 0.98241265 0.96765202 0.98649576 0.97047777 0.98618179 0.96827849\n",
      " 0.98586732 0.96262601 0.98712321 0.96859443 0.98869257 0.96859295\n",
      " 0.98083983 0.96859394 0.98680973 0.96953783 0.98241166 0.97173563\n",
      " 0.98052487 0.97173267 0.98806414 0.96827947 0.98586732 0.96890841\n",
      " 0.98241265 0.96765202 0.98649576 0.97047777 0.98618179 0.96827849\n",
      " 0.98586732 0.96262601 0.98712321 0.96859443 0.98869257 0.96859295\n",
      " 0.98083983 0.96859394 0.98680973 0.96953783 0.98241166 0.97173563\n",
      " 0.98398349 0.97299103 0.98775214 0.96639466 0.98994895 0.9692204\n",
      " 0.98241265 0.96765202 0.98649576 0.97047777 0.98618179 0.96827849\n",
      " 0.98335555 0.96262601 0.98837959 0.96859443 0.98869504 0.96859295\n",
      " 0.98083983 0.96859394 0.98680973 0.96953783 0.98241166 0.97173563\n",
      " 0.98147073 0.97173267 0.98712222 0.96827947 0.98618129 0.96890841\n",
      " 0.98241265 0.96765202 0.98649576 0.97047777 0.98618179 0.96827849\n",
      " 0.98586732 0.96262601 0.98712321 0.96859443 0.98869257 0.96859295\n",
      " 0.98083983 0.96859394 0.98680973 0.96953783 0.98241166 0.97173563\n",
      " 0.98052487 0.97173267 0.98806414 0.96827947 0.98586732 0.96890841\n",
      " 0.98241265 0.96765202 0.98649576 0.97047777 0.98618179 0.96827849\n",
      " 0.98586732 0.96262601 0.98712321 0.96859443 0.98869257 0.96859295]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.63852922 0.64677915 0.65249842 0.65215491        nan 0.65577455\n",
      " 0.64405091 0.6494464  0.65654235 0.65712935 0.6473324  0.65233524\n",
      " 0.63852922 0.64677915 0.65249842 0.65215491 0.64120645 0.65577455\n",
      " 0.64405091 0.6494464  0.65654235 0.65712935 0.6473324  0.65233524\n",
      " 0.63852922 0.64677915 0.65249842 0.65215491 0.64120645 0.65577455\n",
      " 0.64405091 0.6494464  0.65654235 0.65712935 0.6473324  0.65233524\n",
      " 0.63852922 0.64677915 0.65249842 0.65215491 0.64120645 0.65577455\n",
      " 0.64405091 0.6494464  0.65654235 0.65712935 0.6473324  0.65233524\n",
      " 0.63852922 0.64677915 0.65249842 0.65215491 0.64120645 0.65577455\n",
      " 0.64405091 0.6494464  0.65654235 0.65712935 0.6473324  0.65233524\n",
      " 0.63852922 0.64677915 0.65249842 0.65215491 0.64120645 0.65577455\n",
      " 0.64405091 0.6494464  0.65654235 0.65712935 0.6473324  0.65233524\n",
      " 0.63852922 0.64677915 0.65249842 0.65215491 0.64120645 0.65577455\n",
      " 0.64405091 0.6494464  0.65654235 0.65712935 0.6473324  0.65233524\n",
      " 0.63852922 0.64677915 0.65249842 0.65215491 0.64120645 0.65577455\n",
      " 0.64405091 0.6494464  0.65654235 0.65712935 0.6473324  0.65233524\n",
      " 0.63852922 0.64677915 0.65249842 0.65215491 0.64120645 0.65577455\n",
      " 0.64405091 0.6494464  0.65654235 0.65712935 0.6473324  0.65233524\n",
      " 0.63852922 0.64677915 0.65249842 0.65215491 0.64120645 0.65577455\n",
      " 0.64405091 0.6494464  0.65654235 0.65712935 0.6473324  0.65233524\n",
      " 0.63852922 0.64677915 0.65249842 0.65215491 0.64120645 0.65577455\n",
      " 0.64405091 0.6494464  0.65654235 0.65712935 0.6473324  0.65233524\n",
      " 0.63852922 0.64677915 0.65249842 0.65215491 0.64120645 0.65577455\n",
      " 0.64405091 0.6494464  0.65654235 0.65712935 0.6473324  0.65233524\n",
      " 0.6357868  0.64342335 0.63743772 0.64837113 0.64184746 0.64646297\n",
      " 0.61996585 0.64015774 0.63751398 0.64589673 0.61685297 0.64667211\n",
      " 0.62709241 0.64368524 0.63227776 0.63668714 0.62304618 0.63796685\n",
      " 0.61786547 0.64031947 0.62095352 0.64333404 0.62266027 0.64448358\n",
      " 0.6357868  0.64342335 0.63743772 0.64837113 0.64184746 0.64646297\n",
      " 0.62429491 0.64055933 0.63604297 0.64901581 0.6377295  0.64553698\n",
      " 0.62709241 0.64368524 0.63227776 0.63668714 0.62304618 0.63796685\n",
      " 0.63956807 0.64031947 0.63610351 0.64333404 0.61733553 0.64448358\n",
      " 0.6357868  0.64342335 0.63743772 0.64837113 0.64184746 0.64646297\n",
      " 0.63829854 0.64055933 0.63707324 0.64901581 0.63695047 0.64553698\n",
      " 0.62709241 0.64368524 0.63227776 0.63668714 0.62304618 0.63796685\n",
      " 0.63956807 0.64031947 0.63610351 0.64333404 0.61733553 0.64448358\n",
      " 0.6357868  0.64342335 0.63743772 0.64837113 0.64184746 0.64646297\n",
      " 0.61996585 0.64015774 0.63751398 0.64589673 0.61685297 0.64667211\n",
      " 0.62709241 0.64368524 0.63227776 0.63668714 0.62304618 0.63796685\n",
      " 0.61786547 0.64031947 0.62095352 0.64333404 0.62266027 0.64448358\n",
      " 0.6357868  0.64342335 0.63743772 0.64837113 0.64184746 0.64646297\n",
      " 0.62429491 0.64055933 0.63604297 0.64901581 0.6377295  0.64553698\n",
      " 0.62709241 0.64368524 0.63227776 0.63668714 0.62304618 0.63796685\n",
      " 0.63956807 0.64031947 0.63610351 0.64333404 0.61733553 0.64448358\n",
      " 0.6357868  0.64342335 0.63743772 0.64837113 0.64184746 0.64646297\n",
      " 0.63829854 0.64055933 0.63707324 0.64901581 0.63695047 0.64553698\n",
      " 0.62709241 0.64368524 0.63227776 0.63668714 0.62304618 0.63796685\n",
      " 0.63956807 0.64031947 0.63610351 0.64333404 0.61733553 0.64448358]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.88329332 0.8317098  0.8951099  0.84507508        nan 0.83857503\n",
      " 0.88692962 0.8319583  0.89283094 0.84430482 0.89436486 0.83903981\n",
      " 0.88329332 0.8317098  0.8951099  0.84507508 0.89274047 0.83857503\n",
      " 0.88692962 0.8319583  0.89283094 0.84430482 0.89436486 0.83903981\n",
      " 0.88329332 0.8317098  0.8951099  0.84507508 0.89274047 0.83857503\n",
      " 0.88692962 0.8319583  0.89283094 0.84430482 0.89436486 0.83903981\n",
      " 0.88329332 0.8317098  0.8951099  0.84507508 0.89274047 0.83857503\n",
      " 0.88692962 0.8319583  0.89283094 0.84430482 0.89436486 0.83903981\n",
      " 0.88329332 0.8317098  0.8951099  0.84507508 0.89274047 0.83857503\n",
      " 0.88692962 0.8319583  0.89283094 0.84430482 0.89436486 0.83903981\n",
      " 0.88329332 0.8317098  0.8951099  0.84507508 0.89274047 0.83857503\n",
      " 0.88692962 0.8319583  0.89283094 0.84430482 0.89436486 0.83903981\n",
      " 0.88329332 0.8317098  0.8951099  0.84507508 0.89274047 0.83857503\n",
      " 0.88692962 0.8319583  0.89283094 0.84430482 0.89436486 0.83903981\n",
      " 0.88329332 0.8317098  0.8951099  0.84507508 0.89274047 0.83857503\n",
      " 0.88692962 0.8319583  0.89283094 0.84430482 0.89436486 0.83903981\n",
      " 0.88329332 0.8317098  0.8951099  0.84507508 0.89274047 0.83857503\n",
      " 0.88692962 0.8319583  0.89283094 0.84430482 0.89436486 0.83903981\n",
      " 0.88329332 0.8317098  0.8951099  0.84507508 0.89274047 0.83857503\n",
      " 0.88692962 0.8319583  0.89283094 0.84430482 0.89436486 0.83903981\n",
      " 0.88329332 0.8317098  0.8951099  0.84507508 0.89274047 0.83857503\n",
      " 0.88692962 0.8319583  0.89283094 0.84430482 0.89436486 0.83903981\n",
      " 0.88329332 0.8317098  0.8951099  0.84507508 0.89274047 0.83857503\n",
      " 0.88692962 0.8319583  0.89283094 0.84430482 0.89436486 0.83903981\n",
      " 0.93427258 0.86314873 0.94048528 0.88156312 0.93433893 0.87157772\n",
      " 0.93246249 0.86175424 0.93630095 0.88024088 0.93843373 0.87704259\n",
      " 0.93709916 0.8596759  0.94186533 0.88263091 0.93458541 0.87591216\n",
      " 0.93467734 0.8675429  0.93970172 0.88041527 0.93637957 0.87993951\n",
      " 0.93427258 0.86314873 0.94048528 0.88156312 0.93433893 0.87157772\n",
      " 0.93064198 0.86452629 0.93513898 0.87916916 0.93427893 0.87352494\n",
      " 0.93709916 0.8596759  0.94186533 0.88263091 0.93458541 0.87591216\n",
      " 0.92959245 0.8675429  0.93522152 0.88041527 0.93305161 0.87993951\n",
      " 0.93427258 0.86314873 0.94048528 0.88156312 0.93433893 0.87157772\n",
      " 0.93032731 0.86452629 0.93776988 0.87916916 0.93651873 0.87352494\n",
      " 0.93709916 0.8596759  0.94186533 0.88263091 0.93458541 0.87591216\n",
      " 0.92959245 0.8675429  0.93522152 0.88041527 0.93305161 0.87993951\n",
      " 0.93427258 0.86314873 0.94048528 0.88156312 0.93433893 0.87157772\n",
      " 0.93246249 0.86175424 0.93630095 0.88024088 0.93843373 0.87704259\n",
      " 0.93709916 0.8596759  0.94186533 0.88263091 0.93458541 0.87591216\n",
      " 0.93467734 0.8675429  0.93970172 0.88041527 0.93637957 0.87993951\n",
      " 0.93427258 0.86314873 0.94048528 0.88156312 0.93433893 0.87157772\n",
      " 0.93064198 0.86452629 0.93513898 0.87916916 0.93427893 0.87352494\n",
      " 0.93709916 0.8596759  0.94186533 0.88263091 0.93458541 0.87591216\n",
      " 0.92959245 0.8675429  0.93522152 0.88041527 0.93305161 0.87993951\n",
      " 0.93427258 0.86314873 0.94048528 0.88156312 0.93433893 0.87157772\n",
      " 0.93032731 0.86452629 0.93776988 0.87916916 0.93651873 0.87352494\n",
      " 0.93709916 0.8596759  0.94186533 0.88263091 0.93458541 0.87591216\n",
      " 0.92959245 0.8675429  0.93522152 0.88041527 0.93305161 0.87993951]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.67178835 0.69286926 0.68719883 0.69243984        nan 0.70402707\n",
      " 0.68569809 0.69493954 0.68920607 0.69975436 0.67502178 0.69922191\n",
      " 0.67178835 0.69286926 0.68719883 0.69243984 0.67290072 0.70402707\n",
      " 0.68569809 0.69493954 0.68920607 0.69975436 0.67502178 0.69922191\n",
      " 0.67178835 0.69286926 0.68719883 0.69243984 0.67290072 0.70402707\n",
      " 0.68569809 0.69493954 0.68920607 0.69975436 0.67502178 0.69922191\n",
      " 0.67178835 0.69286926 0.68719883 0.69243984 0.67290072 0.70402707\n",
      " 0.68569809 0.69493954 0.68920607 0.69975436 0.67502178 0.69922191\n",
      " 0.67178835 0.69286926 0.68719883 0.69243984 0.67290072 0.70402707\n",
      " 0.68569809 0.69493954 0.68920607 0.69975436 0.67502178 0.69922191\n",
      " 0.67178835 0.69286926 0.68719883 0.69243984 0.67290072 0.70402707\n",
      " 0.68569809 0.69493954 0.68920607 0.69975436 0.67502178 0.69922191\n",
      " 0.67178835 0.69286926 0.68719883 0.69243984 0.67290072 0.70402707\n",
      " 0.68569809 0.69493954 0.68920607 0.69975436 0.67502178 0.69922191\n",
      " 0.67178835 0.69286926 0.68719883 0.69243984 0.67290072 0.70402707\n",
      " 0.68569809 0.69493954 0.68920607 0.69975436 0.67502178 0.69922191\n",
      " 0.67178835 0.69286926 0.68719883 0.69243984 0.67290072 0.70402707\n",
      " 0.68569809 0.69493954 0.68920607 0.69975436 0.67502178 0.69922191\n",
      " 0.67178835 0.69286926 0.68719883 0.69243984 0.67290072 0.70402707\n",
      " 0.68569809 0.69493954 0.68920607 0.69975436 0.67502178 0.69922191\n",
      " 0.67178835 0.69286926 0.68719883 0.69243984 0.67290072 0.70402707\n",
      " 0.68569809 0.69493954 0.68920607 0.69975436 0.67502178 0.69922191\n",
      " 0.67178835 0.69286926 0.68719883 0.69243984 0.67290072 0.70402707\n",
      " 0.68569809 0.69493954 0.68920607 0.69975436 0.67502178 0.69922191\n",
      " 0.66275873 0.68392906 0.65699603 0.68831777 0.66393241 0.6994228\n",
      " 0.64126071 0.68527911 0.66523989 0.69265309 0.64259217 0.69058407\n",
      " 0.65618372 0.68988826 0.65890414 0.67981762 0.65149752 0.68799257\n",
      " 0.6419672  0.68152124 0.64589949 0.68705189 0.64515328 0.69126598\n",
      " 0.66275873 0.68392906 0.65699603 0.68831777 0.66393241 0.6994228\n",
      " 0.64703674 0.69027488 0.65634134 0.69226597 0.66650653 0.69300069\n",
      " 0.65618372 0.68988826 0.65890414 0.67981762 0.65149752 0.68799257\n",
      " 0.65654146 0.68152124 0.66338227 0.68705189 0.64783893 0.69126598\n",
      " 0.66275873 0.68392906 0.65699603 0.68831777 0.66393241 0.6994228\n",
      " 0.65696481 0.69027488 0.65614502 0.69226597 0.66248797 0.69300069\n",
      " 0.65618372 0.68988826 0.65890414 0.67981762 0.65149752 0.68799257\n",
      " 0.65654146 0.68152124 0.66338227 0.68705189 0.64783893 0.69126598\n",
      " 0.66275873 0.68392906 0.65699603 0.68831777 0.66393241 0.6994228\n",
      " 0.64126071 0.68527911 0.66523989 0.69265309 0.64259217 0.69058407\n",
      " 0.65618372 0.68988826 0.65890414 0.67981762 0.65149752 0.68799257\n",
      " 0.6419672  0.68152124 0.64589949 0.68705189 0.64515328 0.69126598\n",
      " 0.66275873 0.68392906 0.65699603 0.68831777 0.66393241 0.6994228\n",
      " 0.64703674 0.69027488 0.65634134 0.69226597 0.66650653 0.69300069\n",
      " 0.65618372 0.68988826 0.65890414 0.67981762 0.65149752 0.68799257\n",
      " 0.65654146 0.68152124 0.66338227 0.68705189 0.64783893 0.69126598\n",
      " 0.66275873 0.68392906 0.65699603 0.68831777 0.66393241 0.6994228\n",
      " 0.65696481 0.69027488 0.65614502 0.69226597 0.66248797 0.69300069\n",
      " 0.65618372 0.68988826 0.65890414 0.67981762 0.65149752 0.68799257\n",
      " 0.65654146 0.68152124 0.66338227 0.68705189 0.64783893 0.69126598]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Home\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.92124809 0.87918637 0.92733636 0.88633235        nan 0.88315071\n",
      " 0.92682066 0.88017801 0.93132983 0.88732092 0.93070732 0.88409381\n",
      " 0.92124809 0.87918637 0.92733636 0.88633235 0.92792414 0.88315071\n",
      " 0.92682066 0.88017801 0.93132983 0.88732092 0.93070732 0.88409381\n",
      " 0.92124809 0.87918637 0.92733636 0.88633235 0.92792414 0.88315071\n",
      " 0.92682066 0.88017801 0.93132983 0.88732092 0.93070732 0.88409381\n",
      " 0.92124809 0.87918637 0.92733636 0.88633235 0.92792414 0.88315071\n",
      " 0.92682066 0.88017801 0.93132983 0.88732092 0.93070732 0.88409381\n",
      " 0.92124809 0.87918637 0.92733636 0.88633235 0.92792414 0.88315071\n",
      " 0.92682066 0.88017801 0.93132983 0.88732092 0.93070732 0.88409381\n",
      " 0.92124809 0.87918637 0.92733636 0.88633235 0.92792414 0.88315071\n",
      " 0.92682066 0.88017801 0.93132983 0.88732092 0.93070732 0.88409381\n",
      " 0.92124809 0.87918637 0.92733636 0.88633235 0.92792414 0.88315071\n",
      " 0.92682066 0.88017801 0.93132983 0.88732092 0.93070732 0.88409381\n",
      " 0.92124809 0.87918637 0.92733636 0.88633235 0.92792414 0.88315071\n",
      " 0.92682066 0.88017801 0.93132983 0.88732092 0.93070732 0.88409381\n",
      " 0.92124809 0.87918637 0.92733636 0.88633235 0.92792414 0.88315071\n",
      " 0.92682066 0.88017801 0.93132983 0.88732092 0.93070732 0.88409381\n",
      " 0.92124809 0.87918637 0.92733636 0.88633235 0.92792414 0.88315071\n",
      " 0.92682066 0.88017801 0.93132983 0.88732092 0.93070732 0.88409381\n",
      " 0.92124809 0.87918637 0.92733636 0.88633235 0.92792414 0.88315071\n",
      " 0.92682066 0.88017801 0.93132983 0.88732092 0.93070732 0.88409381\n",
      " 0.92124809 0.87918637 0.92733636 0.88633235 0.92792414 0.88315071\n",
      " 0.92682066 0.88017801 0.93132983 0.88732092 0.93070732 0.88409381\n",
      " 0.9569621  0.91282333 0.96307373 0.92342903 0.95775272 0.91890537\n",
      " 0.95751557 0.91399758 0.96133368 0.92128297 0.96348896 0.92079406\n",
      " 0.95921514 0.91046458 0.96365035 0.9244655  0.95966856 0.91976241\n",
      " 0.95837863 0.91260995 0.96341149 0.92239014 0.96180537 0.92212345\n",
      " 0.9569621  0.91282333 0.96307373 0.92342903 0.95775272 0.91890537\n",
      " 0.95537022 0.9149882  0.96042484 0.92155533 0.95951836 0.91871076\n",
      " 0.95921514 0.91046458 0.96365035 0.9244655  0.95966856 0.91976241\n",
      " 0.95687861 0.91260995 0.96045109 0.92239014 0.96004986 0.92212345\n",
      " 0.9569621  0.91282333 0.96307373 0.92342903 0.95775272 0.91890537\n",
      " 0.95474685 0.9149882  0.96224104 0.92155533 0.96053776 0.91871076\n",
      " 0.95921514 0.91046458 0.96365035 0.9244655  0.95966856 0.91976241\n",
      " 0.95687861 0.91260995 0.96045109 0.92239014 0.96004986 0.92212345\n",
      " 0.9569621  0.91282333 0.96307373 0.92342903 0.95775272 0.91890537\n",
      " 0.95751557 0.91399758 0.96133368 0.92128297 0.96348896 0.92079406\n",
      " 0.95921514 0.91046458 0.96365035 0.9244655  0.95966856 0.91976241\n",
      " 0.95837863 0.91260995 0.96341149 0.92239014 0.96180537 0.92212345\n",
      " 0.9569621  0.91282333 0.96307373 0.92342903 0.95775272 0.91890537\n",
      " 0.95537022 0.9149882  0.96042484 0.92155533 0.95951836 0.91871076\n",
      " 0.95921514 0.91046458 0.96365035 0.9244655  0.95966856 0.91976241\n",
      " 0.95687861 0.91260995 0.96045109 0.92239014 0.96004986 0.92212345\n",
      " 0.9569621  0.91282333 0.96307373 0.92342903 0.95775272 0.91890537\n",
      " 0.95474685 0.9149882  0.96224104 0.92155533 0.96053776 0.91871076\n",
      " 0.95921514 0.91046458 0.96365035 0.9244655  0.95966856 0.91976241\n",
      " 0.95687861 0.91260995 0.96045109 0.92239014 0.96004986 0.92212345]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search\n",
    "\n",
    "# Record start time\n",
    "start_time =time.time()\n",
    "\n",
    "\n",
    "\n",
    "with parallel_backend('threading', n_jobs=-1):\n",
    "    grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfa39926-b982-4047-ba39-6eef78ea2882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 4522.0351 seconds\n"
     ]
    }
   ],
   "source": [
    "# Code you want to time (e.g., fitting a model)\n",
    "# Example: grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8811037a-8a59-4afc-aebd-e71d7f57da35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier</th>\n",
       "      <th>param_vectorizer</th>\n",
       "      <th>param_vectorizer__max_df</th>\n",
       "      <th>param_vectorizer__max_features</th>\n",
       "      <th>param_vectorizer__min_df</th>\n",
       "      <th>param_vectorizer__ngram_range</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "      <th>split0_train_f1</th>\n",
       "      <th>split1_train_f1</th>\n",
       "      <th>split2_train_f1</th>\n",
       "      <th>split3_train_f1</th>\n",
       "      <th>split4_train_f1</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>std_train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.949552</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>3.161523</td>\n",
       "      <td>1.092554</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(token_pattern=None)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671788</td>\n",
       "      <td>0.026088</td>\n",
       "      <td>204</td>\n",
       "      <td>0.919609</td>\n",
       "      <td>0.922962</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.917983</td>\n",
       "      <td>0.924117</td>\n",
       "      <td>0.921248</td>\n",
       "      <td>0.002219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.165167</td>\n",
       "      <td>5.378996</td>\n",
       "      <td>1.884814</td>\n",
       "      <td>0.774990</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(token_pattern=None)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692869</td>\n",
       "      <td>0.024391</td>\n",
       "      <td>59</td>\n",
       "      <td>0.883929</td>\n",
       "      <td>0.882309</td>\n",
       "      <td>0.875827</td>\n",
       "      <td>0.875280</td>\n",
       "      <td>0.878587</td>\n",
       "      <td>0.879186</td>\n",
       "      <td>0.003439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.120031</td>\n",
       "      <td>1.470151</td>\n",
       "      <td>4.373120</td>\n",
       "      <td>0.717288</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(token_pattern=None)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687199</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>131</td>\n",
       "      <td>0.932830</td>\n",
       "      <td>0.925532</td>\n",
       "      <td>0.923427</td>\n",
       "      <td>0.929385</td>\n",
       "      <td>0.925508</td>\n",
       "      <td>0.927336</td>\n",
       "      <td>0.003354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.043328</td>\n",
       "      <td>4.331086</td>\n",
       "      <td>4.827612</td>\n",
       "      <td>1.590701</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(token_pattern=None)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692440</td>\n",
       "      <td>0.013102</td>\n",
       "      <td>73</td>\n",
       "      <td>0.887229</td>\n",
       "      <td>0.886245</td>\n",
       "      <td>0.887892</td>\n",
       "      <td>0.885049</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.886332</td>\n",
       "      <td>0.001102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.708147</td>\n",
       "      <td>7.640329</td>\n",
       "      <td>1.523650</td>\n",
       "      <td>1.869666</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(token_pattern=None)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.925870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.927013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>13.064052</td>\n",
       "      <td>3.556542</td>\n",
       "      <td>3.395017</td>\n",
       "      <td>1.541867</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>TfidfVectorizer(token_pattern=None)</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681521</td>\n",
       "      <td>0.029798</td>\n",
       "      <td>169</td>\n",
       "      <td>0.916293</td>\n",
       "      <td>0.912752</td>\n",
       "      <td>0.917717</td>\n",
       "      <td>0.908550</td>\n",
       "      <td>0.907738</td>\n",
       "      <td>0.912610</td>\n",
       "      <td>0.003997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>20.630471</td>\n",
       "      <td>1.659882</td>\n",
       "      <td>5.005322</td>\n",
       "      <td>0.897432</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>TfidfVectorizer(token_pattern=None)</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663382</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>226</td>\n",
       "      <td>0.958779</td>\n",
       "      <td>0.958175</td>\n",
       "      <td>0.969183</td>\n",
       "      <td>0.963303</td>\n",
       "      <td>0.952816</td>\n",
       "      <td>0.960451</td>\n",
       "      <td>0.005489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>18.565896</td>\n",
       "      <td>3.267501</td>\n",
       "      <td>3.832250</td>\n",
       "      <td>2.069654</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>TfidfVectorizer(token_pattern=None)</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687052</td>\n",
       "      <td>0.016259</td>\n",
       "      <td>143</td>\n",
       "      <td>0.925262</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.924925</td>\n",
       "      <td>0.917472</td>\n",
       "      <td>0.922390</td>\n",
       "      <td>0.003458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>17.016517</td>\n",
       "      <td>2.032845</td>\n",
       "      <td>2.958295</td>\n",
       "      <td>0.959548</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>TfidfVectorizer(token_pattern=None)</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647839</td>\n",
       "      <td>0.020555</td>\n",
       "      <td>272</td>\n",
       "      <td>0.955065</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.962394</td>\n",
       "      <td>0.961890</td>\n",
       "      <td>0.958779</td>\n",
       "      <td>0.960050</td>\n",
       "      <td>0.002816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>10.251659</td>\n",
       "      <td>1.785884</td>\n",
       "      <td>0.954970</td>\n",
       "      <td>0.677818</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>TfidfVectorizer(token_pattern=None)</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691266</td>\n",
       "      <td>0.025923</td>\n",
       "      <td>89</td>\n",
       "      <td>0.921466</td>\n",
       "      <td>0.923423</td>\n",
       "      <td>0.929746</td>\n",
       "      <td>0.921230</td>\n",
       "      <td>0.914752</td>\n",
       "      <td>0.922123</td>\n",
       "      <td>0.004803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows  72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         8.949552      0.589286         3.161523        1.092554   \n",
       "1        13.165167      5.378996         1.884814        0.774990   \n",
       "2        22.120031      1.470151         4.373120        0.717288   \n",
       "3        28.043328      4.331086         4.827612        1.590701   \n",
       "4        23.708147      7.640329         1.523650        1.869666   \n",
       "..             ...           ...              ...             ...   \n",
       "283      13.064052      3.556542         3.395017        1.541867   \n",
       "284      20.630471      1.659882         5.005322        0.897432   \n",
       "285      18.565896      3.267501         3.832250        2.069654   \n",
       "286      17.016517      2.032845         2.958295        0.959548   \n",
       "287      10.251659      1.785884         0.954970        0.677818   \n",
       "\n",
       "                                      param_classifier  \\\n",
       "0    XGBClassifier(base_score=None, booster=None, c...   \n",
       "1    XGBClassifier(base_score=None, booster=None, c...   \n",
       "2    XGBClassifier(base_score=None, booster=None, c...   \n",
       "3    XGBClassifier(base_score=None, booster=None, c...   \n",
       "4    XGBClassifier(base_score=None, booster=None, c...   \n",
       "..                                                 ...   \n",
       "283  XGBClassifier(base_score=None, booster=None, c...   \n",
       "284  XGBClassifier(base_score=None, booster=None, c...   \n",
       "285  XGBClassifier(base_score=None, booster=None, c...   \n",
       "286  XGBClassifier(base_score=None, booster=None, c...   \n",
       "287  XGBClassifier(base_score=None, booster=None, c...   \n",
       "\n",
       "                        param_vectorizer param_vectorizer__max_df  \\\n",
       "0    CountVectorizer(token_pattern=None)                      0.8   \n",
       "1    CountVectorizer(token_pattern=None)                      0.8   \n",
       "2    CountVectorizer(token_pattern=None)                      0.8   \n",
       "3    CountVectorizer(token_pattern=None)                      0.8   \n",
       "4    CountVectorizer(token_pattern=None)                      0.8   \n",
       "..                                   ...                      ...   \n",
       "283  TfidfVectorizer(token_pattern=None)                      0.9   \n",
       "284  TfidfVectorizer(token_pattern=None)                      0.9   \n",
       "285  TfidfVectorizer(token_pattern=None)                      0.9   \n",
       "286  TfidfVectorizer(token_pattern=None)                      0.9   \n",
       "287  TfidfVectorizer(token_pattern=None)                      0.9   \n",
       "\n",
       "    param_vectorizer__max_features param_vectorizer__min_df  \\\n",
       "0                             3000                        2   \n",
       "1                             3000                        2   \n",
       "2                             3000                        2   \n",
       "3                             3000                        2   \n",
       "4                             3000                        2   \n",
       "..                             ...                      ...   \n",
       "283                           None                        3   \n",
       "284                           None                        3   \n",
       "285                           None                        3   \n",
       "286                           None                        3   \n",
       "287                           None                        3   \n",
       "\n",
       "    param_vectorizer__ngram_range  ... mean_test_f1 std_test_f1  rank_test_f1  \\\n",
       "0                          (1, 1)  ...     0.671788    0.026088           204   \n",
       "1                          (1, 1)  ...     0.692869    0.024391            59   \n",
       "2                          (1, 1)  ...     0.687199    0.021761           131   \n",
       "3                          (1, 1)  ...     0.692440    0.013102            73   \n",
       "4                          (1, 1)  ...          NaN         NaN           288   \n",
       "..                            ...  ...          ...         ...           ...   \n",
       "283                        (1, 2)  ...     0.681521    0.029798           169   \n",
       "284                        (1, 2)  ...     0.663382    0.026101           226   \n",
       "285                        (1, 2)  ...     0.687052    0.016259           143   \n",
       "286                        (1, 2)  ...     0.647839    0.020555           272   \n",
       "287                        (1, 2)  ...     0.691266    0.025923            89   \n",
       "\n",
       "     split0_train_f1  split1_train_f1  split2_train_f1  split3_train_f1  \\\n",
       "0           0.919609         0.922962         0.921569         0.917983   \n",
       "1           0.883929         0.882309         0.875827         0.875280   \n",
       "2           0.932830         0.925532         0.923427         0.929385   \n",
       "3           0.887229         0.886245         0.887892         0.885049   \n",
       "4                NaN              NaN         0.925870              NaN   \n",
       "..               ...              ...              ...              ...   \n",
       "283         0.916293         0.912752         0.917717         0.908550   \n",
       "284         0.958779         0.958175         0.969183         0.963303   \n",
       "285         0.925262         0.918919         0.925373         0.924925   \n",
       "286         0.955065         0.962121         0.962394         0.961890   \n",
       "287         0.921466         0.923423         0.929746         0.921230   \n",
       "\n",
       "     split4_train_f1  mean_train_f1  std_train_f1  \n",
       "0           0.924117       0.921248      0.002219  \n",
       "1           0.878587       0.879186      0.003439  \n",
       "2           0.925508       0.927336      0.003354  \n",
       "3           0.885246       0.886332      0.001102  \n",
       "4           0.927013            NaN           NaN  \n",
       "..               ...            ...           ...  \n",
       "283         0.907738       0.912610      0.003997  \n",
       "284         0.952816       0.960451      0.005489  \n",
       "285         0.917472       0.922390      0.003458  \n",
       "286         0.958779       0.960050      0.002816  \n",
       "287         0.914752       0.922123      0.004803  \n",
       "\n",
       "[288 rows x 72 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results.to_csv('../data/cv_results_xgb.csv') \n",
    "# Display important metrics\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd3ce14-7f3d-4ff8-87bf-5a3c9bf3d5af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
